0
00:00:00,000 --> 00:00:13,000
In the last lecture we introduced the notion of virtual memory and added a Memory Management Unit (MMU) to translate the virtual addresses generated by the CPU to the physical addresses sent to main memory.

1
00:00:13,000 --> 00:00:23,000
This gave us the ability to share physical memory between many running programs while still giving each program the illusion of having its own large address space.

2
00:00:23,000 --> 00:00:32,000
Both the virtual and physical address spaces are divided into a sequence of pages, each holding some fixed number of locations.

3
00:00:32,000 --> 00:00:43,000
For example if each page holds 2^12 bytes, a 32-bit address would have 2^32/2^12 = 2^20 pages.

4
00:00:43,000 --> 00:00:57,000
In this example the 32-bit address can be thought of as having two fields: a 20-bit page number formed from the high-order address bits and a 12-bit page offset formed from the low-order address bits.

5
00:00:57,000 --> 00:01:02,000
This arrangement ensures that nearby data will be located on the same page.

6
00:01:02,000 --> 00:01:10,000
The MMU translates virtual page numbers into physical page numbers using a page map.

7
00:01:10,000 --> 00:01:20,000
Conceptually the page map is an array where each entry in the array contains a physical page number along with a couple of bits indicating the page status.

8
00:01:20,000 --> 00:01:30,000
The translation process is simple: the virtual page number is used as an index into the array to fetch the corresponding physical page number.

9
00:01:30,000 --> 00:01:37,000
The physical page number is then combined with the page offset to form the complete physical address.

10
00:01:37,000 --> 00:01:48,000
In the actual implementation the page map is usually organized into multiple levels, which permits us to have resident only the portion of the page map we're actively using.

11
00:01:48,000 --> 00:02:03,000
And to avoid the costs of accessing the page map on each address translation, we use a cache (called the translation look-aside buffer) to remember the results of recent vpn-to-ppn translations.

12
00:02:03,000 --> 00:02:09,000
All allocated locations of each virtual address space can be found on secondary storage.

13
00:02:09,000 --> 00:02:14,000
Note that they may not necessarily be resident in main memory.

14
00:02:14,000 --> 00:02:27,000
If the CPU attempts to access a virtual address that's not resident in main memory, a page fault is signaled and the operating system will arrange to move the desired page from secondary storage into main memory.

15
00:02:27,000 --> 00:02:34,000
In practice, only the active pages for each program are resident in main memory at any given time.

16
00:02:34,000 --> 00:02:39,000
Here's a diagram showing the translation process.

17
00:02:39,000 --> 00:02:44,000
First we check to see if the required vpn-to-ppn mapping is cached in the TLB.

18
00:02:44,000 --> 00:02:53,000
If not, we have to access the hierarchical page map to see if the page is resident and, if so, lookup its physical page number.

19
00:02:53,000 --> 00:03:03,000
If we discover that the page is not resident, a page fault exception is signaled to the CPU so that it can run a handler to load the page from secondary storage.

20
00:03:03,000 --> 00:03:09,000
Note that access to a particular mapping context is controlled by two registers.

21
00:03:09,000 --> 00:03:13,000
The context-number register controls which mappings are accessible in the TLB.

22
00:03:13,000 --> 00:03:21,000
And the page-directory register indicates which physical page holds the top tier of the hierarchical page map.

23
00:03:21,000 --> 00:03:26,000
We can switch to another context by simply reloading these two registers.

24
00:03:26,000 --> 00:03:37,000
To effectively accommodate multiple contexts we'll need to have sufficient TLB capacity to simultaneously cache the most frequent mappings for all the processes.

25
00:03:37,000 --> 00:03:43,000
And we'll need some number of physical pages to hold the required page directories and segments of the page tables.

26
00:03:43,000 --> 00:03:55,000
For example, for a particular process, three pages will suffice hold the resident two-level page map for 1024 pages at each end of the virtual address space,

27
00:03:55,000 --> 00:04:03,000
providing access to up to 8MB of code, stack, and heap, more than enough for many simple programs.

28
00:04:03,000 --> 00:04:09,000
The page map creates the context needed to translate virtual addresses to physical addresses.

29
00:04:09,000 --> 00:04:19,000
In a computer system that's working on multiple tasks at the same time, we would like to support multiple contexts and to be able to quickly switch from one context to another.

30
00:04:19,000 --> 00:04:26,000
Multiple contexts would allow us to share physical memory between multiple programs.

31
00:04:26,000 --> 00:04:41,000
Each program would have an independent virtual address space, e.g., two programs could both access virtual address 0 as the address of their first instruction and would end up accessing different physical locations in main memory.

32
00:04:41,000 --> 00:04:48,000
When switching between programs, we'd perform a "context switch" to move to the appropriate MMU context.

33
00:04:48,000 --> 00:04:53,000
The ability to share the CPU between many programs seems like a great idea!

34
00:04:53,000 --> 00:04:57,000
Let's figure out the details of how that might work...

