{"C03S01B05-LEC.srt": {"url": "https://courses.edx.org/courses/course-v1:MITx+6.004.3x+2T2016/courseware/c3/c3s1/5?activate_block_id=block-v1%3AMITx%2B6.004.3x%2B2T2016%2Btype%40discussion%2Bblock%40c3s1v5", "items": [{"start": "00:00:00", "is_lecture": true, "end": "00:00:06", "is_worked_example": false, "text": "Now let's turn our attention to control hazards, illustrated by the code fragment shown here."}, {"start": "00:00:06", "is_lecture": true, "end": "00:00:09", "is_worked_example": false, "text": "Which instruction should be executed after the BNE?"}, {"start": "00:00:09", "is_lecture": true, "end": "00:00:13", "is_worked_example": false, "text": "If the value in R3 is non-zero, ADDC should be executed."}, {"start": "00:00:13", "is_lecture": true, "end": "00:00:18", "is_worked_example": false, "text": "If the value in R3 is zero, the next instruction should be SUB."}, {"start": "00:00:18", "is_lecture": true, "end": "00:00:29", "is_worked_example": false, "text": "If the current instruction is an explicit transfer of control (i.e., JMPs or branches), the choice of the next instruction depends on the execution of the current instruction."}, {"start": "00:00:29", "is_lecture": true, "end": "00:00:34", "is_worked_example": false, "text": "What are the implications of this dependency on our execution pipeline?"}, {"start": "00:00:34", "is_lecture": true, "end": "00:00:40", "is_worked_example": false, "text": "How does the unpipelined implementation determine the next instruction?"}, {"start": "00:00:40", "is_lecture": true, "end": "00:00:47", "is_worked_example": false, "text": "For branches (BEQ or BNE), the value to be loaded into the program counter depends on"}, {"start": "00:00:47", "is_lecture": true, "end": "00:00:52", "is_worked_example": false, "text": "(1) the opcode, i.e., whether the instruction is a BEQ or a BNE,"}, {"start": "00:00:52", "is_lecture": true, "end": "00:00:58", "is_worked_example": false, "text": "(2) the current value of the program counter since that's used in the offset calculation, and"}, {"start": "00:00:58", "is_lecture": true, "end": "00:01:06", "is_worked_example": false, "text": "(3) the value stored in the register specified by the RA field of the instruction since that's the value tested by the branch."}, {"start": "00:01:06", "is_lecture": true, "end": "00:01:15", "is_worked_example": false, "text": "For JMP instructions, the next value of the program counter depends once again on the opcode field and the value of the RA register."}, {"start": "00:01:15", "is_lecture": true, "end": "00:01:24", "is_worked_example": false, "text": "For all other instructions, the next PC value depends only the opcode of the instruction and the value PC+4."}, {"start": "00:01:24", "is_lecture": true, "end": "00:01:28", "is_worked_example": false, "text": "Exceptions also change the program counter."}, {"start": "00:01:28", "is_lecture": true, "end": "00:01:30", "is_worked_example": false, "text": "We'll deal with them later in the lecture."}, {"start": "00:01:30", "is_lecture": true, "end": "00:01:43", "is_worked_example": false, "text": "The control hazard is triggered by JMP and branches since their execution depends on the value in the RA register, i.e., they need to read from the register file, which happens in the RF pipeline stage."}, {"start": "00:01:43", "is_lecture": true, "end": "00:01:51", "is_worked_example": false, "text": "Our bypass mechanisms ensure that we'll use the correct value for the RA register even if it's not yet written into the register file."}, {"start": "00:01:51", "is_lecture": true, "end": "00:02:04", "is_worked_example": false, "text": "What we're concerned about here is that the address of the instruction following the JMP or branch will be loaded into program counter at the end of the cycle when the JMP or branch is in the RF stage."}, {"start": "00:02:04", "is_lecture": true, "end": "00:02:09", "is_worked_example": false, "text": "But what should the IF stage be doing while all this is going on in RF stage?"}, {"start": "00:02:09", "is_lecture": true, "end": "00:02:22", "is_worked_example": false, "text": "The answer is that in the case of JMPs and taken branches, we don't know what the IF stage should be doing until those instructions are able to access the value of the RA register in the RF stage."}, {"start": "00:02:22", "is_lecture": true, "end": "00:02:29", "is_worked_example": false, "text": "One solution is to stall the IF stage until the RF stage can compute the necessary result."}, {"start": "00:02:29", "is_lecture": true, "end": "00:02:33", "is_worked_example": false, "text": "This was the first of our general strategies for dealing with hazards."}, {"start": "00:02:33", "is_lecture": true, "end": "00:02:35", "is_worked_example": false, "text": "How would this work?"}, {"start": "00:02:35", "is_lecture": true, "end": "00:02:43", "is_worked_example": false, "text": "If the opcode in the RF stage is JMP, BEQ, or BNE, stall the IF stage for one cycle."}, {"start": "00:02:43", "is_lecture": true, "end": "00:02:56", "is_worked_example": false, "text": "In the example code shown here, assume that the value in R3 is non-zero when the BNE is executed, i.e., that the instruction following BNE should be the ADDC at the top of the loop."}, {"start": "00:02:56", "is_lecture": true, "end": "00:03:05", "is_worked_example": false, "text": "The pipeline diagram shows the effect we're trying to achieve: a NOP is inserted into the pipeline in cycles 4 and 8."}, {"start": "00:03:05", "is_lecture": true, "end": "00:03:12", "is_worked_example": false, "text": "Then execution resumes in the next cycle after the RF stage determines what instruction comes next."}, {"start": "00:03:12", "is_lecture": true, "end": "00:03:26", "is_worked_example": false, "text": "Note, by the way, that we're relying on our bypass logic to deliver the correct value for R3 from the MEM stage since the ADDC instruction that wrote into R3 is still in the pipeline, i.e., we have a data hazard to deal with too!"}, {"start": "00:03:26", "is_lecture": true, "end": "00:03:37", "is_worked_example": false, "text": "Looking at, say, the WB stage in the pipeline diagram, we see it takes 4 cycles to execute one iteration of our 3-instruction loop."}, {"start": "00:03:37", "is_lecture": true, "end": "00:03:43", "is_worked_example": false, "text": "So the effective CPI is 4/3, an increase of 33%."}, {"start": "00:03:43", "is_lecture": true, "end": "00:03:51", "is_worked_example": false, "text": "Using stall to deal with control hazards has had an impact on the instruction throughput of our execution pipeline."}, {"start": "00:03:51", "is_lecture": true, "end": "00:03:57", "is_worked_example": false, "text": "We've already seen the logic needed to introduce NOPs into the pipeline."}, {"start": "00:03:57", "is_lecture": true, "end": "00:04:05", "is_worked_example": false, "text": "In this case, we add a mux to the instruction path in the IF stage, controlled by the IRSrc_IF signal."}, {"start": "00:04:05", "is_lecture": true, "end": "00:04:11", "is_worked_example": false, "text": "We use the superscript on the control signals to indicate which pipeline stage holds the logic they control."}, {"start": "00:04:11", "is_lecture": true, "end": "00:04:24", "is_worked_example": false, "text": "If the opcode in the RF stage is JMP, BEQ, or BNE we set IRSrc_IF to 1, which causes a NOP to replace the instruction that was being read from main memory."}, {"start": "00:04:24", "is_lecture": true, "end": "00:04:35", "is_worked_example": false, "text": "And, of course, we'll be setting the PCSEL control signals to select the correct next PC value, so the IF stage will fetch the desired follow-on instruction in the next cycle."}, {"start": "00:04:35", "is_lecture": true, "end": "00:04:41", "is_worked_example": false, "text": "If we replace an instruction with NOP, we say we \"annulled\" the instruction."}, {"start": "00:04:41", "is_lecture": true, "end": "00:04:50", "is_worked_example": false, "text": "The branch instructions in the Beta ISA make their branch decision in the RF stage since they only need the value in register RA."}, {"start": "00:04:50", "is_lecture": true, "end": "00:04:55", "is_worked_example": false, "text": "But suppose the ISA had a branch where the branch decision was made in ALU stage."}, {"start": "00:04:55", "is_lecture": true, "end": "00:05:07", "is_worked_example": false, "text": "When the branch decision is made in the ALU stage, we need to introduce two NOPs into the pipeline, replacing the now unwanted instructions in the RF and IF stages."}, {"start": "00:05:07", "is_lecture": true, "end": "00:05:11", "is_worked_example": false, "text": "This would increase the effective CPI even further."}, {"start": "00:05:11", "is_lecture": true, "end": "00:05:18", "is_worked_example": false, "text": "But the tradeoff is that the more complex branches may reduce the number of instructions in the program."}, {"start": "00:05:18", "is_lecture": true, "end": "00:05:25", "is_worked_example": false, "text": "If we annul instructions in all the earlier pipeline stages, this is called \"flushing the pipeline\"."}, {"start": "00:05:25", "is_lecture": true, "end": "00:05:36", "is_worked_example": false, "text": "Since flushing the pipeline has a big impact on the effective CPI, we do it when it's the only way to ensure the correct behavior of the execution pipeline."}, {"start": "00:05:36", "is_lecture": true, "end": "00:05:42", "is_worked_example": false, "text": "We can be smarter about when we choose to flush the pipeline when executing branches."}, {"start": "00:05:42", "is_lecture": true, "end": "00:05:59", "is_worked_example": false, "text": "If the branch is not taken, it turns out that the pipeline has been doing the right thing by fetching the instruction following the branch."}, {"start": "00:05:59", "is_lecture": true, "end": "00:05:58", "is_worked_example": false, "text": "Starting execution of an instruction even when we're unsure whether we really want it executed is called \"speculation\"."}, {"start": "00:05:58", "is_lecture": true, "end": "00:06:08", "is_worked_example": false, "text": "Speculative execution is okay if we're able to annul the instruction before it has an effect on the CPU state, e.g., by writing into the register file or main memory."}, {"start": "00:06:08", "is_lecture": true, "end": "00:06:21", "is_worked_example": false, "text": "Since these state changes (called \"side effects\") happen in the later pipeline stages, an instruction can progress through the IF, RF, and ALU stages before we have to make a final decision about whether it should be annulled."}, {"start": "00:06:21", "is_lecture": true, "end": "00:06:25", "is_worked_example": false, "text": "How does speculation help with control hazards?"}, {"start": "00:06:25", "is_lecture": true, "end": "00:06:33", "is_worked_example": false, "text": "Guessing that the next value of the program counter is PC+4 is correct for all but JMPs and taken branches."}, {"start": "00:06:33", "is_lecture": true, "end": "00:06:41", "is_worked_example": false, "text": "Here's our example again, but this time let's assume that the BNE is not taken, i.e., that the value in R3 is zero."}, {"start": "00:06:41", "is_lecture": true, "end": "00:06:46", "is_worked_example": false, "text": "The SUB instruction enters the pipeline at the start of cycle 4."}, {"start": "00:06:46", "is_lecture": true, "end": "00:06:50", "is_worked_example": false, "text": "At the end of cycle 4, we know whether or not to annul the SUB."}, {"start": "00:06:50", "is_lecture": true, "end": "00:06:57", "is_worked_example": false, "text": "If the branch is not taken, we want to execute the SUB instruction, so we just let it continue down the pipeline."}, {"start": "00:06:57", "is_lecture": true, "end": "00:07:05", "is_worked_example": false, "text": "In other words, instead of always annulling the instruction following branch, we only annul it if the branch was taken."}, {"start": "00:07:05", "is_lecture": true, "end": "00:07:12", "is_worked_example": false, "text": "If the branch is not taken, the pipeline has speculated correctly and no instructions need to be annulled."}, {"start": "00:07:12", "is_lecture": true, "end": "00:07:20", "is_worked_example": false, "text": "However if the BNE is taken, the SUB is annulled at the end of cycle 4 and a NOP is executed in cycle 5."}, {"start": "00:07:20", "is_lecture": true, "end": "00:07:24", "is_worked_example": false, "text": "So we only introduce a bubble in the pipeline when there's a taken branch."}, {"start": "00:07:24", "is_lecture": true, "end": "00:07:30", "is_worked_example": false, "text": "Fewer bubbles will decrease the impact of annulment on the effective CPI."}, {"start": "00:07:30", "is_lecture": true, "end": "00:07:40", "is_worked_example": false, "text": "We'll be using the same data path circuitry as before, we'll just be a bit more clever about when the value of the IRSrc_IF control signal is set to 1."}, {"start": "00:07:40", "is_lecture": true, "end": "00:07:47", "is_worked_example": false, "text": "Instead of setting it to 1 for all branches, we only set it to 1 when the branch is taken."}, {"start": "00:07:47", "is_lecture": true, "end": "00:07:55", "is_worked_example": false, "text": "Our naive strategy of always speculating that the next instruction comes from PC+4 is wrong for JMPs and taken branches."}, {"start": "00:07:55", "is_lecture": true, "end": "00:08:05", "is_worked_example": false, "text": "Looking at simulated execution traces, we'll see that this error in speculation leads to about 10% higher effective CPI."}, {"start": "00:08:05", "is_lecture": true, "end": "00:08:06", "is_worked_example": false, "text": "Can we do better?"}, {"start": "00:08:06", "is_lecture": true, "end": "00:08:11", "is_worked_example": false, "text": "This is an important question for CPUs with deep pipelines."}, {"start": "00:08:11", "is_lecture": true, "end": "00:08:20", "is_worked_example": false, "text": "For example, Intel's Nehalem processor from 2009 resolves the more complex x86 branch instructions quite late in the pipeline."}, {"start": "00:08:20", "is_lecture": true, "end": "00:08:32", "is_worked_example": false, "text": "Since Nehalem is capable of executing multiple instructions each cycle, flushing the pipeline in Nehalem actually annuls the execution of many instructions, resulting in a considerable hit on the CPI."}, {"start": "00:08:32", "is_lecture": true, "end": "00:08:41", "is_worked_example": false, "text": "Like many modern processor implementations, Nehalem has a much more sophisticated speculation mechanism."}, {"start": "00:08:41", "is_lecture": true, "end": "00:08:49", "is_worked_example": false, "text": "Rather than always guessing the next instruction is at PC+4, it only does that for non-branch instructions."}, {"start": "00:08:49", "is_lecture": true, "end": "00:08:59", "is_worked_example": false, "text": "For branches, it predicts the behavior of each individual branch based on what the branch did last time it was executed and some knowledge of how the branch is being used."}, {"start": "00:08:59", "is_lecture": true, "end": "00:09:09", "is_worked_example": false, "text": "For example, backward branches at the end of loops, which are taken for all but the final iteration of the loop, can be identified by their negative branch offset values."}, {"start": "00:09:09", "is_lecture": true, "end": "00:09:20", "is_worked_example": false, "text": "Nehalem can even determine if there's correlation between branch instructions, using the results of an another, earlier branch to speculate on the branch decision of the current branch."}, {"start": "00:09:20", "is_lecture": true, "end": "00:09:32", "is_worked_example": false, "text": "With these sophisticated strategies, Nehalem's speculation is correct 95% to 99% of the time, greatly reducing the impact of branches on the effective CPI."}, {"start": "00:09:32", "is_lecture": true, "end": "00:09:38", "is_worked_example": false, "text": "There's also the lazy option of changing the ISA to deal with control hazards."}, {"start": "00:09:38", "is_lecture": true, "end": "00:09:45", "is_worked_example": false, "text": "For example, we could change the ISA to specify that the instruction following a jump or branch is always executed."}, {"start": "00:09:45", "is_lecture": true, "end": "00:09:49", "is_worked_example": false, "text": "In other words the transfer of control happens *after* the next instruction."}, {"start": "00:09:49", "is_lecture": true, "end": "00:09:55", "is_worked_example": false, "text": "This change ensures that the guess of PC+4 as the address of the next instruction is always correct!"}, {"start": "00:09:55", "is_lecture": true, "end": "00:10:08", "is_worked_example": false, "text": "In the example shown here, assuming we changed the ISA, we can reorganize the execution order of the loop to place the MUL instruction after the BNE instruction, in the so-called \"branch delay slot\"."}, {"start": "00:10:08", "is_lecture": true, "end": "00:10:16", "is_worked_example": false, "text": "Since the instruction in the branch delay slot is always executed, the MUL instruction will be executed during each iteration of the loop."}, {"start": "00:10:16", "is_lecture": true, "end": "00:10:20", "is_worked_example": false, "text": "The resulting execution is shown in this pipeline diagram."}, {"start": "00:10:20", "is_lecture": true, "end": "00:10:29", "is_worked_example": false, "text": "Assuming we can find an appropriate instruction to place in the delay slot, the branch will have zero impact on the effective CPI."}, {"start": "00:10:29", "is_lecture": true, "end": "00:10:32", "is_worked_example": false, "text": "Are branch delay slots a good idea?"}, {"start": "00:10:32", "is_lecture": true, "end": "00:10:38", "is_worked_example": false, "text": "Seems like they reduce the negative impact that branches might have on instruction throughput."}, {"start": "00:10:38", "is_lecture": true, "end": "00:10:45", "is_worked_example": false, "text": "The downside is that only half the time can we find instructions to move to the branch delay slot."}, {"start": "00:10:45", "is_lecture": true, "end": "00:10:51", "is_worked_example": false, "text": "The other half of the time we have to fill it with an explicit NOP instruction, increasing the size of the code."}, {"start": "00:10:51", "is_lecture": true, "end": "00:10:59", "is_worked_example": false, "text": "And if we make the branch decision later in the pipeline, there are more branch delay slots, which would be even harder to fill."}, {"start": "00:10:59", "is_lecture": true, "end": "00:11:06", "is_worked_example": false, "text": "In practice, it turns out that branch prediction works better than delay slots in reducing the impact of branches."}, {"start": "00:11:06", "is_lecture": true, "end": "00:11:14", "is_worked_example": false, "text": "So, once again we see that it's problematic to alter the ISA to improve the throughput of pipelined execution."}, {"start": "00:11:14", "is_lecture": true, "end": "00:11:25", "is_worked_example": false, "text": "ISAs outlive implementations, so it's best not to change the execution semantics to deal with performance issues created by a particular implementation."}]}, "C06S01B05-LEC.srt": {"url": "https://courses.edx.org/courses/course-v1:MITx+6.004.3x+2T2016/courseware/c6/c6s1/5?activate_block_id=block-v1%3AMITx%2B6.004.3x%2B2T2016%2Btype%40discussion%2Bblock%40c6s1v5", "items": [{"start": "00:00:00", "is_lecture": true, "end": "00:00:08", "is_worked_example": false, "text": "Another service provided by operating system is dealing properly with the attempt to execute instructions with \"illegal\" opcodes."}, {"start": "00:00:08", "is_lecture": true, "end": "00:00:15", "is_worked_example": false, "text": "Illegal is quotes because that just means opcodes whose operations aren't implemented directly by the hardware."}, {"start": "00:00:15", "is_lecture": true, "end": "00:00:21", "is_worked_example": false, "text": "As we'll see, it's possible extend the functionality of the hardware via software emulation."}, {"start": "00:00:21", "is_lecture": true, "end": "00:00:33", "is_worked_example": false, "text": "The action of the CPU upon encountering an illegal instruction (sometimes referred to as an unimplemented user operation or UUO) is very similar to how it processes interrupts."}, {"start": "00:00:33", "is_lecture": true, "end": "00:00:39", "is_worked_example": false, "text": "Think of illegal instructions as an interrupt caused directly by the CPU!"}, {"start": "00:00:39", "is_lecture": true, "end": "00:00:54", "is_worked_example": false, "text": "As for interrupts, the execution of the current instruction is suspended and the control signals are set to values to capture PC+4 in the XP register and set the PC to, in this case, 0x80000004."}, {"start": "00:00:54", "is_lecture": true, "end": "00:01:05", "is_worked_example": false, "text": "Note that bit 31 of the new PC, aka the supervisor bit, is set to 1, meaning that the OS handler will have access to the kernel-mode context."}, {"start": "00:01:05", "is_lecture": true, "end": "00:01:12", "is_worked_example": false, "text": "Here's some code similar to that found in the Tiny Operating System (TinyOS), which you'll be experimenting with in the final lab assignment."}, {"start": "00:01:12", "is_lecture": true, "end": "00:01:17", "is_worked_example": false, "text": "Let's do a quick walk-through of the code executed when an illegal instruction is executed."}, {"start": "00:01:17", "is_lecture": true, "end": "00:01:22", "is_worked_example": false, "text": "Starting at location 0, we see the branches to the handlers for the various interrupts and exceptions."}, {"start": "00:01:22", "is_lecture": true, "end": "00:01:29", "is_worked_example": false, "text": "In the case of an illegal instruction, the BR(I_IllOp) in location 4 will be executed."}, {"start": "00:01:29", "is_lecture": true, "end": "00:01:34", "is_worked_example": false, "text": "Immediately following is where the OS data structures are allocated."}, {"start": "00:01:34", "is_lecture": true, "end": "00:01:43", "is_worked_example": false, "text": "This includes space for the OS stack, UserMState where user-mode register values are stored during interrupts, and the process table,"}, {"start": "00:01:43", "is_lecture": true, "end": "00:01:50", "is_worked_example": false, "text": "providing long-term storage for the complete state of each process while another process is executing."}, {"start": "00:01:50", "is_lecture": true, "end": "00:01:57", "is_worked_example": false, "text": "When writing in assembly language, it's convenient to define macros for operations that are used repeatedly."}, {"start": "00:01:57", "is_lecture": true, "end": "00:02:09", "is_worked_example": false, "text": "We can use a macro call whenever we want to perform the action and the assembler will insert the body of the macro in place of the macro call, performing a lexical substitution of the macro's arguments."}, {"start": "00:02:09", "is_lecture": true, "end": "00:02:16", "is_worked_example": false, "text": "Here's a macro for a two-instruction sequence that extracts a particular field of bits from a 32-bit value."}, {"start": "00:02:16", "is_lecture": true, "end": "00:02:21", "is_worked_example": false, "text": "M is the bit number of the left-most bit, N is the bit number of the right-most bit."}, {"start": "00:02:21", "is_lecture": true, "end": "00:02:31", "is_worked_example": false, "text": "Bits are numbered 0 through 31, where bit 31 is the most-significant bit, i.e., the one at the left end of the 32-bit binary value."}, {"start": "00:02:31", "is_lecture": true, "end": "00:02:42", "is_worked_example": false, "text": "And here are some macros that expand into instruction sequences that save and restore the CPU registers to or from the UserMState temporary storage area."}, {"start": "00:02:42", "is_lecture": true, "end": "00:02:47", "is_worked_example": false, "text": "With those macros in hand, let's see how illegal opcodes are handled."}, {"start": "00:02:47", "is_lecture": true, "end": "00:02:56", "is_worked_example": false, "text": "Like all interrupt handlers, the first action is to save the user-mode registers in the temporary storage area and initialize the OS stack."}, {"start": "00:02:56", "is_lecture": true, "end": "00:03:01", "is_worked_example": false, "text": "Next, we fetch the illegal instruction from the user-mode program."}, {"start": "00:03:01", "is_lecture": true, "end": "00:03:08", "is_worked_example": false, "text": "Note that the saved PC+4 value is a virtual address in the context of the interrupted program."}, {"start": "00:03:08", "is_lecture": true, "end": "00:03:15", "is_worked_example": false, "text": "So we'll need to use the MMU routines to compute the correct physical address -- more about this on the next slide."}, {"start": "00:03:15", "is_lecture": true, "end": "00:03:26", "is_worked_example": false, "text": "Then we'll use the opcode of the illegal instruction as an index into a table of subroutine addresses, one for each of the 64 possible opcodes."}, {"start": "00:03:26", "is_lecture": true, "end": "00:03:34", "is_worked_example": false, "text": "Once we have the address of the handler for this particular illegal opcode, we JMP there to deal with the situation."}, {"start": "00:03:34", "is_lecture": true, "end": "00:03:42", "is_worked_example": false, "text": "Selecting a destination from a table of addresses is called \"dispatching\" and the table is called the \"dispatch table\"."}, {"start": "00:03:42", "is_lecture": true, "end": "00:05:42", "is_worked_example": false, "text": "If the dispatch table contains many different entries, dispatching is much more efficient in time and space than a long series of compares and branches."}, {"start": "00:05:42", "is_lecture": true, "end": "00:03:59", "is_worked_example": false, "text": "In this case, the table is indicating that the handler for most illegal opcodes is the UUOError routine,"}, {"start": "00:03:59", "is_lecture": true, "end": "00:04:07", "is_worked_example": false, "text": "so it might have smaller and faster simply to test for the two illegal opcodes the OS is going to emulate."}, {"start": "00:04:07", "is_lecture": true, "end": "00:04:17", "is_worked_example": false, "text": "Illegal opcode 1 will be used to implement procedure calls from user-mode to the OS, which we call supervisor calls."}, {"start": "00:04:17", "is_lecture": true, "end": "00:04:19", "is_worked_example": false, "text": "More on this in the next segment."}, {"start": "00:04:19", "is_lecture": true, "end": "00:04:30", "is_worked_example": false, "text": "As an example of having the OS emulate an instruction, we'll use illegal opcode 2 as the opcode for the SWAPREG instruction, which we'll discuss now."}, {"start": "00:04:30", "is_lecture": true, "end": "00:04:37", "is_worked_example": false, "text": "But first just a quick look at how the OS converts user-mode virtual addresses into physical addresses it can use."}, {"start": "00:04:37", "is_lecture": true, "end": "00:04:43", "is_worked_example": false, "text": "We'll build on the MMU VtoP procedure, described in the previous lecture."}, {"start": "00:04:43", "is_lecture": true, "end": "00:04:50", "is_worked_example": false, "text": "This procedure expects as its arguments the virtual page number and offset fields of the virtual address, so,"}, {"start": "00:04:50", "is_lecture": true, "end": "00:04:57", "is_worked_example": false, "text": "following our convention for passing arguments to C procedures, these are pushed onto the stack in reverse order."}, {"start": "00:04:57", "is_lecture": true, "end": "00:05:01", "is_worked_example": false, "text": "The corresponding physical address is returned in R0."}, {"start": "00:05:01", "is_lecture": true, "end": "00:05:08", "is_worked_example": false, "text": "We can then use the calculated physical address to read the desired location from physical memory."}, {"start": "00:05:08", "is_lecture": true, "end": "00:05:12", "is_worked_example": false, "text": "Okay, back to dealing with illegal opcodes."}, {"start": "00:05:12", "is_lecture": true, "end": "00:05:15", "is_worked_example": false, "text": "Here's the handler for opcodes that are truly illegal."}, {"start": "00:05:15", "is_lecture": true, "end": "00:05:23", "is_worked_example": false, "text": "In this case the OS uses various kernel routines to print out a helpful error message on the user's console, then crashes the system!"}, {"start": "00:05:23", "is_lecture": true, "end": "00:05:30", "is_worked_example": false, "text": "You may have seen these \"blue screens of death\" if you run the Windows operating system, full of cryptic hex numbers."}, {"start": "00:05:30", "is_lecture": true, "end": "00:05:36", "is_worked_example": false, "text": "Actually, this wouldn't be the best approach to handling an illegal opcode in a user's program."}, {"start": "00:05:36", "is_lecture": true, "end": "00:05:44", "is_worked_example": false, "text": "In a real operating system, it would be better to save the state of the process in a special debugging file historically referred to as a \"core dump\""}, {"start": "00:05:44", "is_lecture": true, "end": "00:05:52", "is_worked_example": false, "text": "and then terminate this particular process, perhaps printing a short error message on the user's console to let them know what happened."}, {"start": "00:05:52", "is_lecture": true, "end": "00:05:59", "is_worked_example": false, "text": "Then later the user could start a debugging program to examine the dump file to see where their bug is."}, {"start": "00:05:59", "is_lecture": true, "end": "00:06:11", "is_worked_example": false, "text": "Finally, here's the handler that will emulate the actions of the SWAPREG instruction, after which program execution will resume as if the instruction had been implemented in hardware."}, {"start": "00:06:11", "is_lecture": true, "end": "00:06:16", "is_worked_example": false, "text": "SWAPREG is an instruction that swaps the values in the two specified registers."}, {"start": "00:06:16", "is_lecture": true, "end": "00:06:26", "is_worked_example": false, "text": "To define a new instruction, we'd first have to let the assembler know to convert the swapreg(ra,rc) assembly language statement into binary."}, {"start": "00:06:26", "is_lecture": true, "end": "00:06:34", "is_worked_example": false, "text": "In this case we'll use a binary format similar to the ADDC instruction, but setting the unused literal field to 0."}, {"start": "00:06:34", "is_lecture": true, "end": "00:06:42", "is_worked_example": false, "text": "The encoding for the RA and RC registers occur in their usual fields and the opcode field is set to 2."}, {"start": "00:06:42", "is_lecture": true, "end": "00:06:45", "is_worked_example": false, "text": "Emulation is surprisingly simple."}, {"start": "00:06:45", "is_lecture": true, "end": "00:06:58", "is_worked_example": false, "text": "First we extract the RA and RC fields from the binary for the swapreg instruction and convert those values into the appropriate byte offsets for accessing the temporary array of saved register values."}, {"start": "00:06:58", "is_lecture": true, "end": "00:07:06", "is_worked_example": false, "text": "Then we use RA and RC offsets to access the user-mode register values that have been saved in UserMState."}, {"start": "00:07:06", "is_lecture": true, "end": "00:07:18", "is_worked_example": false, "text": "We'll make the appropriate interchange, leaving the updated register values in UserMState, where they'll be loaded into the CPU registers upon returning from the illegal instruction interrupt handler."}, {"start": "00:07:18", "is_lecture": true, "end": "00:07:25", "is_worked_example": false, "text": "Finally, we'll branch to the kernel code that restores the process state and resumes execution."}, {"start": "00:07:25", "is_lecture": true, "end": "00:07:28", "is_worked_example": false, "text": "We'll see this code in the next segment."}]}, "C05S01B08-LEC.srt": {"url": "https://courses.edx.org/courses/course-v1:MITx+6.004.3x+2T2016/courseware/c5/c5s1/8?activate_block_id=block-v1%3AMITx%2B6.004.3x%2B2T2016%2Btype%40discussion%2Bblock%40c5s1v8", "items": [{"start": "00:00:00", "is_lecture": true, "end": "00:00:12", "is_worked_example": false, "text": "The page map provides the context for interpreting virtual addresses, i.e., it provides the information needed to correctly determine where to find a virtual address in main memory or secondary storage."}, {"start": "00:00:12", "is_lecture": true, "end": "00:00:19", "is_worked_example": false, "text": "Several programs may be simultaneously loaded into main memory, each with its own context."}, {"start": "00:00:19", "is_lecture": true, "end": "00:00:24", "is_worked_example": false, "text": "Note that the separate contexts ensure that the programs don't interfere which each other."}, {"start": "00:00:24", "is_lecture": true, "end": "00:00:35", "is_worked_example": false, "text": "For example, the physical location for virtual address 0 in one program will be different than the physical location for virtual address 0 in another program."}, {"start": "00:00:35", "is_lecture": true, "end": "00:00:41", "is_worked_example": false, "text": "Each program operates independently in its own virtual address space."}, {"start": "00:00:41", "is_lecture": true, "end": "00:00:48", "is_worked_example": false, "text": "It's the context provided by the page map that allows them to coexist and share a common physical memory."}, {"start": "00:00:48", "is_lecture": true, "end": "00:00:52", "is_worked_example": false, "text": "So we need to switch contexts when switching programs."}, {"start": "00:00:52", "is_lecture": true, "end": "00:00:55", "is_worked_example": false, "text": "This is accomplished by reloading the page map."}, {"start": "00:00:55", "is_lecture": true, "end": "00:01:08", "is_worked_example": false, "text": "In a timesharing system, the CPU will periodically switch from running one program to another, giving the illusion that multiple programs are each running on their own virtual machine."}, {"start": "00:01:08", "is_lecture": true, "end": "00:01:13", "is_worked_example": false, "text": "This is accomplished by switching contexts when switching the CPU state to the next program."}, {"start": "00:01:13", "is_lecture": true, "end": "00:01:28", "is_worked_example": false, "text": "There's a privileged set of code called the operating system (OS) that manages the sharing of one physical processor and main memory amongst many programs, each with its own CPU state and virtual address space."}, {"start": "00:01:28", "is_lecture": true, "end": "00:01:37", "is_worked_example": false, "text": "The OS is effectively creating many virtual machines and choreographing their execution using a single set of shared physical resources."}, {"start": "00:01:37", "is_lecture": true, "end": "00:01:43", "is_worked_example": false, "text": "The OS runs in a special OS context, which we call the kernel."}, {"start": "00:01:43", "is_lecture": true, "end": "00:01:48", "is_worked_example": false, "text": "The OS contains the necessary exception handlers and timesharing support."}, {"start": "00:01:48", "is_lecture": true, "end": "00:01:57", "is_worked_example": false, "text": "Since it has to manage physical memory, it's allowed to access any physical location as it deals with page faults, etc."}, {"start": "00:01:57", "is_lecture": true, "end": "00:02:05", "is_worked_example": false, "text": "Exceptions in running programs cause the hardware to switch to the kernel context, which we call entering \"kernel mode\"."}, {"start": "00:02:05", "is_lecture": true, "end": "00:02:12", "is_worked_example": false, "text": "After the exception handling is complete, execution of the program resumes in what we call \"user mode\"."}, {"start": "00:02:12", "is_lecture": true, "end": "00:02:20", "is_worked_example": false, "text": "Since the OS runs in kernel mode it has privileged access to many hardware registers that are inaccessible in user mode."}, {"start": "00:02:20", "is_lecture": true, "end": "00:02:24", "is_worked_example": false, "text": "These include the MMU state, I/O devices, and so on."}, {"start": "00:02:24", "is_lecture": true, "end": "00:02:38", "is_worked_example": false, "text": "User-mode programs that need to access, say, the disk, need to make a request to the OS kernel to perform the operation, giving the OS the chance to vet the request for appropriate permissions, etc."}, {"start": "00:02:38", "is_lecture": true, "end": "00:02:41", "is_worked_example": false, "text": "We'll see how all of this works in an upcoming lecture."}, {"start": "00:02:41", "is_lecture": true, "end": "00:02:51", "is_worked_example": false, "text": "User-mode programs (aka applications) are written as if they have access to the entire virtual address space."}, {"start": "00:02:51", "is_lecture": true, "end": "00:03:00", "is_worked_example": false, "text": "They often obey the same conventions such as the address of the first instruction in the program, the initial value for the stack pointer, etc."}, {"start": "00:03:00", "is_lecture": true, "end": "00:03:13", "is_worked_example": false, "text": "Since all these virtual addresses are interpreted using the current context, by controlling the contexts the OS can ensure that the programs can coexist without conflict."}, {"start": "00:03:13", "is_lecture": true, "end": "00:03:20", "is_worked_example": false, "text": "The diagram on the right shows a standard plan for organizing the virtual address space of an application."}, {"start": "00:03:20", "is_lecture": true, "end": "00:03:31", "is_worked_example": false, "text": "Typically the first virtual page is made inaccessible, which helps catch errors involving references to initialized (i.e., zero-valued) pointers."}, {"start": "00:03:31", "is_lecture": true, "end": "00:03:39", "is_worked_example": false, "text": "Then come some number of read-only pages that hold the application's code and perhaps the code from any shared libraries it uses."}, {"start": "00:03:39", "is_lecture": true, "end": "00:03:47", "is_worked_example": false, "text": "Marking code pages as read-only avoids hard-to-find bugs where errant data accesses inadvertently change the program!"}, {"start": "00:03:47", "is_lecture": true, "end": "00:03:53", "is_worked_example": false, "text": "Then there are read-write pages holding the application's statically allocated data structures."}, {"start": "00:03:53", "is_lecture": true, "end": "00:04:00", "is_worked_example": false, "text": "The rest of the virtual address space is divided between two data regions that can grow over time."}, {"start": "00:04:00", "is_lecture": true, "end": "00:04:06", "is_worked_example": false, "text": "The first is the application's stack, used to hold procedure activation records."}, {"start": "00:04:06", "is_lecture": true, "end": "00:04:14", "is_worked_example": false, "text": "Here we show it located at the lower end of the virtual address space since our convention is that the stack grows towards higher addresses."}, {"start": "00:04:14", "is_lecture": true, "end": "00:04:22", "is_worked_example": false, "text": "The other growable region is the heap, used when dynamically allocating storage for long-lived data structures."}, {"start": "00:04:22", "is_lecture": true, "end": "00:04:30", "is_worked_example": false, "text": "\"Dynamically\" means that the allocation and deallocation of objects is done by explicit procedure calls while the application is running."}, {"start": "00:04:30", "is_lecture": true, "end": "00:04:26", "is_worked_example": false, "text": "In other words, we don't know which objects will be created until the program actually executes."}, {"start": "00:04:26", "is_lecture": true, "end": "00:04:41", "is_worked_example": false, "text": "As shown here, as the heap expands it grows towards lower addresses."}, {"start": "00:04:41", "is_lecture": true, "end": "00:04:47", "is_worked_example": false, "text": "The page fault handler knows to allocate new pages when these regions grow."}, {"start": "00:04:47", "is_lecture": true, "end": "00:04:57", "is_worked_example": false, "text": "Of course, if they ever meet somewhere in the middle and more space is needed, the application is out of luck -- it's run out of virtual memory!"}]}, "C06S01B01-LEC.srt": {"url": "https://courses.edx.org/courses/course-v1:MITx+6.004.3x+2T2016/courseware/c6/c6s1/1?activate_block_id=block-v1%3AMITx%2B6.004.3x%2B2T2016%2Btype%40discussion%2Bblock%40c6s1v1", "items": [{"start": "00:00:00", "is_lecture": true, "end": "00:00:13", "is_worked_example": false, "text": "In the last lecture we introduced the notion of virtual memory and added a Memory Management Unit (MMU) to translate the virtual addresses generated by the CPU to the physical addresses sent to main memory."}, {"start": "00:00:13", "is_lecture": true, "end": "00:00:23", "is_worked_example": false, "text": "This gave us the ability to share physical memory between many running programs while still giving each program the illusion of having its own large address space."}, {"start": "00:00:23", "is_lecture": true, "end": "00:00:32", "is_worked_example": false, "text": "Both the virtual and physical address spaces are divided into a sequence of pages, each holding some fixed number of locations."}, {"start": "00:00:32", "is_lecture": true, "end": "00:00:43", "is_worked_example": false, "text": "For example if each page holds 2^12 bytes, a 32-bit address would have 2^32/2^12 = 2^20 pages."}, {"start": "00:00:43", "is_lecture": true, "end": "00:00:57", "is_worked_example": false, "text": "In this example the 32-bit address can be thought of as having two fields: a 20-bit page number formed from the high-order address bits and a 12-bit page offset formed from the low-order address bits."}, {"start": "00:00:57", "is_lecture": true, "end": "00:01:02", "is_worked_example": false, "text": "This arrangement ensures that nearby data will be located on the same page."}, {"start": "00:01:02", "is_lecture": true, "end": "00:01:10", "is_worked_example": false, "text": "The MMU translates virtual page numbers into physical page numbers using a page map."}, {"start": "00:01:10", "is_lecture": true, "end": "00:01:20", "is_worked_example": false, "text": "Conceptually the page map is an array where each entry in the array contains a physical page number along with a couple of bits indicating the page status."}, {"start": "00:01:20", "is_lecture": true, "end": "00:01:30", "is_worked_example": false, "text": "The translation process is simple: the virtual page number is used as an index into the array to fetch the corresponding physical page number."}, {"start": "00:01:30", "is_lecture": true, "end": "00:01:37", "is_worked_example": false, "text": "The physical page number is then combined with the page offset to form the complete physical address."}, {"start": "00:01:37", "is_lecture": true, "end": "00:01:48", "is_worked_example": false, "text": "In the actual implementation the page map is usually organized into multiple levels, which permits us to have resident only the portion of the page map we're actively using."}, {"start": "00:01:48", "is_lecture": true, "end": "00:02:03", "is_worked_example": false, "text": "And to avoid the costs of accessing the page map on each address translation, we use a cache (called the translation look-aside buffer) to remember the results of recent vpn-to-ppn translations."}, {"start": "00:02:03", "is_lecture": true, "end": "00:02:09", "is_worked_example": false, "text": "All allocated locations of each virtual address space can be found on secondary storage."}, {"start": "00:02:09", "is_lecture": true, "end": "00:02:14", "is_worked_example": false, "text": "Note that they may not necessarily be resident in main memory."}, {"start": "00:02:14", "is_lecture": true, "end": "00:02:27", "is_worked_example": false, "text": "If the CPU attempts to access a virtual address that's not resident in main memory, a page fault is signaled and the operating system will arrange to move the desired page from secondary storage into main memory."}, {"start": "00:02:27", "is_lecture": true, "end": "00:02:34", "is_worked_example": false, "text": "In practice, only the active pages for each program are resident in main memory at any given time."}, {"start": "00:02:34", "is_lecture": true, "end": "00:02:39", "is_worked_example": false, "text": "Here's a diagram showing the translation process."}, {"start": "00:02:39", "is_lecture": true, "end": "00:02:44", "is_worked_example": false, "text": "First we check to see if the required vpn-to-ppn mapping is cached in the TLB."}, {"start": "00:02:44", "is_lecture": true, "end": "00:02:53", "is_worked_example": false, "text": "If not, we have to access the hierarchical page map to see if the page is resident and, if so, lookup its physical page number."}, {"start": "00:02:53", "is_lecture": true, "end": "00:03:03", "is_worked_example": false, "text": "If we discover that the page is not resident, a page fault exception is signaled to the CPU so that it can run a handler to load the page from secondary storage."}, {"start": "00:03:03", "is_lecture": true, "end": "00:03:09", "is_worked_example": false, "text": "Note that access to a particular mapping context is controlled by two registers."}, {"start": "00:03:09", "is_lecture": true, "end": "00:03:13", "is_worked_example": false, "text": "The context-number register controls which mappings are accessible in the TLB."}, {"start": "00:03:13", "is_lecture": true, "end": "00:03:21", "is_worked_example": false, "text": "And the page-directory register indicates which physical page holds the top tier of the hierarchical page map."}, {"start": "00:03:21", "is_lecture": true, "end": "00:03:26", "is_worked_example": false, "text": "We can switch to another context by simply reloading these two registers."}, {"start": "00:03:26", "is_lecture": true, "end": "00:03:37", "is_worked_example": false, "text": "To effectively accommodate multiple contexts we'll need to have sufficient TLB capacity to simultaneously cache the most frequent mappings for all the processes."}, {"start": "00:03:37", "is_lecture": true, "end": "00:03:43", "is_worked_example": false, "text": "And we'll need some number of physical pages to hold the required page directories and segments of the page tables."}, {"start": "00:03:43", "is_lecture": true, "end": "00:03:55", "is_worked_example": false, "text": "For example, for a particular process, three pages will suffice hold the resident two-level page map for 1024 pages at each end of the virtual address space,"}, {"start": "00:03:55", "is_lecture": true, "end": "00:04:03", "is_worked_example": false, "text": "providing access to up to 8MB of code, stack, and heap, more than enough for many simple programs."}, {"start": "00:04:03", "is_lecture": true, "end": "00:04:09", "is_worked_example": false, "text": "The page map creates the context needed to translate virtual addresses to physical addresses."}, {"start": "00:04:09", "is_lecture": true, "end": "00:04:19", "is_worked_example": false, "text": "In a computer system that's working on multiple tasks at the same time, we would like to support multiple contexts and to be able to quickly switch from one context to another."}, {"start": "00:04:19", "is_lecture": true, "end": "00:04:26", "is_worked_example": false, "text": "Multiple contexts would allow us to share physical memory between multiple programs."}, {"start": "00:04:26", "is_lecture": true, "end": "00:04:41", "is_worked_example": false, "text": "Each program would have an independent virtual address space, e.g., two programs could both access virtual address 0 as the address of their first instruction and would end up accessing different physical locations in main memory."}, {"start": "00:04:41", "is_lecture": true, "end": "00:04:48", "is_worked_example": false, "text": "When switching between programs, we'd perform a \"context switch\" to move to the appropriate MMU context."}, {"start": "00:04:48", "is_lecture": true, "end": "00:04:53", "is_worked_example": false, "text": "The ability to share the CPU between many programs seems like a great idea!"}, {"start": "00:04:53", "is_lecture": true, "end": "00:04:57", "is_worked_example": false, "text": "Let's figure out the details of how that might work..."}]}, "C06S01B02-LEC.srt": {"url": "https://courses.edx.org/courses/course-v1:MITx+6.004.3x+2T2016/courseware/c6/c6s1/2?activate_block_id=block-v1%3AMITx%2B6.004.3x%2B2T2016%2Btype%40discussion%2Bblock%40c6s1v2", "items": [{"start": "00:00:00", "is_lecture": true, "end": "00:00:05", "is_worked_example": false, "text": "Let's create a new abstraction called a \"process\" to capture the notion of a running program."}, {"start": "00:00:05", "is_lecture": true, "end": "00:00:15", "is_worked_example": false, "text": "A process encompasses all the resources that would be used when running a program including those of the CPU, the MMU, input and output devices, etc."}, {"start": "00:00:15", "is_lecture": true, "end": "00:00:20", "is_worked_example": false, "text": "Each process has a \"state\" that captures everything we know about its execution."}, {"start": "00:00:20", "is_lecture": true, "end": "00:00:22", "is_worked_example": false, "text": "The process state includes"}, {"start": "00:00:22", "is_lecture": true, "end": "00:00:28", "is_worked_example": false, "text": "* the hardware state of the CPU, i.e., the values in the registers and program counter."}, {"start": "00:00:28", "is_lecture": true, "end": "00:00:37", "is_worked_example": false, "text": "* the contents of the process' virtual address space, including code, data values, the stack, and data objects dynamically allocated from the heap."}, {"start": "00:00:37", "is_lecture": true, "end": "00:00:45", "is_worked_example": false, "text": "Under the management of the MMU, this portion of the state can be resident in main memory or can reside in secondary storage."}, {"start": "00:00:45", "is_lecture": true, "end": "00:00:53", "is_worked_example": false, "text": "* the hardware state of the MMU, which, as we saw earlier, depends on the context-number and page-directory registers."}, {"start": "00:00:53", "is_lecture": true, "end": "00:00:57", "is_worked_example": false, "text": "Also included are the pages allocated for the hierarchical page map."}, {"start": "00:00:57", "is_lecture": true, "end": "00:01:06", "is_worked_example": false, "text": "* additional information about the process' input and output activities, such as where it has reached in reading or writing files in the file system,"}, {"start": "00:01:06", "is_lecture": true, "end": "00:01:10", "is_worked_example": false, "text": "the status and buffers associated with open network connections,"}, {"start": "00:01:10", "is_lecture": true, "end": "00:01:16", "is_worked_example": false, "text": "pending events from the user interface (e.g., keyboard characters and mouse clicks), and so on."}, {"start": "00:01:16", "is_lecture": true, "end": "00:01:25", "is_worked_example": false, "text": "As we'll see, there is a special, privileged process, called the operating system (OS), running in its own kernel-mode context."}, {"start": "00:01:25", "is_lecture": true, "end": "00:01:32", "is_worked_example": false, "text": "The OS manages all the bookkeeping for each process, arranging for the process run periodically."}, {"start": "00:01:32", "is_lecture": true, "end": "00:01:44", "is_worked_example": false, "text": "The OS will provide various services to the processes, such as accessing data in files, establishing network connections, managing the window system and user interface, and so on."}, {"start": "00:01:44", "is_lecture": true, "end": "00:01:53", "is_worked_example": false, "text": "To switch from running one user-mode process to another, the OS will need to capture and save the *entire* state of the current user-mode process."}, {"start": "00:01:53", "is_lecture": true, "end": "00:01:57", "is_worked_example": false, "text": "Some of it already lives in main memory, so we're all set there."}, {"start": "00:01:57", "is_lecture": true, "end": "00:02:01", "is_worked_example": false, "text": "Some of it will be found in various kernel data structures."}, {"start": "00:02:01", "is_lecture": true, "end": "00:02:08", "is_worked_example": false, "text": "And some of it we'll need to be able to save and restore from the various hardware resources in the CPU and MMU."}, {"start": "00:02:08", "is_lecture": true, "end": "00:02:23", "is_worked_example": false, "text": "In order to successfully implement processes, the OS must be able to make it seem as if each process was running on its own \"virtual machine\" that works independently of other virtual machines for other processes."}, {"start": "00:02:23", "is_lecture": true, "end": "00:02:30", "is_worked_example": false, "text": "Our goal is to efficiently share one physical machine between all the virtual machines."}, {"start": "00:02:30", "is_lecture": true, "end": "00:02:33", "is_worked_example": false, "text": "Here's a sketch of the organization we're proposing."}, {"start": "00:02:33", "is_lecture": true, "end": "00:02:38", "is_worked_example": false, "text": "The resources provided by a physical machine are shown at the bottom of the slide."}, {"start": "00:02:38", "is_lecture": true, "end": "00:02:43", "is_worked_example": false, "text": "The CPU and main memory form the computation engine at heart of the system."}, {"start": "00:02:43", "is_lecture": true, "end": "00:02:53", "is_worked_example": false, "text": "Connected to the CPU are various peripherals, a collective noun coined from the English word \"periphery\" that indicates the resources surrounding the CPU."}, {"start": "00:02:53", "is_lecture": true, "end": "00:02:59", "is_worked_example": false, "text": "A timer generates periodic CPU interrupts that can be used to trigger periodic actions."}, {"start": "00:02:59", "is_lecture": true, "end": "00:03:05", "is_worked_example": false, "text": "Secondary storage provides high-capacity non-volatile memories for the system."}, {"start": "00:03:05", "is_lecture": true, "end": "00:03:08", "is_worked_example": false, "text": "Connections to the outside world are important too."}, {"start": "00:03:08", "is_lecture": true, "end": "00:03:12", "is_worked_example": false, "text": "Many computers include USB connections for removable devices."}, {"start": "00:03:12", "is_lecture": true, "end": "00:03:16", "is_worked_example": false, "text": "And most provide wired or wireless network connections."}, {"start": "00:03:16", "is_lecture": true, "end": "00:03:23", "is_worked_example": false, "text": "And finally there are usually video monitors, keyboards and mice that serve as the user interface."}, {"start": "00:03:23", "is_lecture": true, "end": "00:03:28", "is_worked_example": false, "text": "Cameras and microphones are becoming increasing important as the next generation of user interface."}, {"start": "00:03:28", "is_lecture": true, "end": "00:03:35", "is_worked_example": false, "text": "The physical machine is managed by the OS running in the privileged kernel context."}, {"start": "00:03:35", "is_lecture": true, "end": "00:03:43", "is_worked_example": false, "text": "The OS handles the low-level interfaces to the peripherals, initializes and manages the MMU contexts, and so on."}, {"start": "00:03:43", "is_lecture": true, "end": "00:03:48", "is_worked_example": false, "text": "It's the OS that creates the virtual machine seen by each process."}, {"start": "00:03:48", "is_lecture": true, "end": "00:03:54", "is_worked_example": false, "text": "User-mode programs run directly on the physical processor, but their execution can be interrupted by the timer,"}, {"start": "00:03:54", "is_lecture": true, "end": "00:04:01", "is_worked_example": false, "text": "giving the OS the opportunity to save away the current process state and move to running the next process."}, {"start": "00:04:01", "is_lecture": true, "end": "00:04:11", "is_worked_example": false, "text": "Via the MMU, the OS provides each process with an independent virtual address space that's isolated from the actions of other processes."}, {"start": "00:04:11", "is_lecture": true, "end": "00:04:19", "is_worked_example": false, "text": "The virtual peripherals provided by the OS isolate the process from all the details of sharing resources with other processes."}, {"start": "00:04:19", "is_lecture": true, "end": "00:04:28", "is_worked_example": false, "text": "The notion of a window allows the process to access a rectangular array of pixels without having to worry if some pixels in the window are hidden by other windows."}, {"start": "00:04:28", "is_lecture": true, "end": "00:04:35", "is_worked_example": false, "text": "Or worrying about how to ensure the mouse cursor always appears on top of whatever is being displayed, and so on."}, {"start": "00:04:35", "is_lecture": true, "end": "00:04:46", "is_worked_example": false, "text": "Instead of accessing I/O devices directly, each process has access to a stream of I/O events that are generated when a character is typed, the mouse is clicked, etc."}, {"start": "00:04:46", "is_lecture": true, "end": "00:04:53", "is_worked_example": false, "text": "For example, the OS deals with how to determine which typed characters belong to which process."}, {"start": "00:04:53", "is_lecture": true, "end": "00:05:03", "is_worked_example": false, "text": "In most window systems, the user clicks on a window to indicate that the process that owns the window now has the keyboard focus and should receive any subsequent typed characters."}, {"start": "00:05:03", "is_lecture": true, "end": "00:05:08", "is_worked_example": false, "text": "And the position of the mouse when clicked might determine which process receives the click."}, {"start": "00:05:08", "is_lecture": true, "end": "00:05:17", "is_worked_example": false, "text": "All of which is to say that the details of sharing have been abstracted out of the simple interface provided by the virtual peripherals."}, {"start": "00:05:17", "is_lecture": true, "end": "00:05:21", "is_worked_example": false, "text": "The same is true of accessing files on disk."}, {"start": "00:05:21", "is_lecture": true, "end": "00:05:30", "is_worked_example": false, "text": "The OS provides the useful abstraction of having each file appear as a contiguous, growable array of bytes that supports read and write operations."}, {"start": "00:05:30", "is_lecture": true, "end": "00:05:42", "is_worked_example": false, "text": "The OS knows how the file is mapped to a pool of sectors on the disk and deals with bad sectors, reducing fragmentation, and improving throughput by doing read look-aheads and write behinds."}, {"start": "00:05:42", "is_lecture": true, "end": "00:05:50", "is_worked_example": false, "text": "For networks, the OS provides access to an in-order stream of bytes to some remote socket."}, {"start": "00:05:50", "is_lecture": true, "end": "00:05:59", "is_worked_example": false, "text": "It implements the appropriate network protocols for packetizing the stream, addressing the packets, and dealing with dropped, damaged, or out-of-order packets."}, {"start": "00:05:59", "is_lecture": true, "end": "00:06:12", "is_worked_example": false, "text": "To configure and control these virtual services, the process communicates with the OS using supervisor calls (SVCs), a type of controlled-access procedure call that invokes code in the OS kernel."}, {"start": "00:06:12", "is_lecture": true, "end": "00:06:18", "is_worked_example": false, "text": "The details of the design and implementation of each virtual service are beyond the scope of this course."}, {"start": "00:06:18", "is_lecture": true, "end": "00:06:24", "is_worked_example": false, "text": "If you're interested, a course on operating systems will explore each of these topics in detail."}, {"start": "00:06:24", "is_lecture": true, "end": "00:06:34", "is_worked_example": false, "text": "The OS provides an independent virtual machine for each process, periodically switching from running one process to running the next process."}, {"start": "00:06:34", "is_lecture": true, "end": "00:06:39", "is_worked_example": false, "text": "Let's follow along as we switch from running process #0 to running process #1."}, {"start": "00:06:39", "is_lecture": true, "end": "00:06:44", "is_worked_example": false, "text": "Initially, the CPU is executing user-mode code in process #0."}, {"start": "00:06:44", "is_lecture": true, "end": "00:06:52", "is_worked_example": false, "text": "That execution is interrupted, either by an explicit yield by the program, or, more likely, by a timer interrupt."}, {"start": "00:06:52", "is_lecture": true, "end": "00:07:01", "is_worked_example": false, "text": "Either ends up transferring control to OS code running in kernel mode, while saving the current PC+4 value in the XP register."}, {"start": "00:07:01", "is_lecture": true, "end": "00:07:05", "is_worked_example": false, "text": "We'll talk about the interrupt mechanism in more detail in just a moment."}, {"start": "00:07:05", "is_lecture": true, "end": "00:07:10", "is_worked_example": false, "text": "The OS saves the state of process #0 in the appropriate table in kernel storage."}, {"start": "00:07:10", "is_lecture": true, "end": "00:07:14", "is_worked_example": false, "text": "Then it reloads the state from the kernel table for process #1."}, {"start": "00:07:14", "is_lecture": true, "end": "00:07:20", "is_worked_example": false, "text": "Note that the process #1 state was saved when process #1 was interrupted at some earlier point."}, {"start": "00:07:20", "is_lecture": true, "end": "00:07:26", "is_worked_example": false, "text": "The OS then uses a JMP() to resume user-mode execution using the newly restored process #1 state."}, {"start": "00:07:26", "is_lecture": true, "end": "00:07:32", "is_worked_example": false, "text": "Execution resumes in process #1 just where it was when interrupted earlier."}, {"start": "00:07:32", "is_lecture": true, "end": "00:07:37", "is_worked_example": false, "text": "And now we're running the user-mode program in process #1."}, {"start": "00:07:37", "is_lecture": true, "end": "00:07:42", "is_worked_example": false, "text": "We've interrupted one process and resumed execution of another."}, {"start": "00:07:42", "is_lecture": true, "end": "00:07:50", "is_worked_example": false, "text": "We'll keep doing this in a round-robin fashion, giving each process a chance to run, before starting another round of execution."}, {"start": "00:07:50", "is_lecture": true, "end": "00:07:54", "is_worked_example": false, "text": "The black arrows give a sense for how time proceeds."}, {"start": "00:07:54", "is_lecture": true, "end": "00:08:00", "is_worked_example": false, "text": "For each process, virtual time unfolds as a sequence of executed instructions."}, {"start": "00:08:00", "is_lecture": true, "end": "00:08:07", "is_worked_example": false, "text": "Unless it looks at a real-time clock, a process is unaware that occasionally its execution is suspended for a while."}, {"start": "00:08:07", "is_lecture": true, "end": "00:08:12", "is_worked_example": false, "text": "The suspension and resumption are completely transparent to a running process."}, {"start": "00:08:12", "is_lecture": true, "end": "00:08:26", "is_worked_example": false, "text": "Of course, from the outside we can see that in real time, the execution path moves from process to process, visiting the OS during switches, producing the dove-tailed execution path we see here."}, {"start": "00:08:26", "is_lecture": true, "end": "00:08:35", "is_worked_example": false, "text": "Time-multiplexing of the CPU is called \"timesharing\" and we'll examine the implementation in more detail in the following segment."}]}, "C03S01B03-LEC.srt": {"url": "https://courses.edx.org/courses/course-v1:MITx+6.004.3x+2T2016/courseware/c3/c3s1/3?activate_block_id=block-v1%3AMITx%2B6.004.3x%2B2T2016%2Btype%40discussion%2Bblock%40c3s1v3", "items": [{"start": "00:00:00", "is_lecture": true, "end": "00:00:10", "is_worked_example": false, "text": "The data path diagram isn't all that useful in diagramming the pipelined execution of an instruction sequence since we need a new copy of the diagram for each clock cycle."}, {"start": "00:00:10", "is_lecture": true, "end": "00:00:19", "is_worked_example": false, "text": "A more compact and easier-to-read diagram of pipelined execution is provided by the pipeline diagrams we met back in Part 1 of the course."}, {"start": "00:00:19", "is_lecture": true, "end": "00:00:27", "is_worked_example": false, "text": "There's one row in the diagram for each pipeline stage and one column for each cycle of execution."}, {"start": "00:00:27", "is_lecture": true, "end": "00:00:34", "is_worked_example": false, "text": "Entries in the table show which instruction is in each pipeline stage at each cycle."}, {"start": "00:00:34", "is_lecture": true, "end": "00:00:41", "is_worked_example": false, "text": "In normal operation, a particular instruction moves diagonally through the diagram as it proceeds through the five pipeline stages."}, {"start": "00:00:41", "is_lecture": true, "end": "00:00:49", "is_worked_example": false, "text": "To understand data hazards, let's first remind ourselves of when the register file is read and written for a particular instruction."}, {"start": "00:00:49", "is_lecture": true, "end": "00:00:58", "is_worked_example": false, "text": "Register reads happen when the instruction is in the RF stage, i.e., when we're reading the instruction's register operands."}, {"start": "00:00:58", "is_lecture": true, "end": "00:01:03", "is_worked_example": false, "text": "Register writes happen at the end of the cycle when the instruction is in the WB stage."}, {"start": "00:01:03", "is_lecture": true, "end": "00:01:12", "is_worked_example": false, "text": "For example, for the first LD instruction, we read R1 during cycle 2 and write R2 at the end of cycle 5."}, {"start": "00:01:12", "is_lecture": true, "end": "00:01:17", "is_worked_example": false, "text": "Or consider the register file operations in cycle 6:"}, {"start": "00:01:17", "is_lecture": true, "end": "00:01:28", "is_worked_example": false, "text": "we're reading R12 and R13 for the MUL instruction in the RF stage, and writing R4 at the end of the cycle for the LD instruction in the WB stage."}, {"start": "00:01:28", "is_lecture": true, "end": "00:01:32", "is_worked_example": false, "text": "Okay, now let's see what happens when there are data hazards."}, {"start": "00:01:32", "is_lecture": true, "end": "00:01:40", "is_worked_example": false, "text": "In this instruction sequence, the ADDC instruction writes its result in R2, which is immediately read by the following SUBC instruction."}, {"start": "00:01:40", "is_lecture": true, "end": "00:01:46", "is_worked_example": false, "text": "Correct execution of the SUBC instruction clearly depends on the results of the ADDC instruction."}, {"start": "00:01:46", "is_lecture": true, "end": "00:01:50", "is_worked_example": false, "text": "This what we'd call a read-after-write dependency."}, {"start": "00:01:50", "is_lecture": true, "end": "00:02:00", "is_worked_example": false, "text": "This pipeline diagram shows the cycle-by-cycle execution where we've circled the cycles during which ADDC writes R2 and SUBC reads R2."}, {"start": "00:02:00", "is_lecture": true, "end": "00:02:01", "is_worked_example": false, "text": "Oops!"}, {"start": "00:02:01", "is_lecture": true, "end": "00:02:09", "is_worked_example": false, "text": "ADDC doesn't write R2 until the end of cycle 5, but SUBC is trying to read the R2 value in cycle 3."}, {"start": "00:02:09", "is_lecture": true, "end": "00:02:17", "is_worked_example": false, "text": "The value in R2 in the register file in cycle 3 doesn't yet reflect the execution of the ADDC instruction."}, {"start": "00:02:17", "is_lecture": true, "end": "00:02:23", "is_worked_example": false, "text": "So as things stand the pipeline would *not* correctly execute this instruction sequence."}, {"start": "00:02:23", "is_lecture": true, "end": "00:02:27", "is_worked_example": false, "text": "This instruction sequence has triggered a data hazard."}, {"start": "00:02:27", "is_lecture": true, "end": "00:02:35", "is_worked_example": false, "text": "We want the pipelined CPU to generate the same program results as the unpipelined CPU, so we'll need to figure out a fix."}, {"start": "00:02:35", "is_lecture": true, "end": "00:02:40", "is_worked_example": false, "text": "There are three general strategies we can pursue to fix pipeline hazards."}, {"start": "00:02:40", "is_lecture": true, "end": "00:02:48", "is_worked_example": false, "text": "Any of the techniques will work, but as we'll see they have different tradeoffs for instruction throughput and circuit complexity."}, {"start": "00:02:48", "is_lecture": true, "end": "00:02:56", "is_worked_example": false, "text": "The first strategy is to stall instructions in the RF stage until the result they need has been written to the register file."}, {"start": "00:02:56", "is_lecture": true, "end": "00:03:04", "is_worked_example": false, "text": "\"Stall\" means that we don't reload the instruction register at the end of the cycle, so we'll try to execute the same instruction in the next cycle."}, {"start": "00:03:04", "is_lecture": true, "end": "00:03:11", "is_worked_example": false, "text": "If we stall one pipeline stage, all earlier stages must also be stalled since they are blocked by the stalled instruction."}, {"start": "00:03:11", "is_lecture": true, "end": "00:03:17", "is_worked_example": false, "text": "If an instruction is stalled in the RF stage, then the IF stage is also stalled."}, {"start": "00:03:17", "is_lecture": true, "end": "00:03:23", "is_worked_example": false, "text": "Stalling will always work, but has a negative impact on instruction throughput."}, {"start": "00:03:23", "is_lecture": true, "end": "00:03:29", "is_worked_example": false, "text": "Stall for too many cycles and you'll loose the performance advantages of pipelined execution!"}, {"start": "00:03:29", "is_lecture": true, "end": "00:03:36", "is_worked_example": false, "text": "The second strategy is to route the needed value to earlier pipeline stages as soon as its computed."}, {"start": "00:03:36", "is_lecture": true, "end": "00:03:39", "is_worked_example": false, "text": "This called bypassing or forwarding."}, {"start": "00:03:39", "is_lecture": true, "end": "00:03:47", "is_worked_example": false, "text": "As it turns out, the value we need often exists somewhere in the pipelined data path, it just hasn't been written yet to the register file."}, {"start": "00:03:47", "is_lecture": true, "end": "00:03:53", "is_worked_example": false, "text": "If the value exists and can be forwarded to where it's needed, we won't need to stall."}, {"start": "00:03:53", "is_lecture": true, "end": "00:03:58", "is_worked_example": false, "text": "We'll be able to use this strategy to avoid stalling on most types of data hazards."}, {"start": "00:03:58", "is_lecture": true, "end": "00:04:02", "is_worked_example": false, "text": "The third strategy is called speculation."}, {"start": "00:04:02", "is_lecture": true, "end": "00:04:06", "is_worked_example": false, "text": "We'll make an intelligent guess for the needed value and continue execution."}, {"start": "00:04:06", "is_lecture": true, "end": "00:04:11", "is_worked_example": false, "text": "Once the actual value is determined, if we guessed correctly, we're all set."}, {"start": "00:04:11", "is_lecture": true, "end": "00:04:18", "is_worked_example": false, "text": "If we guessed incorrectly, we have to back up execution and restart with the correct value."}, {"start": "00:04:18", "is_lecture": true, "end": "00:04:23", "is_worked_example": false, "text": "Obviously speculation only makes sense if it's possible to make accurate guesses."}, {"start": "00:04:23", "is_lecture": true, "end": "00:04:28", "is_worked_example": false, "text": "We'll be able to use this strategy to avoid stalling on control hazards."}, {"start": "00:04:28", "is_lecture": true, "end": "00:04:33", "is_worked_example": false, "text": "Let's see how the first two strategies work when dealing with our data hazard."}, {"start": "00:04:33", "is_lecture": true, "end": "00:04:43", "is_worked_example": false, "text": "Applying the stall strategy to our data hazard, we need to stall the SUBC instruction in the RF stage until the ADDC instruction writes its result in R2."}, {"start": "00:04:43", "is_lecture": true, "end": "00:04:54", "is_worked_example": false, "text": "So in the pipeline diagram, SUBC is stalled three times in the RF stage until it can finally access the R2 value from the register file in cycle 6."}, {"start": "00:04:54", "is_lecture": true, "end": "00:05:00", "is_worked_example": false, "text": "Whenever the RF stage is stalled, the IF stage is also stalled."}, {"start": "00:05:00", "is_lecture": true, "end": "00:05:02", "is_worked_example": false, "text": "You can see that in the diagram too."}, {"start": "00:05:02", "is_lecture": true, "end": "00:05:07", "is_worked_example": false, "text": "But when RF is stalled, what should the ALU stage do in the next cycle?"}, {"start": "00:05:07", "is_lecture": true, "end": "00:05:13", "is_worked_example": false, "text": "The RF stage hasn't finished its job and so can't pass along its instruction!"}, {"start": "00:05:13", "is_lecture": true, "end": "00:05:23", "is_worked_example": false, "text": "The solution is for the RF stage to make-up an innocuous instruction for the ALU stage, what's called a NOP instruction, short for \"no operation\"."}, {"start": "00:05:23", "is_lecture": true, "end": "00:05:31", "is_worked_example": false, "text": "A NOP instruction has no effect on the CPU state, i.e., it doesn't change the contents of the register file or main memory."}, {"start": "00:05:31", "is_lecture": true, "end": "00:05:39", "is_worked_example": false, "text": "For example any OP-class or OPC-class instruction that has R31 as its destination register is a NOP."}, {"start": "00:05:39", "is_lecture": true, "end": "00:05:45", "is_worked_example": false, "text": "The NOPs introduced into the pipeline by the stalled RF stage are shown in red."}, {"start": "00:05:45", "is_lecture": true, "end": "00:05:52", "is_worked_example": false, "text": "Since the SUBC is stalled in the RF stage for three cycles, three NOPs are introduced into the pipeline."}, {"start": "00:05:52", "is_lecture": true, "end": "00:05:56", "is_worked_example": false, "text": "We sometimes refer to these NOPs as \"bubbles\" in the pipeline."}, {"start": "00:05:56", "is_lecture": true, "end": "00:06:00", "is_worked_example": false, "text": "How does the pipeline know when to stall?"}, {"start": "00:06:00", "is_lecture": true, "end": "00:06:13", "is_worked_example": false, "text": "It can compare the register numbers in the RA and RB fields of the instruction in the RF stage with the register numbers in the RC field of instructions in the ALU, MEM, and WB stage."}, {"start": "00:06:13", "is_lecture": true, "end": "00:06:20", "is_worked_example": false, "text": "If there's a match, there's a data hazard and the RF stage should be stalled."}, {"start": "00:06:20", "is_lecture": true, "end": "00:06:23", "is_worked_example": false, "text": "The stall will continue until there's no hazard detected."}, {"start": "00:06:23", "is_lecture": true, "end": "00:06:26", "is_worked_example": false, "text": "There are a few details to take care of:"}, {"start": "00:06:26", "is_lecture": true, "end": "00:06:39", "is_worked_example": false, "text": "some instructions don't read both registers, the ST instruction doesn't use its RC field, and we don't want R31 to match since it's always okay to read R31 from the register file."}, {"start": "00:06:39", "is_lecture": true, "end": "00:06:46", "is_worked_example": false, "text": "Stalling will ensure correct pipelined execution, but it does increase the effective CPI."}, {"start": "00:06:46", "is_lecture": true, "end": "00:06:55", "is_worked_example": false, "text": "This will lead to longer execution times if the increase in CPI is larger than the decrease in cycle time afforded by pipelining."}, {"start": "00:06:55", "is_lecture": true, "end": "00:07:01", "is_worked_example": false, "text": "To implement stalling, we only need to make two simple changes to our pipelined data path."}, {"start": "00:07:01", "is_lecture": true, "end": "00:07:14", "is_worked_example": false, "text": "We generate a new control signal, STALL, which, when asserted, disables the loading of the three pipeline registers at the input of the IF and RF stages, which means they'll have the same value next cycle as they do this cycle."}, {"start": "00:07:14", "is_lecture": true, "end": "00:07:20", "is_worked_example": false, "text": "We also introduce a mux to choose the instruction to be sent along to the ALU stage."}, {"start": "00:07:20", "is_lecture": true, "end": "00:07:27", "is_worked_example": false, "text": "If STALL is 1, we choose a NOP instruction, e.g., an ADD with R31 as its destination."}, {"start": "00:07:27", "is_lecture": true, "end": "00:07:33", "is_worked_example": false, "text": "If STALL is 0, the RF stage is not stalled, so we pass its current instruction to the ALU."}, {"start": "00:07:33", "is_lecture": true, "end": "00:07:38", "is_worked_example": false, "text": "And here we see how to compute STALL as described in the previous slide."}, {"start": "00:07:38", "is_lecture": true, "end": "00:07:49", "is_worked_example": false, "text": "The additional logic needed to implement stalling is pretty modest, so the real design tradeoff is about increased CPI due to stalling vs. decreased cycle time due to pipelining."}, {"start": "00:07:49", "is_lecture": true, "end": "00:07:55", "is_worked_example": false, "text": "So we have a solution, although it carries some potential performance costs."}, {"start": "00:07:55", "is_lecture": true, "end": "00:07:56", "is_worked_example": false, "text": "Now let's consider our second strategy:"}, {"start": "00:07:56", "is_lecture": true, "end": "00:08:04", "is_worked_example": false, "text": "bypassing, which is applicable if the data we need in the RF stage is somewhere in the pipelined data path."}, {"start": "00:08:04", "is_lecture": true, "end": "00:08:16", "is_worked_example": false, "text": "In our example, even though ADDC doesn't write R2 until the end of cycle 5, the value that will be written is computed during cycle 3 when the ADDC is in the ALU stage."}, {"start": "00:08:16", "is_lecture": true, "end": "00:08:24", "is_worked_example": false, "text": "In cycle 3, the output of the ALU is the value needed by the SUBC that's in the RF stage in the same cycle."}, {"start": "00:08:24", "is_lecture": true, "end": "00:08:41", "is_worked_example": false, "text": "So, if we detect that the RA field of the instruction in the RF stage is the same as the RC field of the instruction in the ALU stage, we can use the output of the ALU in place of the (stale) RA value being read from the register file."}, {"start": "00:08:41", "is_lecture": true, "end": "00:08:42", "is_worked_example": false, "text": "No stalling necessary!"}, {"start": "00:08:42", "is_lecture": true, "end": "00:08:51", "is_worked_example": false, "text": "In our example, in cycle 3 we want to route the output of the ALU to the RF stage to be used as the value for R2."}, {"start": "00:08:51", "is_lecture": true, "end": "00:08:59", "is_worked_example": false, "text": "We show this with a red \"bypass arrow\" showing data being routed from the ALU stage to the RF stage."}, {"start": "00:08:59", "is_lecture": true, "end": "00:09:09", "is_worked_example": false, "text": "To implement bypassing, we'll add a many-input multiplexer to the read ports of the register file so we can select the appropriate value from other pipeline stages."}, {"start": "00:09:09", "is_lecture": true, "end": "00:09:15", "is_worked_example": false, "text": "Here we show the combinational bypass paths from the ALU, MEM, and WB stages."}, {"start": "00:09:15", "is_lecture": true, "end": "00:09:24", "is_worked_example": false, "text": "For the bypassing example of the previous slides, we use the blue bypass path during cycle 3 to get the correct value for R2."}, {"start": "00:09:24", "is_lecture": true, "end": "00:09:40", "is_worked_example": false, "text": "The bypass muxes are controlled by logic that's matching the number of the source register to the number of the destination registers in the ALU, MEM, and WB stages, with the usual complications of dealing with R31."}, {"start": "00:09:40", "is_lecture": true, "end": "00:09:51", "is_worked_example": false, "text": "What if there are multiple matches, i.e., if the RF stage is trying to read a register that's the destination for, say, the instructions in both the ALU and MEM stages?"}, {"start": "00:09:51", "is_lecture": true, "end": "00:09:52", "is_worked_example": false, "text": "No problem!"}, {"start": "00:09:52", "is_lecture": true, "end": "00:10:05", "is_worked_example": false, "text": "We want to select the result from the most recent instruction, so we'd chose the ALU match if there is one, then the MEM match, then the WB match, then, finally, the output of the register file."}, {"start": "00:10:05", "is_lecture": true, "end": "00:10:09", "is_worked_example": false, "text": "Here's diagram showing all the bypass paths we'll need."}, {"start": "00:10:09", "is_lecture": true, "end": "00:10:20", "is_worked_example": false, "text": "Note that branches and jumps write their PC+4 value into the register file, so we'll need to bypass from the PC+4 values in the various stages as well as the ALU values."}, {"start": "00:10:20", "is_lecture": true, "end": "00:10:27", "is_worked_example": false, "text": "Note that the bypassing is happening at the end of the cycle, e.g., after the ALU has computed its answer."}, {"start": "00:10:27", "is_lecture": true, "end": "00:10:34", "is_worked_example": false, "text": "To accommodate the extra t_PD of the bypass mux, we'll have to extend the clock period by a small amount."}, {"start": "00:10:34", "is_lecture": true, "end": "00:10:43", "is_worked_example": false, "text": "So once again there's a design tradeoff -- the increased CPI of stalling vs the slightly increased cycle time of bypassing."}, {"start": "00:10:43", "is_lecture": true, "end": "00:10:50", "is_worked_example": false, "text": "And, of course, in the case of bypassing there's the extra area needed for the necessary wiring and muxes."}, {"start": "00:10:50", "is_lecture": true, "end": "00:11:03", "is_worked_example": false, "text": "We can cut back on the costs by reducing the amount of bypassing, say, to only bypassing ALU results from the ALU stage and use stalling to deal with all the other data hazards."}, {"start": "00:11:03", "is_lecture": true, "end": "00:11:07", "is_worked_example": false, "text": "If we implement full bypassing, do we still need the STALL logic?"}, {"start": "00:11:07", "is_lecture": true, "end": "00:11:09", "is_worked_example": false, "text": "As it turns out, we do!"}, {"start": "00:11:09", "is_lecture": true, "end": "00:11:13", "is_worked_example": false, "text": "There's one data hazard that bypassing doesn't completely address."}, {"start": "00:11:13", "is_lecture": true, "end": "00:11:18", "is_worked_example": false, "text": "Consider trying to immediately the use the result of a LD instruction."}, {"start": "00:11:18", "is_lecture": true, "end": "00:11:25", "is_worked_example": false, "text": "In the example shown here, the SUBC is trying to use the value the immediately preceding LD is writing to R2."}, {"start": "00:11:25", "is_lecture": true, "end": "00:11:28", "is_worked_example": false, "text": "This is called a load-to-use hazard."}, {"start": "00:11:28", "is_lecture": true, "end": "00:11:44", "is_worked_example": false, "text": "Recalling that LD data isn't available in the data path until the cycle when LD reaches the WB stage, even with full bypassing we'll need to stall SUBC in the RF stage until cycle 5, introducing two NOPs into the pipeline."}, {"start": "00:11:44", "is_lecture": true, "end": "00:11:50", "is_worked_example": false, "text": "Without bypassing from the WB stage, we need to stall until cycle 6."}, {"start": "00:11:50", "is_lecture": true, "end": "00:11:55", "is_worked_example": false, "text": "In summary, we have two strategies for dealing with data hazards."}, {"start": "00:11:55", "is_lecture": true, "end": "00:12:04", "is_worked_example": false, "text": "We can stall the IF and RF stages until the register values needed by the instruction in the RF stage are available in the register file."}, {"start": "00:12:04", "is_lecture": true, "end": "00:12:14", "is_worked_example": false, "text": "The required hardware is simple, but the NOPs introduced into the pipeline waste CPU cycles and result in an higher effective CPI."}, {"start": "00:12:14", "is_lecture": true, "end": "00:12:23", "is_worked_example": false, "text": "Or we can use bypass paths to route the required values to the RF stage assuming they exist somewhere in the pipelined data path."}, {"start": "00:12:23", "is_lecture": true, "end": "00:12:29", "is_worked_example": false, "text": "This approach requires more hardware than stalling, but doesn't reduce the effective CPI."}, {"start": "00:12:29", "is_lecture": true, "end": "00:12:34", "is_worked_example": false, "text": "Even if we implement bypassing, we'll still need stalls to deal with load-to-use hazards."}, {"start": "00:12:34", "is_lecture": true, "end": "00:12:39", "is_worked_example": false, "text": "Can we keep adding pipeline stages in the hopes of further reducing the clock period?"}, {"start": "00:12:39", "is_lecture": true, "end": "00:12:51", "is_worked_example": false, "text": "More pipeline stages mean more instructions in the pipeline at the same time, which in turn increases the chance of a data hazard and the necessity of stalling, thus increasing CPI."}, {"start": "00:12:51", "is_lecture": true, "end": "00:12:57", "is_worked_example": false, "text": "Compilers can help reduce dependencies by reorganizing the assembly language code they produce."}, {"start": "00:12:57", "is_lecture": true, "end": "00:13:01", "is_worked_example": false, "text": "Here's the load-to-use hazard example we saw earlier."}, {"start": "00:13:01", "is_lecture": true, "end": "00:13:05", "is_worked_example": false, "text": "Even with full bypassing, we'd need to stall for 2 cycles."}, {"start": "00:13:05", "is_lecture": true, "end": "00:13:16", "is_worked_example": false, "text": "But if the compiler (or assembly language programmer!) notices that the MUL and XOR instructions are independent of the SUBC instruction and hence can be moved before the SUBC,"}, {"start": "00:13:16", "is_lecture": true, "end": "00:13:25", "is_worked_example": false, "text": "the dependency is now such that the LD is naturally in the WB stage when the SUBC is in the RF stage, so no stalls are needed."}, {"start": "00:13:25", "is_lecture": true, "end": "00:13:31", "is_worked_example": false, "text": "This optimization only works when the compiler can find independent instructions to move around."}, {"start": "00:13:31", "is_lecture": true, "end": "00:13:37", "is_worked_example": false, "text": "Unfortunately there are plenty of programs where such instructions are hard to find."}, {"start": "00:13:37", "is_lecture": true, "end": "00:13:41", "is_worked_example": false, "text": "Then there's one final approach we could take --"}, {"start": "00:13:41", "is_lecture": true, "end": "00:13:54", "is_worked_example": false, "text": "change the ISA so that data hazards are part of the ISA, i.e., just explain that writes to the destination register happen with a 3-instruction delay!"}, {"start": "00:13:54", "is_lecture": true, "end": "00:13:58", "is_worked_example": false, "text": "If NOPs are needed, make the programmer add them to the program."}, {"start": "00:13:58", "is_lecture": true, "end": "00:14:03", "is_worked_example": false, "text": "Simplify the hardware at the \"small\" cost of making the compilers work harder."}, {"start": "00:14:03", "is_lecture": true, "end": "00:14:08", "is_worked_example": false, "text": "You can imagine exactly how much the compiler writers will like this suggestion."}, {"start": "00:14:08", "is_lecture": true, "end": "00:14:10", "is_worked_example": false, "text": "Not to mention assembly language programmers!"}, {"start": "00:14:10", "is_lecture": true, "end": "00:14:16", "is_worked_example": false, "text": "And you can change the ISA again when you add more pipeline stages!"}, {"start": "00:14:16", "is_lecture": true, "end": "00:14:24", "is_worked_example": false, "text": "This is how a compiler writer views CPU architects who unilaterally change the ISA to save a few logic gates :)"}, {"start": "00:14:24", "is_lecture": true, "end": "00:14:34", "is_worked_example": false, "text": "The bottom line is that successful ISAs have very long lifetimes and so shouldn't include tradeoffs driven by short-term implementation considerations."}, {"start": "00:14:34", "is_lecture": true, "end": "00:14:37", "is_worked_example": false, "text": "Best not to go there."}]}, "C06S01B06-LEC.srt": {"url": "https://courses.edx.org/courses/course-v1:MITx+6.004.3x+2T2016/courseware/c6/c6s1/6?activate_block_id=block-v1%3AMITx%2B6.004.3x%2B2T2016%2Btype%40discussion%2Bblock%40c6s1v6", "items": [{"start": "00:00:00", "is_lecture": true, "end": "00:00:07", "is_worked_example": false, "text": "User-mode programs need to communicate with the OS to request service or get access to useful OS data like the time of day."}, {"start": "00:00:07", "is_lecture": true, "end": "00:00:15", "is_worked_example": false, "text": "But if they're running in a different MMU context than the OS, they don't have direct access to OS code and data."}, {"start": "00:00:15", "is_lecture": true, "end": "00:00:18", "is_worked_example": false, "text": "And that might be bad idea in any case:"}, {"start": "00:00:18", "is_lecture": true, "end": "00:00:28", "is_worked_example": false, "text": "the OS is usually responsible for implementing security and access policies and other users of the system would be upset if any random user program could circumvent those protections."}, {"start": "00:00:28", "is_lecture": true, "end": "00:00:41", "is_worked_example": false, "text": "What's needed is the ability for user-mode programs to call OS code at specific entry points, using registers or the user-mode virtual memory to send or receive information."}, {"start": "00:00:41", "is_lecture": true, "end": "00:00:50", "is_worked_example": false, "text": "We'd use these \"supervisor calls\" to access a well-documented and secure OS application programming interface (API)."}, {"start": "00:00:50", "is_lecture": true, "end": "00:00:58", "is_worked_example": false, "text": "An example of such an interface is POSIX (https://en.wikipedia.org/wiki/POSIX), a standard interface implemented by many Unix-like operating systems."}, {"start": "00:00:58", "is_lecture": true, "end": "00:01:09", "is_worked_example": false, "text": "As it turns out, we have a way of transferring control from a user-mode program to a specific OS handler -- just execute an illegal instruction!"}, {"start": "00:01:09", "is_lecture": true, "end": "00:01:16", "is_worked_example": false, "text": "We'll adopt the convention of using illegal instructions with an opcode field of 1 to serve as supervisor calls."}, {"start": "00:01:16", "is_lecture": true, "end": "00:01:25", "is_worked_example": false, "text": "The low order bits of these SVC instructions will contain an index indicating which SVC service we're trying to access."}, {"start": "00:01:25", "is_lecture": true, "end": "00:01:27", "is_worked_example": false, "text": "Let's see how this would work."}, {"start": "00:01:27", "is_lecture": true, "end": "00:01:31", "is_worked_example": false, "text": "Here's our user-mode/kernel-mode diagram again."}, {"start": "00:01:31", "is_lecture": true, "end": "00:01:42", "is_worked_example": false, "text": "Note that the user-mode programs contain supervisor calls with different indices, which when executed are intended to serve as requests for different OS services."}, {"start": "00:01:42", "is_lecture": true, "end": "00:01:56", "is_worked_example": false, "text": "When an SVC instruction is executed, the hardware detects the opcode field of 1 as an illegal instruction and triggers an exception that runs the OS IllOp handler, as we saw in the previous segment."}, {"start": "00:01:56", "is_lecture": true, "end": "00:02:05", "is_worked_example": false, "text": "The handler saves the process state in the temporary storage area, then dispatches to the appropriate handler based on the opcode field."}, {"start": "00:02:05", "is_lecture": true, "end": "00:02:17", "is_worked_example": false, "text": "This handler can access the user's registers in the temporary storage area, or using the appropriate OS subroutines can access the contents of any user-mode virtual address."}, {"start": "00:02:17", "is_lecture": true, "end": "00:02:28", "is_worked_example": false, "text": "If information is to be returned to the user, the return values can be stored in the temporary storage area, overwriting, say, the saved contents of the user's R0 register."}, {"start": "00:02:28", "is_lecture": true, "end": "00:02:36", "is_worked_example": false, "text": "Then, when the handler completes, the potentially-updated saved register values are reloaded into the CPU registers"}, {"start": "00:02:36", "is_lecture": true, "end": "00:02:43", "is_worked_example": false, "text": "and execution of the user-mode program resumes at the instruction following the supervisor call."}, {"start": "00:02:43", "is_lecture": true, "end": "00:02:54", "is_worked_example": false, "text": "In the previous segment we saw how the illegal instruction handler uses a dispatch table to choose the appropriate sub-handler depending on the opcode field of the illegal instruction."}, {"start": "00:02:54", "is_lecture": true, "end": "00:03:02", "is_worked_example": false, "text": "In this slide we see the sub-handler for SVC instructions, i.e., those with an opcode field of 1."}, {"start": "00:03:02", "is_lecture": true, "end": "00:03:11", "is_worked_example": false, "text": "This code uses the low-order bits of the instruction to access another dispatch table to select the appropriate code for each of the eight possible SVCs."}, {"start": "00:03:11", "is_lecture": true, "end": "00:03:16", "is_worked_example": false, "text": "Our Tiny OS only has a meagre selection of simple services."}, {"start": "00:03:16", "is_lecture": true, "end": "00:03:27", "is_worked_example": false, "text": "A real OS would have SVCs for accessing files, dealing with network connections, managing virtual memory, spawning new processes, and so on."}, {"start": "00:03:27", "is_lecture": true, "end": "00:03:33", "is_worked_example": false, "text": "Here's the code for resuming execution of the user-mode process when the SVC handler is done:"}, {"start": "00:03:33", "is_lecture": true, "end": "00:03:42", "is_worked_example": false, "text": "simply restore the saved values for the registers and JMP to resume execution at the instruction following the SVC instruction."}, {"start": "00:03:42", "is_lecture": true, "end": "00:03:50", "is_worked_example": false, "text": "There are times when for some reason the SVC request cannot be completed and the request should be retried in the future."}, {"start": "00:03:50", "is_lecture": true, "end": "00:04:02", "is_worked_example": false, "text": "For example, the ReadCh SVC returns the next character typed by the user, but if no character has yet been typed, the OS cannot complete the request at this time."}, {"start": "00:04:02", "is_lecture": true, "end": "00:04:16", "is_worked_example": false, "text": "In this case, the SVC handler should branch to I_Wait, which arranges for the SVC instruction to be re-executed next time this process runs and then calls Scheduler() to run the next process."}, {"start": "00:04:16", "is_lecture": true, "end": "00:04:23", "is_worked_example": false, "text": "This gives all the other processes a chance to run before the SVC is tried again, hopefully this time successfully."}, {"start": "00:04:23", "is_lecture": true, "end": "00:04:30", "is_worked_example": false, "text": "You can see that this code also serves as the implementation for two different SVCs!"}, {"start": "00:04:30", "is_lecture": true, "end": "00:03:47", "is_worked_example": false, "text": "A process can give up the remainder of its current execution time slice by calling the Yield() SVC."}, {"start": "00:03:47", "is_lecture": true, "end": "00:04:48", "is_worked_example": false, "text": "This simply causes the OS to call Scheduler(), suspending execution of the current process until its next turn in the round-robin scheduling process."}, {"start": "00:04:48", "is_lecture": true, "end": "00:04:53", "is_worked_example": false, "text": "And to stop execution, a process can call the Halt() SVC."}, {"start": "00:04:53", "is_lecture": true, "end": "00:04:58", "is_worked_example": false, "text": "Looking at the implementation, we can see that \"halt\" is a bit of misnomer."}, {"start": "00:04:58", "is_lecture": true, "end": "00:05:09", "is_worked_example": false, "text": "What really happens is that the system arranges to re-execute the Halt() SVC each time the process is scheduled, which then causes the OS to schedule the next process for execution."}, {"start": "00:05:09", "is_lecture": true, "end": "00:05:16", "is_worked_example": false, "text": "The process appears to halt since the instruction following the Halt() SVC is never executed."}, {"start": "00:05:16", "is_lecture": true, "end": "00:05:19", "is_worked_example": false, "text": "Adding new SVC handlers is straightforward."}, {"start": "00:05:19", "is_lecture": true, "end": "00:05:25", "is_worked_example": false, "text": "First we need to define new SVC macros for use in user-mode programs."}, {"start": "00:05:25", "is_lecture": true, "end": "00:05:30", "is_worked_example": false, "text": "In this example, we're defining SVCs for getting and setting the time of day."}, {"start": "00:05:30", "is_lecture": true, "end": "00:05:42", "is_worked_example": false, "text": "Since these are the eighth and ninth SVCs, we need to make a small adjustment to the SVC dispatch code and then add the appropriate entries to the end of the dispatch table."}, {"start": "00:05:42", "is_lecture": true, "end": "00:05:46", "is_worked_example": false, "text": "The code for the new handlers is equally straightforward."}, {"start": "00:05:46", "is_lecture": true, "end": "00:05:54", "is_worked_example": false, "text": "The handler can access the value of the program's R0 by looking at the correct entry in the UserMState temporary holding area."}, {"start": "00:05:54", "is_lecture": true, "end": "00:05:59", "is_worked_example": false, "text": "It just takes a few instructions to implement the desired operations."}, {"start": "00:05:59", "is_lecture": true, "end": "00:06:06", "is_worked_example": false, "text": "The SVC mechanism provides controlled access to OS services and data."}, {"start": "00:06:06", "is_lecture": true, "end": "00:06:16", "is_worked_example": false, "text": "As we'll see in a few lectures, it'll be useful that SVC handlers can't be interrupted since they are running in supervisor mode where interrupts are disabled."}, {"start": "00:06:16", "is_lecture": true, "end": "00:06:29", "is_worked_example": false, "text": "So, for example, if we need to increment a value in main memory, using a LD/ADDC/ST sequence, but we want to ensure no other process execution intervenes between the LD and the ST,"}, {"start": "00:06:29", "is_lecture": true, "end": "00:06:36", "is_worked_example": false, "text": "we can encapsulate the required functionality as an SVC, which is guaranteed to be uninterruptible."}, {"start": "00:06:36", "is_lecture": true, "end": "00:06:43", "is_worked_example": false, "text": "We've made an excellent start at exploring the implementation of a simple time-shared operating system."}, {"start": "00:06:43", "is_lecture": true, "end": "00:06:51", "is_worked_example": false, "text": "We'll continue the exploration in the next lecture when we see how the OS deals with external input/output devices."}]}, "C05S02B01-WE.srt": {"url": "https://courses.edx.org/courses/course-v1:MITx+6.004.3x+2T2016/courseware/c5/c5s2/1?activate_block_id=block-v1%3AMITx%2B6.004.3x%2B2T2016%2Btype%40discussion%2Bblock%40c5s2v1", "items": [{"start": "00:00:00", "is_lecture": false, "end": "00:00:06", "is_worked_example": true, "text": "Virtual memory allows programs to behave as if they have a larger memory than they actually do."}, {"start": "00:00:06", "is_lecture": false, "end": "00:00:14", "is_worked_example": true, "text": "The way this works is by using virtual addresses, which refer to addresses on disk, in our programs."}, {"start": "00:00:14", "is_lecture": false, "end": "00:00:23", "is_worked_example": true, "text": "The virtual addresses are translated into physical addresses using the page map which is a lookup table that has one entry per virtual page."}, {"start": "00:00:23", "is_lecture": false, "end": "00:00:31", "is_worked_example": true, "text": "The page map knows whether the virtual page is in physical memory and if so it immediately returns the physical page number."}, {"start": "00:00:31", "is_lecture": false, "end": "00:00:42", "is_worked_example": true, "text": "If the page is not in physical memory, then this causes a fault which means that the virtual page must be brought in from disk to physical memory before it can be accessed."}, {"start": "00:00:42", "is_lecture": false, "end": "00:00:52", "is_worked_example": true, "text": "To do this the least recently used (LRU) page in the physical memory is removed to make room for the address that is currently being requested."}, {"start": "00:00:52", "is_lecture": false, "end": "00:00:57", "is_worked_example": true, "text": "The page map is also updated with the new mapping of virtual to physical pages."}, {"start": "00:00:57", "is_lecture": false, "end": "00:01:04", "is_worked_example": true, "text": "Since bringing data to and from disk is an expensive operation, data is moved in chunks."}, {"start": "00:01:04", "is_lecture": false, "end": "00:01:10", "is_worked_example": true, "text": "This makes sense because of the concept of locality which we studied as part of our Caches unit."}, {"start": "00:01:10", "is_lecture": false, "end": "00:01:21", "is_worked_example": true, "text": "The idea is that instructions, or data, that are close to the current address are likely to be accessed as well, so it makes sense to fetch more than one word of data at a time."}, {"start": "00:01:21", "is_lecture": false, "end": "00:01:32", "is_worked_example": true, "text": "This is especially true if the cost of fetching the first word is significantly higher than the cost of fetching adjacent memory locations as is the case with accesses to disk."}, {"start": "00:01:32", "is_lecture": false, "end": "00:01:37", "is_worked_example": true, "text": "So data is moved back and forth from disk in pages."}, {"start": "00:01:37", "is_lecture": false, "end": "00:01:41", "is_worked_example": true, "text": "The size of a page is the same in both virtual and physical memory."}, {"start": "00:01:41", "is_lecture": false, "end": "00:01:45", "is_worked_example": true, "text": "Lets look at an example of how virtual memory is used."}, {"start": "00:01:45", "is_lecture": false, "end": "00:01:59", "is_worked_example": true, "text": "While it is usually the case that the virtual address space is larger than the physical address space, this is not a requirement and in this problem the virtual address space happens to be smaller than the physical address space."}, {"start": "00:01:59", "is_lecture": false, "end": "00:02:06", "is_worked_example": true, "text": "Specifically, virtual addresses are 16 bits long so they can address 2^16 bytes."}, {"start": "00:02:06", "is_lecture": false, "end": "00:02:14", "is_worked_example": true, "text": "Physical addresses are 20 bits long so that means that our physical memory is of size 2^20 bytes."}, {"start": "00:02:14", "is_lecture": false, "end": "00:02:20", "is_worked_example": true, "text": "Our page size is 2^8 bytes or 256 bytes per page."}, {"start": "00:02:20", "is_lecture": false, "end": "00:02:30", "is_worked_example": true, "text": "This means that the 16 bit virtual address consists of 8 bits of page offset and another 8 bits for the virtual page number (or VPN)."}, {"start": "00:02:30", "is_lecture": false, "end": "00:02:39", "is_worked_example": true, "text": "The 20 bit physical address consists of the same 8 bit page offset and another 12 bits for the physical page number (or PPN)."}, {"start": "00:02:39", "is_lecture": false, "end": "00:02:46", "is_worked_example": true, "text": "The first question we want to consider is what is the size of the page map in this example?"}, {"start": "00:02:46", "is_lecture": false, "end": "00:02:53", "is_worked_example": true, "text": "Recall that a page map has 1 entry per virtual page in order to map  each virtual page to a physical page."}, {"start": "00:02:53", "is_lecture": false, "end": "00:03:02", "is_worked_example": true, "text": "This means that the number of entries in the page map is 2^8 where 8 is the number of bits in the VPN."}, {"start": "00:03:02", "is_lecture": false, "end": "00:03:11", "is_worked_example": true, "text": "The size of each page map entry is 14 bits, 12 for the PPN, 1 for the dirty bit and 1 for the resident bit."}, {"start": "00:03:11", "is_lecture": false, "end": "00:03:22", "is_worked_example": true, "text": "Suppose that you are told that the page size is doubled in size so that there are now 2^9 bytes per page, but the size of your physical and virtual addresses remain the same."}, {"start": "00:03:22", "is_lecture": false, "end": "00:03:28", "is_worked_example": true, "text": "We would like to determine what effect this change would have on some of the page map attributes."}, {"start": "00:03:28", "is_lecture": false, "end": "00:03:33", "is_worked_example": true, "text": "The first question is how does the size of each page map entry in bits change?"}, {"start": "00:03:33", "is_lecture": false, "end": "00:03:47", "is_worked_example": true, "text": "Since the size of a physical address continues to be 20 bits long, then the change in page offset size from 8 to 9 bits implies that the size of the PPN decreased by 1 bit from 12 to 11."}, {"start": "00:03:47", "is_lecture": false, "end": "00:03:53", "is_worked_example": true, "text": "This implies that the size of each page map entry also decreases by 1 bit."}, {"start": "00:03:53", "is_lecture": false, "end": "00:03:58", "is_worked_example": true, "text": "How are the number of entries in the page map affected by the change in page size?"}, {"start": "00:03:58", "is_lecture": false, "end": "00:04:09", "is_worked_example": true, "text": "Since the number of entries in a page map is equal to the number of  virtual pages, that means that if the size of each page doubled, then  we have half as many virtual pages."}, {"start": "00:04:09", "is_lecture": false, "end": "00:04:15", "is_worked_example": true, "text": "This is shown in the size of the VPN which has decreased from 8 to 7  bits."}, {"start": "00:04:15", "is_lecture": false, "end": "00:04:24", "is_worked_example": true, "text": "This also means that the number of entries in the page map have halved  in size from 2^8 entries down to 2^7 entries."}, {"start": "00:04:24", "is_lecture": false, "end": "00:04:31", "is_worked_example": true, "text": "How about the number of accesses of the page map that are required to translate a single virtual address?"}, {"start": "00:04:31", "is_lecture": false, "end": "00:04:37", "is_worked_example": true, "text": "This parameter does not change as a result of the pages doubling in size."}, {"start": "00:04:37", "is_lecture": false, "end": "00:04:43", "is_worked_example": true, "text": "Suppose we return to our original page size of 256 bytes per page."}, {"start": "00:04:43", "is_lecture": false, "end": "00:04:49", "is_worked_example": true, "text": "We now execute these two lines of code, a load followed by a store operation."}, {"start": "00:04:49", "is_lecture": false, "end": "00:05:04", "is_worked_example": true, "text": "The comment after each instruction shows us the value of the PC when each of the instructions is executed, so it is telling us that the load instruction is at address 0x1FC and the store instruction is at address 0x200."}, {"start": "00:05:04", "is_lecture": false, "end": "00:05:13", "is_worked_example": true, "text": "To execute these two lines of code, we must first fetch each instruction and then perform the data access required by that instruction."}, {"start": "00:05:13", "is_lecture": false, "end": "00:05:21", "is_worked_example": true, "text": "Since our pages are 2^8 bytes long, that means that the bottom 8 bits of our address correspond to the page offset."}, {"start": "00:05:21", "is_lecture": false, "end": "00:05:28", "is_worked_example": true, "text": "Notice that our instruction addresses are specified in hex so 8 bits correspond to the bottom 2 hex characters."}, {"start": "00:05:28", "is_lecture": false, "end": "00:05:39", "is_worked_example": true, "text": "This means that when accessing the LD instruction, the VPN = 1 (which is what remains of our virtual address after removing the bottom 8 bits.)"}, {"start": "00:05:39", "is_lecture": false, "end": "00:05:44", "is_worked_example": true, "text": "The data accessed by the LD instruction comes from VPN 3."}, {"start": "00:05:44", "is_lecture": false, "end": "00:05:53", "is_worked_example": true, "text": "Next we fetch the store instruction from VPN 2, and finally we store an updated value to VPN 6."}, {"start": "00:05:53", "is_lecture": false, "end": "00:06:02", "is_worked_example": true, "text": "Given the page map shown here, we would like to determine the unique physical addresses that are accessed by this code segment."}, {"start": "00:06:02", "is_lecture": false, "end": "00:06:07", "is_worked_example": true, "text": "Recall that the four virtual addresses that will be accessed are:"}, {"start": "00:06:07", "is_lecture": false, "end": "00:06:11", "is_worked_example": true, "text": "0x1FC which is in VPN 1"}, {"start": "00:06:11", "is_lecture": false, "end": "00:06:16", "is_worked_example": true, "text": "0x34C which is in VPN 3"}, {"start": "00:06:16", "is_lecture": false, "end": "00:06:20", "is_worked_example": true, "text": "0x200 which is in VPN 2"}, {"start": "00:06:20", "is_lecture": false, "end": "00:06:25", "is_worked_example": true, "text": "and 0x604 which is in VPN 6."}, {"start": "00:06:25", "is_lecture": false, "end": "00:06:41", "is_worked_example": true, "text": "Assume that all the code and data required to handle page faults is located at physical page 0, your goal is to determine the 5 different physical pages that will get accessed and the order in which they will get accessed by this code segment."}, {"start": "00:06:41", "is_lecture": false, "end": "00:06:45", "is_worked_example": true, "text": "We begin by looking up VPN 1 in our page map."}, {"start": "00:06:45", "is_lecture": false, "end": "00:06:49", "is_worked_example": true, "text": "We see that its resident bit is set to 1."}, {"start": "00:06:49", "is_lecture": false, "end": "00:06:56", "is_worked_example": true, "text": "This means that the virtual page is in physical memory and its PPN is 0x007."}, {"start": "00:06:56", "is_lecture": false, "end": "00:07:07", "is_worked_example": true, "text": "Thus the first physical page that we access is page 0x7, and the first physical address is determined by concatenating the PPN to the page offset."}, {"start": "00:07:07", "is_lecture": false, "end": "00:07:12", "is_worked_example": true, "text": "This results in a physical address of 0x7FC."}, {"start": "00:07:12", "is_lecture": false, "end": "00:07:20", "is_worked_example": true, "text": "Next, we want to load the data at virtual address 0x34C which is in VPN 3."}, {"start": "00:07:20", "is_lecture": false, "end": "00:07:26", "is_worked_example": true, "text": "Looking up VPN 3 in our page map, we find out that its not resident in physical memory."}, {"start": "00:07:26", "is_lecture": false, "end": "00:07:33", "is_worked_example": true, "text": "This means that we need to make room for it by removing the least recently used page from physical memory."}, {"start": "00:07:33", "is_lecture": false, "end": "00:07:40", "is_worked_example": true, "text": "The least recently used page is VPN 2 which maps to PPN 0x602."}, {"start": "00:07:40", "is_lecture": false, "end": "00:07:53", "is_worked_example": true, "text": "Since the dirty bit of our LRU page is 0, that means that we have not done any writes to this page while it was in physical memory so the version in physical memory and on disk are identical."}, {"start": "00:07:53", "is_lecture": false, "end": "00:08:07", "is_worked_example": true, "text": "So to free up physical page 0x602, all we need to do is change the resident bit of VPN 2 to 0 and now we can bring VPN 3 into physical page 0x602."}, {"start": "00:08:07", "is_lecture": false, "end": "00:08:15", "is_worked_example": true, "text": "Recall that the code for handling the page fault is in physical page 0 so the second physical page that we access is page 0."}, {"start": "00:08:15", "is_lecture": false, "end": "00:08:29", "is_worked_example": true, "text": "The updated page map, after handling the page fault, looks like this, where the resident bit for VPN 2 has been set to 0, and PPN 0x602 is now used for VPN 3."}, {"start": "00:08:29", "is_lecture": false, "end": "00:08:36", "is_worked_example": true, "text": "Since this is a LD operation, we are not modifying the page so the dirty bit is set to 0."}, {"start": "00:08:36", "is_lecture": false, "end": "00:08:50", "is_worked_example": true, "text": "The physical address for virtual address 0x34C is now 0x6024C which is now in VPN 0x602."}, {"start": "00:08:50", "is_lecture": false, "end": "00:08:57", "is_worked_example": true, "text": "Next we need to fetch the store instruction from virtual address 0x200 which is in VPN 2."}, {"start": "00:08:57", "is_lecture": false, "end": "00:09:02", "is_worked_example": true, "text": "Since we just removed VPN 2 from physical memory we get another page fault."}, {"start": "00:09:02", "is_lecture": false, "end": "00:09:10", "is_worked_example": true, "text": "This time we will remove the next LRU page from physical memory in order to make room for VPN 2 once again."}, {"start": "00:09:10", "is_lecture": false, "end": "00:09:20", "is_worked_example": true, "text": "In this case, the dirty bit is set to 1 which means that we have written to PPN 0x097 after it was fetched from disk."}, {"start": "00:09:20", "is_lecture": false, "end": "00:09:34", "is_worked_example": true, "text": "This means that the page fault handler will need to first write physical page 0x097 back to virtual page 5 before we can use physical page 0x097 for VPN 2."}, {"start": "00:09:34", "is_lecture": false, "end": "00:09:40", "is_worked_example": true, "text": "After handling the page fault, our updated page map looks like this."}, {"start": "00:09:40", "is_lecture": false, "end": "00:09:49", "is_worked_example": true, "text": "VPN 5 is no longer resident, and instead VPN 2 is resident in physical page 0x097."}, {"start": "00:09:49", "is_lecture": false, "end": "00:09:56", "is_worked_example": true, "text": "In addition, we set the dirty bit to 0 because we have not made any changes to this virtual page."}, {"start": "00:09:56", "is_lecture": false, "end": "00:10:08", "is_worked_example": true, "text": "We now know that virtual address 0x200 maps to physical address 0x09700 after the handling of the page fault."}, {"start": "00:10:08", "is_lecture": false, "end": "00:10:16", "is_worked_example": true, "text": "Finally, we need to perform the store to virtual address 0x604 which is in VPN 6."}, {"start": "00:10:16", "is_lecture": false, "end": "00:10:25", "is_worked_example": true, "text": "Since VPN 6 is resident in physical memory, we can access it at physical page 0x790 as shown in the page map."}, {"start": "00:10:25", "is_lecture": false, "end": "00:10:35", "is_worked_example": true, "text": "This means that virtual address 0x604 maps to physical address 0x79004."}, {"start": "00:10:35", "is_lecture": false, "end": "00:10:46", "is_worked_example": true, "text": "Note that because the dirty bit of VPN 6 was already a 1, we don't need to make any further modifications to the page map as a result of executing the store operation."}, {"start": "00:10:46", "is_lecture": false, "end": "00:10:52", "is_worked_example": true, "text": "If the dirty bit had been a 0, then we would have set it to 1."}, {"start": "00:10:52", "is_lecture": false, "end": "00:11:09", "is_worked_example": true, "text": "So the five physical pages that were accessed by this program are: page 0x7, page 0 for the page faults, page 0x602, page 0x097, and page 0x790."}]}, "C03S01B07-LEC.srt": {"url": "https://courses.edx.org/courses/course-v1:MITx+6.004.3x+2T2016/courseware/c3/c3s1/7?activate_block_id=block-v1%3AMITx%2B6.004.3x%2B2T2016%2Btype%40discussion%2Bblock%40c3s1v7", "items": [{"start": "00:00:00", "is_lecture": true, "end": "00:00:04", "is_worked_example": false, "text": "Now let's figure out how exceptions impact pipelined execution."}, {"start": "00:00:04", "is_lecture": true, "end": "00:00:17", "is_worked_example": false, "text": "When an exception occurs because of an illegal instruction or an external interrupt, we need to store the current PC+4 value in the XP register and load the program counter with the address of the appropriate exception handler."}, {"start": "00:00:17", "is_lecture": true, "end": "00:00:22", "is_worked_example": false, "text": "Exceptions cause control flow hazards since they are effectively implicit branches."}, {"start": "00:00:22", "is_lecture": true, "end": "00:00:28", "is_worked_example": false, "text": "In an unpipelined implementation, exceptions affect the execution of the current instruction."}, {"start": "00:00:28", "is_lecture": true, "end": "00:00:33", "is_worked_example": false, "text": "We want to achieve exactly the same effect in our pipelined implementation."}, {"start": "00:00:33", "is_lecture": true, "end": "00:00:49", "is_worked_example": false, "text": "So first we have to identify which one of the instructions in our pipeline is affected, then ensure that instructions that came earlier in the code complete correctly and that we annul the affected instruction and any following instructions that are in the pipeline."}, {"start": "00:00:49", "is_lecture": true, "end": "00:00:53", "is_worked_example": false, "text": "Since there are multiple instructions in the pipeline, we have a bit of sorting out to do."}, {"start": "00:00:53", "is_lecture": true, "end": "00:00:59", "is_worked_example": false, "text": "When, during pipelined execution, do we determine that an instruction will cause an exception?"}, {"start": "00:00:59", "is_lecture": true, "end": "00:01:06", "is_worked_example": false, "text": "An obvious example is detecting an illegal opcode when we decode the instruction in the RF stage."}, {"start": "00:01:06", "is_lecture": true, "end": "00:01:10", "is_worked_example": false, "text": "But we can also generate exceptions in other pipeline stages."}, {"start": "00:01:10", "is_lecture": true, "end": "00:01:16", "is_worked_example": false, "text": "For example, the ALU stage can generate an exception if the second operand of a DIV instruction is 0."}, {"start": "00:01:16", "is_lecture": true, "end": "00:01:23", "is_worked_example": false, "text": "Or the MEM stage may detect that the instruction is attempting to access memory with an illegal address."}, {"start": "00:01:23", "is_lecture": true, "end": "00:01:28", "is_worked_example": false, "text": "Similarly the IF stage can generate a memory exception when fetching the next instruction."}, {"start": "00:01:28", "is_lecture": true, "end": "00:01:36", "is_worked_example": false, "text": "In each case, instructions that follow the one that caused the exception may already be in the pipeline and will need to be annulled."}, {"start": "00:01:36", "is_lecture": true, "end": "00:01:44", "is_worked_example": false, "text": "The good news is that since register values are only updated in the WB stage, annulling an instruction only requires replacing it with a NOP."}, {"start": "00:01:44", "is_lecture": true, "end": "00:01:50", "is_worked_example": false, "text": "We won't have to restore any changed values in the register file or main memory."}, {"start": "00:01:50", "is_lecture": true, "end": "00:01:52", "is_worked_example": false, "text": "Here's our plan."}, {"start": "00:01:52", "is_lecture": true, "end": "00:02:04", "is_worked_example": false, "text": "If an instruction causes an exception in stage i, replace that instruction with this BNE instruction, whose only side effect is writing the PC+4 value into the XP register."}, {"start": "00:02:04", "is_lecture": true, "end": "00:02:09", "is_worked_example": false, "text": "Then flush the pipeline by annulling instructions in earlier pipeline stages."}, {"start": "00:02:09", "is_lecture": true, "end": "00:02:15", "is_worked_example": false, "text": "And, finally, load the program counter with the address of the exception handler."}, {"start": "00:02:15", "is_lecture": true, "end": "00:02:23", "is_worked_example": false, "text": "In this example, assume that LD will generate a memory exception in the MEM stage, which occurs in cycle 4."}, {"start": "00:02:23", "is_lecture": true, "end": "00:02:34", "is_worked_example": false, "text": "The arrows show how the instructions in the pipeline are rewritten for cycle 5, at which point the IF stage is working on fetching the first instruction in the exception handler."}, {"start": "00:02:34", "is_lecture": true, "end": "00:02:38", "is_worked_example": false, "text": "Here are the changes required to the execution pipeline."}, {"start": "00:02:38", "is_lecture": true, "end": "00:02:51", "is_worked_example": false, "text": "We modify the muxes in the instruction path so that they can replace an actual instruction with either NOP if the instruction is to be annulled, or BNE if the instruction caused the exception."}, {"start": "00:02:51", "is_lecture": true, "end": "00:03:00", "is_worked_example": false, "text": "Since the pipeline is executing multiple instructions at the same time, we have to worry about what happens if multiple exceptions are detected during execution."}, {"start": "00:03:00", "is_lecture": true, "end": "00:03:10", "is_worked_example": false, "text": "In this example assume that LD will cause a memory exception in the MEM stage and note that it is followed by an instruction with an illegal opcode."}, {"start": "00:03:10", "is_lecture": true, "end": "00:03:24", "is_worked_example": false, "text": "Looking at the pipeline diagram, the invalid opcode is detected in the RF stage during cycle 3, causing the illegal instruction exception process to begin in cycle 4."}, {"start": "00:03:24", "is_lecture": true, "end": "00:03:35", "is_worked_example": false, "text": "But during that cycle, the MEM stage detects the illegal memory access from the LD instruction and so causes the memory exception process to begin in cycle 5."}, {"start": "00:03:35", "is_lecture": true, "end": "00:03:59", "is_worked_example": false, "text": "Note that the exception caused by the earlier instruction (LD) overrides the exception caused by the later illegal opcode even though the illegal opcode exception was detected first. .348 That's the correct behavior since once the execution of LD is abandoned, the pipeline should behave as if none of the instructions that come after the LD were executed."}, {"start": "00:03:59", "is_lecture": true, "end": "00:04:07", "is_worked_example": false, "text": "If multiple exceptions are detected in the *same* cycle, the exception from the instruction furthest down the pipeline should be given precedence."}, {"start": "00:04:07", "is_lecture": true, "end": "00:04:17", "is_worked_example": false, "text": "External interrupts also behave as implicit branches, but it turns out they are a bit easier to handle in our pipeline."}, {"start": "00:04:17", "is_lecture": true, "end": "00:04:22", "is_worked_example": false, "text": "We'll treat external interrupts as if they were an exception that affected the IF stage."}, {"start": "00:04:22", "is_lecture": true, "end": "00:04:26", "is_worked_example": false, "text": "Let's assume the external interrupt occurs in cycle 2."}, {"start": "00:04:26", "is_lecture": true, "end": "00:04:26", "is_worked_example": false, "text": "This means that the SUB instruction will be replaced by our magic BNE to capture the PC+4 value and we'll force the next PC to be the address of the interrupt handler."}, {"start": "00:04:26", "is_lecture": true, "end": "00:04:51", "is_worked_example": false, "text": "After the interrupt handler completes, we'll want to resume execution of the interrupted program at the SUB instruction, so we'll code the handler to correct the value saved in the XP register so that it points to the SUB instruction."}, {"start": "00:04:51", "is_lecture": true, "end": "00:04:55", "is_worked_example": false, "text": "This is all shown in the pipeline diagram."}, {"start": "00:04:55", "is_lecture": true, "end": "00:05:01", "is_worked_example": false, "text": "Note that the ADD, LD, and other instructions that came before SUB in the program are unaffected by the interrupt."}, {"start": "00:05:01", "is_lecture": true, "end": "00:05:10", "is_worked_example": false, "text": "We can use the existing instruction-path muxes to deal with interrupts, since we're treating them as IF-stage exceptions."}, {"start": "00:05:10", "is_lecture": true, "end": "00:05:18", "is_worked_example": false, "text": "We simply have to adjust the logic for IRSrc_IF to also make it 1 when an interrupt is requested."}]}, "C05S01B06-LEC.srt": {"url": "https://courses.edx.org/courses/course-v1:MITx+6.004.3x+2T2016/courseware/c5/c5s1/6?activate_block_id=block-v1%3AMITx%2B6.004.3x%2B2T2016%2Btype%40discussion%2Bblock%40c5s1v6", "items": [{"start": "00:00:00", "is_lecture": true, "end": "00:00:07", "is_worked_example": false, "text": "There are three architectural parameters that characterize a virtual memory system and hence the architecture of the MMU."}, {"start": "00:00:07", "is_lecture": true, "end": "00:00:14", "is_worked_example": false, "text": "P is the number of address bits used for the page offset in both virtual and physical addresses."}, {"start": "00:00:14", "is_lecture": true, "end": "00:00:19", "is_worked_example": false, "text": "V is the number of address bits used for the virtual page number."}, {"start": "00:00:19", "is_lecture": true, "end": "00:00:24", "is_worked_example": false, "text": "And M is the number of address bits used for the physical page number."}, {"start": "00:00:24", "is_lecture": true, "end": "00:00:29", "is_worked_example": false, "text": "All the other parameters, listed on the right, are derived from these three parameters."}, {"start": "00:00:29", "is_lecture": true, "end": "00:00:41", "is_worked_example": false, "text": "As mentioned earlier, the typical page size is between 4KB and 16KB, the sweet spot in the tradeoff between the downside of using physical memory to hold unwanted locations"}, {"start": "00:00:41", "is_lecture": true, "end": "00:00:52", "is_worked_example": false, "text": "and the upside of reading as much as possible from secondary storage so as to amortize the high cost of accessing the initial word over as many words as possible."}, {"start": "00:00:52", "is_lecture": true, "end": "00:00:57", "is_worked_example": false, "text": "The size of the virtual address is determined by the ISA."}, {"start": "00:00:57", "is_lecture": true, "end": "00:01:10", "is_worked_example": false, "text": "We're now making the transition from 32-bit architectures, which support a 4 gigabyte virtual address space, to 64-bit architectures, which support a 16 exabyte virtual address space."}, {"start": "00:01:10", "is_lecture": true, "end": "00:01:18", "is_worked_example": false, "text": "\"Exa\" is the SI prefix for 10^18 -- a 64-bit address can access a *lot* of memory!"}, {"start": "00:01:18", "is_lecture": true, "end": "00:01:26", "is_worked_example": false, "text": "The limitations of a small virtual address have been the main cause for the extinction of many ISAs."}, {"start": "00:01:26", "is_lecture": true, "end": "00:01:32", "is_worked_example": false, "text": "Of course, each generation of engineers thinks that the transition they make will be the final one!"}, {"start": "00:01:32", "is_lecture": true, "end": "00:01:38", "is_worked_example": false, "text": "I can remember when we all thought that 32 bits was an unimaginably large address."}, {"start": "00:01:38", "is_lecture": true, "end": "00:01:47", "is_worked_example": false, "text": "Back then we're buying memory by the megabyte and only in our fantasies did we think one could have a system with several thousand megabytes."}, {"start": "00:01:47", "is_lecture": true, "end": "00:01:55", "is_worked_example": false, "text": "Today's CPU architects are feeling pretty smug about 64 bits -- we'll see how they feel in a couple of decades!"}, {"start": "00:01:55", "is_lecture": true, "end": "00:02:07", "is_worked_example": false, "text": "The size of physical addresses is currently between 30 bits (for embedded processors with modest memory needs) and 40+ bits (for servers that handle large data sets)."}, {"start": "00:02:07", "is_lecture": true, "end": "00:02:17", "is_worked_example": false, "text": "Since CPU implementations are expected to change every couple of years, the choice of physical memory size can be adjusted to match current technologies."}, {"start": "00:02:17", "is_lecture": true, "end": "00:02:23", "is_worked_example": false, "text": "Since programmers use virtual addresses, they're insulated from this implementation choice."}, {"start": "00:02:23", "is_lecture": true, "end": "00:02:29", "is_worked_example": false, "text": "The MMU ensures that existing software will continue to function correctly with different sizes of physical memory."}, {"start": "00:02:29", "is_lecture": true, "end": "00:02:35", "is_worked_example": false, "text": "The programmer may notice differences in performance, but not in basic functionality."}, {"start": "00:02:35", "is_lecture": true, "end": "00:02:44", "is_worked_example": false, "text": "For example, suppose our system supported a 32-bit virtual address, a 30-bit physical address and a 4KB page size."}, {"start": "00:02:44", "is_lecture": true, "end": "00:02:54", "is_worked_example": false, "text": "So p = 12, v = 32-12 = 20, and m = 30 - 12 = 18."}, {"start": "00:02:54", "is_lecture": true, "end": "00:03:00", "is_worked_example": false, "text": "There are 2^m physical pages, which is 2^18 in our example."}, {"start": "00:03:00", "is_lecture": true, "end": "00:03:05", "is_worked_example": false, "text": "There are 2^v virtual pages, which is 2^20 in our example."}, {"start": "00:03:05", "is_lecture": true, "end": "00:03:14", "is_worked_example": false, "text": "And since there is one entry in the page map for each virtual page, there are 2^20 (approximately one million) page map entries."}, {"start": "00:03:14", "is_lecture": true, "end": "00:03:26", "is_worked_example": false, "text": "Each page map entry contains a PPN, an R bit and a D bit, for a total of m+2 bits, which is 20 bits in our example."}, {"start": "00:03:26", "is_lecture": true, "end": "00:03:30", "is_worked_example": false, "text": "So there are approximately 20 million bits in the page map."}, {"start": "00:03:30", "is_lecture": true, "end": "00:03:38", "is_worked_example": false, "text": "If we were thinking of using a large special-purpose static RAM to hold the page map, this would get pretty expensive!"}, {"start": "00:03:38", "is_lecture": true, "end": "00:03:42", "is_worked_example": false, "text": "But why use a special-purpose memory for the page map?"}, {"start": "00:03:42", "is_lecture": true, "end": "00:03:47", "is_worked_example": false, "text": "Why not use a portion of main memory, which we have a lot of and have already bought and paid for?"}, {"start": "00:03:47", "is_lecture": true, "end": "00:03:54", "is_worked_example": false, "text": "We could use a register, called the page map pointer, to hold the address of the page map array in main memory."}, {"start": "00:03:54", "is_lecture": true, "end": "00:03:59", "is_worked_example": false, "text": "In other words, the page map would occupy some number of dedicated physical pages."}, {"start": "00:03:59", "is_lecture": true, "end": "00:04:10", "is_worked_example": false, "text": "Using the desired virtual page number as an index, the hardware could perform the usual array access calculation to fetch the needed page map entry from main memory."}, {"start": "00:04:10", "is_lecture": true, "end": "00:04:19", "is_worked_example": false, "text": "The downside of this proposed implementation is that it now takes two accesses to physical memory to perform one virtual access:"}, {"start": "00:04:19", "is_lecture": true, "end": "00:04:28", "is_worked_example": false, "text": "the first to retrieve the page table entry needed for the virtual-to-physical address translation, and the second to actually access the requested location."}, {"start": "00:04:28", "is_lecture": true, "end": "00:04:31", "is_worked_example": false, "text": "Once again, caches to the rescue."}, {"start": "00:04:31", "is_lecture": true, "end": "00:04:41", "is_worked_example": false, "text": "Most systems incorporate a special-purpose cache, called a translation look-aside buffer (TLB), that maps virtual page numbers to physical page numbers."}, {"start": "00:04:41", "is_lecture": true, "end": "00:04:45", "is_worked_example": false, "text": "The TLB is usually small and quite fast."}, {"start": "00:04:45", "is_lecture": true, "end": "00:04:51", "is_worked_example": false, "text": "It's usually fully-associative to ensure the best possible hit ratio by avoiding collisions."}, {"start": "00:04:51", "is_lecture": true, "end": "00:05:03", "is_worked_example": false, "text": "If the PPN is found by using the TLB, the access to main memory for the page table entry can be avoided, and we're back to a single physical access for each virtual access."}, {"start": "00:05:03", "is_lecture": true, "end": "00:05:09", "is_worked_example": false, "text": "The hit ratio of a TLB is quite high, usually better than 99%."}, {"start": "00:05:09", "is_lecture": true, "end": "00:05:19", "is_worked_example": false, "text": "This isn't too surprising since locality and the notion of a working set suggest that only a small number of pages are in active use over short periods of time."}, {"start": "00:05:19", "is_lecture": true, "end": "00:05:28", "is_worked_example": false, "text": "As we'll see in a few slides, there are interesting variations to this simple TLB page-map-in-main-memory architecture."}, {"start": "00:05:28", "is_lecture": true, "end": "00:05:31", "is_worked_example": false, "text": "But the basic strategy will remain the same."}, {"start": "00:05:31", "is_lecture": true, "end": "00:05:33", "is_worked_example": false, "text": "Putting it all together:"}, {"start": "00:05:33", "is_lecture": true, "end": "00:05:43", "is_worked_example": false, "text": "the virtual address generated by the CPU is first processed by the TLB to see if the appropriate translation from VPN to PPN has been cached."}, {"start": "00:05:43", "is_lecture": true, "end": "00:05:47", "is_worked_example": false, "text": "If so, the main memory access can proceed directly."}, {"start": "00:05:47", "is_lecture": true, "end": "00:05:55", "is_worked_example": false, "text": "If the desired mapping is not in the TLB, the appropriate entry in the page map is accessed in main memory."}, {"start": "00:05:55", "is_lecture": true, "end": "00:06:02", "is_worked_example": false, "text": "If the page is resident, the PPN field of the page map entry is used to complete the address translation."}, {"start": "00:06:02", "is_lecture": true, "end": "00:06:11", "is_worked_example": false, "text": "And, of course, the translation is cached in the TLB so that subsequent accesses to this page can avoid the access to the page map."}, {"start": "00:06:11", "is_lecture": true, "end": "00:06:20", "is_worked_example": false, "text": "If the desired page is not resident, the MMU triggers a page fault exception and the page fault handler code will deal with the problem."}, {"start": "00:06:20", "is_lecture": true, "end": "00:06:24", "is_worked_example": false, "text": "Here's a final example showing all the pieces in action."}, {"start": "00:06:24", "is_lecture": true, "end": "00:06:30", "is_worked_example": false, "text": "In this example, p = 10, v = 22, and m = 14."}, {"start": "00:06:30", "is_lecture": true, "end": "00:06:35", "is_worked_example": false, "text": "How many pages can reside in physical memory at one time?"}, {"start": "00:06:35", "is_lecture": true, "end": "00:06:40", "is_worked_example": false, "text": "There are 2^m physical pages, so 2^14."}, {"start": "00:06:40", "is_lecture": true, "end": "00:06:44", "is_worked_example": false, "text": "How many entries are there in the page table?"}, {"start": "00:06:44", "is_lecture": true, "end": "00:06:52", "is_worked_example": false, "text": "There's one entry for each virtual page and there are 2^v virtual pages, so there are 2^22 entries in the page table."}, {"start": "00:06:52", "is_lecture": true, "end": "00:06:56", "is_worked_example": false, "text": "How many bits per entry in the page table?"}, {"start": "00:06:56", "is_lecture": true, "end": "00:07:00", "is_worked_example": false, "text": "Assume each entry holds the PPN, the resident bit, and the dirty bit."}, {"start": "00:07:00", "is_lecture": true, "end": "00:07:07", "is_worked_example": false, "text": "Since the PPN is m bits, there are m+2 bits in each entry, so 16 bits."}, {"start": "00:07:07", "is_lecture": true, "end": "00:07:10", "is_worked_example": false, "text": "How many pages does the page table occupy?"}, {"start": "00:07:10", "is_lecture": true, "end": "00:07:23", "is_worked_example": false, "text": "There are 2^v page table entries, each occupying (m+2)/8 bytes, so the total size of the page table in this example is 2^23 bytes."}, {"start": "00:07:23", "is_lecture": true, "end": "00:07:35", "is_worked_example": false, "text": "Each page holds 2^p = 2^10 bytes, so the page table occupies 2^23/2^10 = 2^13 pages."}, {"start": "00:07:35", "is_lecture": true, "end": "00:07:40", "is_worked_example": false, "text": "What fraction of virtual memory can be resident at any given time?"}, {"start": "00:07:40", "is_lecture": true, "end": "00:07:45", "is_worked_example": false, "text": "There are 2^v virtual pages, of which 2^m can be resident."}, {"start": "00:07:45", "is_lecture": true, "end": "00:07:56", "is_worked_example": false, "text": "So the fraction of resident pages is 2^m/2^v = 2^14/2^22 = 1/2^8."}, {"start": "00:07:56", "is_lecture": true, "end": "00:08:03", "is_worked_example": false, "text": "What is the physical address for virtual address 0x1804?"}, {"start": "00:08:03", "is_lecture": true, "end": "00:08:07", "is_worked_example": false, "text": "Which MMU components are involved in the translation?"}, {"start": "00:08:07", "is_lecture": true, "end": "00:08:12", "is_worked_example": false, "text": "First we have to decompose the virtual address into VPN and offset."}, {"start": "00:08:12", "is_lecture": true, "end": "00:08:17", "is_worked_example": false, "text": "The offset is the low-order 10 bits, so is 0x004 in this example."}, {"start": "00:08:17", "is_lecture": true, "end": "00:08:22", "is_worked_example": false, "text": "The VPN is the remaining address bits, so the VPN is 0x6."}, {"start": "00:08:22", "is_lecture": true, "end": "00:08:28", "is_worked_example": false, "text": "Looking first in the TLB, we that the VPN-to-PPN mapping for VPN 0x6 is cached,"}, {"start": "00:08:28", "is_lecture": true, "end": "00:08:40", "is_worked_example": false, "text": "so we can construct the physical address by concatenating the PPN (0x2) with the 10-bit offset (0x4) to get a physical address of 0x804."}, {"start": "00:08:40", "is_lecture": true, "end": "00:08:41", "is_worked_example": false, "text": "You're right!"}, {"start": "00:08:41", "is_lecture": true, "end": "00:08:46", "is_worked_example": false, "text": "It's a bit of pain to do all the bit manipulations when p is not a multiple of 4."}, {"start": "00:08:46", "is_lecture": true, "end": "00:08:50", "is_worked_example": false, "text": "How about virtual address 0x1080?"}, {"start": "00:08:50", "is_lecture": true, "end": "00:08:55", "is_worked_example": false, "text": "For this address the VPN is 0x4 and the offset is 0x80."}, {"start": "00:08:55", "is_lecture": true, "end": "00:09:05", "is_worked_example": false, "text": "The translation for VPN 0x4 is not cached in the TLB, so we have to check the page map, which tells us that the page is resident in physical page 5."}, {"start": "00:09:05", "is_lecture": true, "end": "00:09:11", "is_worked_example": false, "text": "Concatenating the PPN and offset, we get 0x1480 as the physical address."}, {"start": "00:09:11", "is_lecture": true, "end": "00:09:16", "is_worked_example": false, "text": "Finally, how about virtual address 0x0FC?"}, {"start": "00:09:16", "is_lecture": true, "end": "00:09:20", "is_worked_example": false, "text": "Here the VPN is 0 and the offset 0xFC."}, {"start": "00:09:20", "is_lecture": true, "end": "00:09:32", "is_worked_example": false, "text": "The mapping for VPN 0 is not found in the TLB and checking the page map reveals that VPN 0 is not resident in main memory, so a page fault exception is triggered."}, {"start": "00:09:32", "is_lecture": true, "end": "00:09:40", "is_worked_example": false, "text": "There are a few things to note about the example TLB and page map contents."}, {"start": "00:09:40", "is_lecture": true, "end": "00:09:44", "is_worked_example": false, "text": "Note that a TLB entry can be invalid (it's R bit is 0)."}, {"start": "00:09:44", "is_lecture": true, "end": "00:09:53", "is_worked_example": false, "text": "This can happen when a virtual page is replaced, so when we change the R bit to 0 in the page map, we have to do the same in the TLB."}, {"start": "00:09:53", "is_lecture": true, "end": "00:09:58", "is_worked_example": false, "text": "And should we be concerned that PPN 0x5 appears twice in the page table?"}, {"start": "00:09:58", "is_lecture": true, "end": "00:10:04", "is_worked_example": false, "text": "Note that the entry for VPN 0x3 doesn't matter since it's R bit is 0."}, {"start": "00:10:04", "is_lecture": true, "end": "00:10:12", "is_worked_example": false, "text": "Typically when marking a page not resident, we don't bother to clear out the other fields in the entry since they won't be used when R=0."}, {"start": "00:10:12", "is_lecture": true, "end": "00:10:16", "is_worked_example": false, "text": "So there's only one *valid* mapping to PPN 5."}]}, "C05S01B04-LEC.srt": {"url": "https://courses.edx.org/courses/course-v1:MITx+6.004.3x+2T2016/courseware/c5/c5s1/4?activate_block_id=block-v1%3AMITx%2B6.004.3x%2B2T2016%2Btype%40discussion%2Bblock%40c5s1v4", "items": [{"start": "00:00:00", "is_lecture": true, "end": "00:00:09", "is_worked_example": false, "text": "Let's review what happens when the CPU accesses a non-resident virtual page, i.e., a page with its resident bit set to 0."}, {"start": "00:00:09", "is_lecture": true, "end": "00:00:15", "is_worked_example": false, "text": "In the example shown here, the CPU is trying to access virtual page 5."}, {"start": "00:00:15", "is_lecture": true, "end": "00:00:27", "is_worked_example": false, "text": "In this case, the MMU signals a page fault exception, causing the CPU to suspend execution of the program and switch to the page fault handler, which is code that deals with the page fault."}, {"start": "00:00:27", "is_lecture": true, "end": "00:00:39", "is_worked_example": false, "text": "The handler starts by either finding an unused physical page or, if necessary, creating an unused page by selecting an in-use page and making it available."}, {"start": "00:00:39", "is_lecture": true, "end": "00:00:44", "is_worked_example": false, "text": "In our example, the handler has chosen virtual page 1 for reuse."}, {"start": "00:00:44", "is_lecture": true, "end": "00:00:55", "is_worked_example": false, "text": "If the selected page is dirty, i.e., its D bit is 1 indicating that its contents have changed since being read from secondary storage, write it back to secondary storage."}, {"start": "00:00:55", "is_lecture": true, "end": "00:01:00", "is_worked_example": false, "text": "Finally, mark the selected virtual page as no longer resident."}, {"start": "00:01:00", "is_lecture": true, "end": "00:01:07", "is_worked_example": false, "text": "In the \"after\" figure, we see that the R bit for virtual page 1 has been set to 0."}, {"start": "00:01:07", "is_lecture": true, "end": "00:01:10", "is_worked_example": false, "text": "Now physical page 4 is available for re-use."}, {"start": "00:01:10", "is_lecture": true, "end": "00:01:15", "is_worked_example": false, "text": "Are there any restrictions on which page we can select?"}, {"start": "00:01:15", "is_lecture": true, "end": "00:01:20", "is_worked_example": false, "text": "Obviously, we can't select the page that holds the code for the page fault handler."}, {"start": "00:01:20", "is_lecture": true, "end": "00:01:24", "is_worked_example": false, "text": "Pages immune from selection are called \"wired\" pages."}, {"start": "00:01:24", "is_lecture": true, "end": "00:01:36", "is_worked_example": false, "text": "And it would very inefficient to choose the page that holds the code that made the initial memory access, since we expect to start executing that code as soon as we finish handling the page fault."}, {"start": "00:01:36", "is_lecture": true, "end": "00:01:42", "is_worked_example": false, "text": "The optimal strategy would be to choose the page whose next use will occur farthest in the future."}, {"start": "00:01:42", "is_lecture": true, "end": "00:01:49", "is_worked_example": false, "text": "But, of course, this involves knowledge of future execution paths and so isn't a realizable strategy."}, {"start": "00:01:49", "is_lecture": true, "end": "00:02:00", "is_worked_example": false, "text": "Wikipedia provides a nice description of the many strategies for choosing a replacement page, with their various tradeoffs between ease of implementation and impact on the rate of page faults --"}, {"start": "00:02:00", "is_lecture": true, "end": "00:02:03", "is_worked_example": false, "text": "see the URL given at the bottom of the slide."}, {"start": "00:02:03", "is_lecture": true, "end": "00:02:13", "is_worked_example": false, "text": "The aging algorithm they describe is frequently used since it offers near optimal performance at a moderate implementation cost."}, {"start": "00:02:13", "is_lecture": true, "end": "00:02:20", "is_worked_example": false, "text": "Next, the desired virtual page is read from secondary storage into the selected physical page."}, {"start": "00:02:20", "is_lecture": true, "end": "00:02:26", "is_worked_example": false, "text": "In our example, virtual page 5 is now loaded into physical page 4."}, {"start": "00:02:26", "is_lecture": true, "end": "00:02:37", "is_worked_example": false, "text": "Then the R bit and PPN fields in the page table entry for virtual page 5 are updated to indicate that the contents of that virtual page now reside in physical page 4."}, {"start": "00:02:37", "is_lecture": true, "end": "00:02:46", "is_worked_example": false, "text": "Finally the handler is finished and execution of the original program is resumed, re-executing the instruction that caused the page fault."}, {"start": "00:02:46", "is_lecture": true, "end": "00:02:53", "is_worked_example": false, "text": "Since the page map has been updated, this time the access succeeds and execution continues."}, {"start": "00:02:53", "is_lecture": true, "end": "00:02:58", "is_worked_example": false, "text": "To double-check our understanding of page faults, let's run through an example."}, {"start": "00:02:58", "is_lecture": true, "end": "00:03:11", "is_worked_example": false, "text": "Here's the same setup as in our previous example, but this time consider a store instruction that's making an access to virtual address 0x600, which is located on virtual page 6."}, {"start": "00:03:11", "is_lecture": true, "end": "00:03:23", "is_worked_example": false, "text": "Checking the page table entry for VPN 6, we see that its R bit 0 indicating that it is NOT resident in main memory, which causes a page fault exception."}, {"start": "00:03:23", "is_lecture": true, "end": "00:03:30", "is_worked_example": false, "text": "The page fault handler selects VPN 0xE for replacement since we've been told in the setup that it's the least-recently-used page."}, {"start": "00:03:30", "is_lecture": true, "end": "00:03:42", "is_worked_example": false, "text": "The page table entry for VPN 0xE has D=1 so the handler writes the contents of VPN 0xE, which is found in PPN 0x5, to secondary storage."}, {"start": "00:03:42", "is_lecture": true, "end": "00:03:48", "is_worked_example": false, "text": "Then it updates the page table to indicate that VPN 0xE is no longer resident."}, {"start": "00:03:48", "is_lecture": true, "end": "00:03:55", "is_worked_example": false, "text": "Next, the contents of VPN 0x6 are read from secondary storage into the now available PPN 0x5."}, {"start": "00:03:55", "is_lecture": true, "end": "00:04:04", "is_worked_example": false, "text": "Now the handler updates the page table entry for VPN 0x6 to indicate that it's resident in PPN 0x5."}, {"start": "00:04:04", "is_lecture": true, "end": "00:04:12", "is_worked_example": false, "text": "The page fault handler has completed its work, so program execution resumes and the ST instruction is re-executed."}, {"start": "00:04:12", "is_lecture": true, "end": "00:04:21", "is_worked_example": false, "text": "This time the MMU is able to translate virtual address 0x600 to physical address 0x500."}, {"start": "00:04:21", "is_lecture": true, "end": "00:04:27", "is_worked_example": false, "text": "And since the ST instruction modifies the contents of VPN 0x6, its D bit is set to 1."}, {"start": "00:04:27", "is_lecture": true, "end": "00:04:29", "is_worked_example": false, "text": "Whew!  We're done :)"}, {"start": "00:04:29", "is_lecture": true, "end": "00:04:38", "is_worked_example": false, "text": "We can think of the work of the MMU as being divided into two tasks, which as computer scientists, we would think of as two procedures."}, {"start": "00:04:38", "is_lecture": true, "end": "00:04:45", "is_worked_example": false, "text": "In this formulation the information in the page map is held in several arrays: the R array holds the resident bits,"}, {"start": "00:04:45", "is_lecture": true, "end": "00:04:50", "is_worked_example": false, "text": "the D array holds the dirty bits, the PPN array holds the physical page numbers,"}, {"start": "00:04:50", "is_lecture": true, "end": "00:04:57", "is_worked_example": false, "text": "and the DiskAdr array holds the location in secondary storage for each virtual page."}, {"start": "00:04:57", "is_lecture": true, "end": "00:05:05", "is_worked_example": false, "text": "The VtoP procedure is invoked on each memory access to translate the virtual address into a physical address."}, {"start": "00:05:05", "is_lecture": true, "end": "00:05:11", "is_worked_example": false, "text": "If the requested virtual page is not resident, the PageFault procedure is invoked to make the page resident."}, {"start": "00:05:11", "is_lecture": true, "end": "00:05:23", "is_worked_example": false, "text": "Once the requested page is resident, the VPN is used as an index to lookup the corresponding PPN, which is then concatenated with the page offset to form the physical address."}, {"start": "00:05:23", "is_lecture": true, "end": "00:05:30", "is_worked_example": false, "text": "The PageFault routine starts by selecting a virtual page to be replaced, writing out its contents if it's dirty."}, {"start": "00:05:30", "is_lecture": true, "end": "00:05:34", "is_worked_example": false, "text": "The selected page is then marked as not resident."}, {"start": "00:05:34", "is_lecture": true, "end": "00:05:45", "is_worked_example": false, "text": "Finally the desired virtual page is read from secondary storage and the page map information updated to reflect that it's now resident in the newly filled physical page."}, {"start": "00:05:45", "is_lecture": true, "end": "00:05:52", "is_worked_example": false, "text": "We'll use hardware to implement the VtoP functionality since it's needed for every memory access."}, {"start": "00:05:52", "is_lecture": true, "end": "00:06:04", "is_worked_example": false, "text": "The call to the PageFault procedure is accomplished via a page fault exception, which directs the CPU to execute the appropriate handler software that contains the PageFault procedure."}, {"start": "00:06:04", "is_lecture": true, "end": "00:06:17", "is_worked_example": false, "text": "This is a good strategy to pursue in all our implementation choices: use hardware for the operations that need to be fast, but use exceptions to handle the (hopefully infrequent) exceptional cases in software."}, {"start": "00:06:17", "is_lecture": true, "end": "00:06:33", "is_worked_example": false, "text": "Since the software is executed by the CPU, which is itself a piece of hardware, what we're really doing is making the tradeoff between using special-purpose hardware (e.g., the MMU) or using general-purpose hardware (e.g., the CPU)."}, {"start": "00:06:33", "is_lecture": true, "end": "00:06:47", "is_worked_example": false, "text": "In general, one should be skeptical of proposals to use special-purpose hardware, reserving that choice for operations that truly are commonplace and whose performance is critical to the overall performance of the system."}]}, "C05S01B02-LEC.srt": {"url": "https://courses.edx.org/courses/course-v1:MITx+6.004.3x+2T2016/courseware/c5/c5s1/2?activate_block_id=block-v1%3AMITx%2B6.004.3x%2B2T2016%2Btype%40discussion%2Bblock%40c5s1v2", "items": [{"start": "00:00:00", "is_lecture": true, "end": "00:00:03", "is_worked_example": false, "text": "Here's how our virtual memory system will work."}, {"start": "00:00:03", "is_lecture": true, "end": "00:00:11", "is_worked_example": false, "text": "The memory addresses generated by the CPU are called virtual addresses to distinguish them from the physical addresses used by main memory."}, {"start": "00:00:11", "is_lecture": true, "end": "00:00:19", "is_worked_example": false, "text": "In between the CPU and main memory there's a new piece of hardware called the memory management unit (MMU)."}, {"start": "00:00:19", "is_lecture": true, "end": "00:00:24", "is_worked_example": false, "text": "The MMU's job is to translate virtual addresses to physical addresses."}, {"start": "00:00:24", "is_lecture": true, "end": "00:00:26", "is_worked_example": false, "text": "\"But wait!\" you say."}, {"start": "00:00:26", "is_lecture": true, "end": "00:00:30", "is_worked_example": false, "text": "\"Doesn't the cache go between the CPU and main memory?\""}, {"start": "00:00:30", "is_lecture": true, "end": "00:00:36", "is_worked_example": false, "text": "You're right and at the end of this lecture we'll talk about how to use both an MMU and a cache."}, {"start": "00:00:36", "is_lecture": true, "end": "00:00:40", "is_worked_example": false, "text": "But for now, let's assume there's only an MMU and no cache."}, {"start": "00:00:40", "is_lecture": true, "end": "00:00:48", "is_worked_example": false, "text": "The MMU hardware translates virtual addresses to physical addresses using a simple table lookup."}, {"start": "00:00:48", "is_lecture": true, "end": "00:00:51", "is_worked_example": false, "text": "This table is called the page map or page table."}, {"start": "00:00:51", "is_lecture": true, "end": "00:01:00", "is_worked_example": false, "text": "Conceptually, the MMU uses the virtual address as index to select an entry in the table, which tells us the corresponding physical address."}, {"start": "00:01:00", "is_lecture": true, "end": "00:01:05", "is_worked_example": false, "text": "The table allows a particular virtual address to be found anywhere in main memory."}, {"start": "00:01:05", "is_lecture": true, "end": "00:01:12", "is_worked_example": false, "text": "In normal operation we'd want to ensure that two virtual addresses don't map to the same physical address."}, {"start": "00:01:12", "is_lecture": true, "end": "00:01:19", "is_worked_example": false, "text": "But it would be okay if some of the virtual addresses did not have a translation to a physical address."}, {"start": "00:01:19", "is_lecture": true, "end": "00:01:29", "is_worked_example": false, "text": "This would indicate that the contents of the requested virtual address haven't yet been loaded into main memory, so the MMU would signal a memory-management exception to the CPU,"}, {"start": "00:01:29", "is_lecture": true, "end": "00:01:38", "is_worked_example": false, "text": "which could assign a location in physical memory and perform the required I/O operation to initialize that location from secondary storage."}, {"start": "00:01:38", "is_lecture": true, "end": "00:01:47", "is_worked_example": false, "text": "The MMU table gives the system a lot of control over how physical memory is accessed by the program running on the CPU."}, {"start": "00:01:47", "is_lecture": true, "end": "00:01:57", "is_worked_example": false, "text": "For example, we could arrange to run multiple programs in quick succession (a technique called time sharing) by changing the page map when we change programs."}, {"start": "00:01:57", "is_lecture": true, "end": "00:02:06", "is_worked_example": false, "text": "Main memory locations accessible to one program could be made inaccessible to another program by proper management of their respective page maps."}, {"start": "00:02:06", "is_lecture": true, "end": "00:02:17", "is_worked_example": false, "text": "And we could use memory-management exceptions to load program contents into main memory on demand instead of having to load the entire program before execution starts."}, {"start": "00:02:17", "is_lecture": true, "end": "00:02:24", "is_worked_example": false, "text": "In fact, we only need to ensure the current working set of a program is actually resident in main memory."}, {"start": "00:02:24", "is_lecture": true, "end": "00:02:29", "is_worked_example": false, "text": "Locations not currently being used could live in secondary storage until needed."}, {"start": "00:02:29", "is_lecture": true, "end": "00:02:37", "is_worked_example": false, "text": "In this lecture and next, we'll see how the MMU plays a central role in the design of a modern timesharing computer system."}, {"start": "00:02:37", "is_lecture": true, "end": "00:02:45", "is_worked_example": false, "text": "Of course, we'd need an impossibly large table to separately map each virtual address to a physical address."}, {"start": "00:02:45", "is_lecture": true, "end": "00:02:52", "is_worked_example": false, "text": "So instead we divide both the virtual and physical address spaces into fixed-sized blocks, called pages."}, {"start": "00:02:52", "is_lecture": true, "end": "00:03:03", "is_worked_example": false, "text": "Page sizes are always a power-of-2 bytes, say 2^p bytes, so p is the number address bits needed to select a particular location on the page."}, {"start": "00:03:03", "is_lecture": true, "end": "00:03:08", "is_worked_example": false, "text": "We'll the use low-order p bits of the virtual or physical address as the page offset."}, {"start": "00:03:08", "is_lecture": true, "end": "00:03:15", "is_worked_example": false, "text": "The remaining address bits tell us which page is being accessed and are called the page number."}, {"start": "00:03:15", "is_lecture": true, "end": "00:03:24", "is_worked_example": false, "text": "A typical page size is 4KB to 16KB, which correspond to p=12 and p=14 respectively."}, {"start": "00:03:24", "is_lecture": true, "end": "00:03:26", "is_worked_example": false, "text": "Suppose p=12."}, {"start": "00:03:26", "is_lecture": true, "end": "00:03:38", "is_worked_example": false, "text": "If the CPU produces a 32-bit virtual address, the low-order 12 bits of the virtual address are the page offset and the high-order 20 bits are the virtual page number."}, {"start": "00:03:38", "is_lecture": true, "end": "00:03:47", "is_worked_example": false, "text": "Similarly, the low-order p bits of the physical address are the page offset and the remaining physical address bits are the physical page number."}, {"start": "00:03:47", "is_lecture": true, "end": "00:03:53", "is_worked_example": false, "text": "The key idea is that the MMU will manage pages, not individual locations."}, {"start": "00:03:53", "is_lecture": true, "end": "00:03:57", "is_worked_example": false, "text": "We'll move entire pages from secondary storage into main memory."}, {"start": "00:03:57", "is_lecture": true, "end": "00:04:07", "is_worked_example": false, "text": "By the principal of locality, if a program access one location on a page, we expect it will soon access other nearby locations."}, {"start": "00:04:07", "is_lecture": true, "end": "00:04:18", "is_worked_example": false, "text": "By choosing the page offset from the low-order address bits, we'll ensure that nearby locations live on the same page (unless of course we're near one end of the page or the other)."}, {"start": "00:04:18", "is_lecture": true, "end": "00:04:22", "is_worked_example": false, "text": "So pages naturally capture the notion of locality."}, {"start": "00:04:22", "is_lecture": true, "end": "00:04:27", "is_worked_example": false, "text": "And since pages are large, by dealing with pages when accessing secondary storage,"}, {"start": "00:04:27", "is_lecture": true, "end": "00:04:35", "is_worked_example": false, "text": "we'll take advantage that reading or writing many locations is only slightly more time consuming than accessing the first location."}, {"start": "00:04:35", "is_lecture": true, "end": "00:04:40", "is_worked_example": false, "text": "The MMU will map virtual page numbers to physical page numbers."}, {"start": "00:04:40", "is_lecture": true, "end": "00:04:47", "is_worked_example": false, "text": "It does this by using the virtual page number (VPN) as an index into the page table."}, {"start": "00:04:47", "is_lecture": true, "end": "00:04:55", "is_worked_example": false, "text": "Each entry in the page table indicates if the page is resident in main memory and, if it is, provides the appropriate physical page number (PPN)."}, {"start": "00:04:55", "is_lecture": true, "end": "00:05:02", "is_worked_example": false, "text": "The PPN is combined with the page offset to form the physical address for main memory."}, {"start": "00:05:02", "is_lecture": true, "end": "00:05:13", "is_worked_example": false, "text": "If the requested virtual page is NOT resident in main memory, the MMU signals a memory-management exception, called a page fault, to the CPU"}, {"start": "00:05:13", "is_lecture": true, "end": "00:05:20", "is_worked_example": false, "text": "so it can load the appropriate page from secondary storage and set up the appropriate mapping in the MMU."}, {"start": "00:05:20", "is_lecture": true, "end": "00:05:31", "is_worked_example": false, "text": "Our plan to use main memory as page cache is called \"paging\" or sometimes \"demand paging\" since movements of pages to and from secondary storage is determined by the demands of the program."}, {"start": "00:05:31", "is_lecture": true, "end": "00:05:34", "is_worked_example": false, "text": "So here's the plan."}, {"start": "00:05:34", "is_lecture": true, "end": "00:05:44", "is_worked_example": false, "text": "Initially all the virtual pages for a program reside in secondary storage and the MMU is empty, i.e., there are no pages resident in physical memory."}, {"start": "00:05:44", "is_lecture": true, "end": "00:05:56", "is_worked_example": false, "text": "The CPU starts running the program and each virtual address it generates, either for an instruction fetch or data access, is passed to the MMU to be mapped to a physical address in main memory."}, {"start": "00:05:56", "is_lecture": true, "end": "00:06:02", "is_worked_example": false, "text": "If the virtual address is resident in physical memory, the main memory hardware can complete the access."}, {"start": "00:06:02", "is_lecture": true, "end": "00:06:15", "is_worked_example": false, "text": "If the virtual address in NOT resident in physical memory, the MMU signals a page fault exception, forcing the CPU to switch execution to special code called the page fault handler."}, {"start": "00:06:15", "is_lecture": true, "end": "00:06:25", "is_worked_example": false, "text": "The handler allocates a physical page to hold the requested virtual page and loads the virtual page from secondary storage into main memory."}, {"start": "00:06:25", "is_lecture": true, "end": "00:06:37", "is_worked_example": false, "text": "It then adjusts the page map entry for the requested virtual page to show that it is now resident and to indicate the physical page number for the newly allocated and initialized physical page."}, {"start": "00:06:37", "is_lecture": true, "end": "00:06:45", "is_worked_example": false, "text": "When trying to allocate a physical page, the handler may discover that all physical pages are currently in use."}, {"start": "00:06:45", "is_lecture": true, "end": "00:06:54", "is_worked_example": false, "text": "In this case it chooses an existing page to replace, e.g., a resident virtual page that hasn't been recently accessed."}, {"start": "00:06:54", "is_lecture": true, "end": "00:07:05", "is_worked_example": false, "text": "It swaps the contents of the chosen virtual page out to secondary storage and updates the page map entry for the replaced virtual page to indicate it is no longer resident."}, {"start": "00:07:05", "is_lecture": true, "end": "00:07:11", "is_worked_example": false, "text": "Now there's a free physical page to re-use to hold the contents of the virtual page that was missing."}, {"start": "00:07:11", "is_lecture": true, "end": "00:07:22", "is_worked_example": false, "text": "The working set of the program, i.e., the set of pages the program is currently accessing, is loaded into main memory through a series of page faults."}, {"start": "00:07:22", "is_lecture": true, "end": "00:07:36", "is_worked_example": false, "text": "After a flurry of page faults when the program starts running, the working set changes slowly, so the frequency of page faults drops dramatically, perhaps close to zero if the program is small and well-behaved."}, {"start": "00:07:36", "is_lecture": true, "end": "00:07:42", "is_worked_example": false, "text": "It is possible to write programs that consistently generate page faults, a phenomenon called thrashing."}, {"start": "00:07:42", "is_lecture": true, "end": "00:07:55", "is_worked_example": false, "text": "Given the long access times of secondary storage, a program that's thrashing runs *very* slowly, usually so slowly that users give up and rewrite the program to behave more sensibly."}, {"start": "00:07:55", "is_lecture": true, "end": "00:07:59", "is_worked_example": false, "text": "The design of the page map is straightforward."}, {"start": "00:07:59", "is_lecture": true, "end": "00:08:03", "is_worked_example": false, "text": "There's one entry in the page map for each virtual page."}, {"start": "00:08:03", "is_lecture": true, "end": "00:08:17", "is_worked_example": false, "text": "For example, if the CPU generates a 32-bit virtual address and the page size is 2^12 bytes, the virtual page number has 32-12 = 20 bits and the page table will have 2^20 entries."}, {"start": "00:08:17", "is_lecture": true, "end": "00:08:27", "is_worked_example": false, "text": "Each entry in the page table contains a \"resident bit\" (R) which is set to 1 when the virtual page is resident in physical memory."}, {"start": "00:08:27", "is_lecture": true, "end": "00:08:32", "is_worked_example": false, "text": "If R is 0, an access to that virtual page will cause a page fault."}, {"start": "00:08:32", "is_lecture": true, "end": "00:08:41", "is_worked_example": false, "text": "If R is 1, the entry also contains the PPN, indicating where to find the virtual page in main memory."}, {"start": "00:08:41", "is_lecture": true, "end": "00:08:46", "is_worked_example": false, "text": "There's one additional state bit called the \"dirty bit\" (D)."}, {"start": "00:08:46", "is_lecture": true, "end": "00:08:57", "is_worked_example": false, "text": "When a page has just been loaded from secondary storage, it's \"clean\", i.e, the contents of physical memory match the contents of the page in secondary storage."}, {"start": "00:08:57", "is_lecture": true, "end": "00:09:00", "is_worked_example": false, "text": "So the D bit is set to 0."}, {"start": "00:09:00", "is_lecture": true, "end": "00:09:14", "is_worked_example": false, "text": "If subsequently the CPU stores into a location on the page, the D bit for the page is set to 1, indicating the page is \"dirty\", i.e., the contents of memory now differ from the contents of secondary storage."}, {"start": "00:09:14", "is_lecture": true, "end": "00:09:25", "is_worked_example": false, "text": "If a dirty page is ever chosen for replacement, its contents must be written to secondary storage in order to save the changes before the page gets reused."}, {"start": "00:09:25", "is_lecture": true, "end": "00:09:30", "is_worked_example": false, "text": "Some MMUs have additional state bits in each page table entry."}, {"start": "00:09:30", "is_lecture": true, "end": "00:09:38", "is_worked_example": false, "text": "For example, there could be a \"read-only\" bit which, when set, would generate an exception if the program attempts to store into the page."}, {"start": "00:09:38", "is_lecture": true, "end": "00:09:46", "is_worked_example": false, "text": "This would be useful for protecting code pages from accidentally being corrupted by errant data accesses, a very handy debugging feature."}, {"start": "00:09:46", "is_lecture": true, "end": "00:09:50", "is_worked_example": false, "text": "Here's an example of the MMU in action."}, {"start": "00:09:50", "is_lecture": true, "end": "00:09:59", "is_worked_example": false, "text": "To make things simple, assume that the virtual address is 12 bits, consisting of an 8-bit page offset and a 4-bit virtual page number."}, {"start": "00:09:59", "is_lecture": true, "end": "00:10:03", "is_worked_example": false, "text": "So there are 2^4 = 16 virtual pages."}, {"start": "00:10:03", "is_lecture": true, "end": "00:10:11", "is_worked_example": false, "text": "The physical address is 11 bits, divided into the same 8-bit page offset and a 3-bit physical page number."}, {"start": "00:10:11", "is_lecture": true, "end": "00:10:14", "is_worked_example": false, "text": "So there are 2^3 = 8 physical pages."}, {"start": "00:10:14", "is_lecture": true, "end": "00:10:23", "is_worked_example": false, "text": "On the left we see a diagram showing the contents of the 16-entry page map, i.e., an entry for each virtual page."}, {"start": "00:10:23", "is_lecture": true, "end": "00:10:33", "is_worked_example": false, "text": "Each page table entry includes a dirty bit (D), a resident bit (R) and a 3-bit physical page number, for a total of 5 bits."}, {"start": "00:10:33", "is_lecture": true, "end": "00:10:40", "is_worked_example": false, "text": "So the page map has 16 entries, each with 5-bits, for a total of 16*5 = 80 bits."}, {"start": "00:10:40", "is_lecture": true, "end": "00:10:47", "is_worked_example": false, "text": "The first entry in the table is for virtual page 0, the second entry for virtual page 1, and so on."}, {"start": "00:10:47", "is_lecture": true, "end": "00:10:54", "is_worked_example": false, "text": "In the middle of the slide there's a diagram of physical memory showing the 8 physical pages."}, {"start": "00:10:54", "is_lecture": true, "end": "00:11:00", "is_worked_example": false, "text": "The annotation for each physical page shows the virtual page number of its contents."}, {"start": "00:11:00", "is_lecture": true, "end": "00:11:05", "is_worked_example": false, "text": "Note that there's no particular order to how virtual pages are stored in physical memory --"}, {"start": "00:11:05", "is_lecture": true, "end": "00:11:11", "is_worked_example": false, "text": "which page holds what is determined by which pages are free at the time of a page fault."}, {"start": "00:11:11", "is_lecture": true, "end": "00:11:18", "is_worked_example": false, "text": "In general, after the program has run for a while, we'd expected to find the sort of jumbled ordering we see here."}, {"start": "00:11:18", "is_lecture": true, "end": "00:11:29", "is_worked_example": false, "text": "Let's follow along as the MMU handles the request for virtual address 0x2C8, generated by the execution of the LD instruction shown here."}, {"start": "00:11:29", "is_lecture": true, "end": "00:11:39", "is_worked_example": false, "text": "Splitting the virtual address into page number and offset, we see that the VPN is 2 and the offset is 0xC8."}, {"start": "00:11:39", "is_lecture": true, "end": "00:11:49", "is_worked_example": false, "text": "Looking at the page map entry with index 2, we see that the R bit is 1, indicating that virtual page 2 is resident in physical memory."}, {"start": "00:11:49", "is_lecture": true, "end": "00:11:56", "is_worked_example": false, "text": "The PPN field of entry tells us that virtual page 2 can be found in physical page 4."}, {"start": "00:11:56", "is_lecture": true, "end": "00:12:08", "is_worked_example": false, "text": "Combining the PPN with the 8-bit offset, we find that the contents of virtual address 0x2C8 can be found in main memory location 0x4C8."}, {"start": "00:12:08", "is_lecture": true, "end": "00:12:13", "is_worked_example": false, "text": "Note that the offset is unchanged by the translation process --"}, {"start": "00:12:13", "is_lecture": true, "end": "00:12:19", "is_worked_example": false, "text": "the offset into the physical page is always the same as the offset into the virtual page."}]}, "C05S01B09-LEC.srt": {"url": "https://courses.edx.org/courses/course-v1:MITx+6.004.3x+2T2016/courseware/c5/c5s1/9?activate_block_id=block-v1%3AMITx%2B6.004.3x%2B2T2016%2Btype%40discussion%2Bblock%40c5s1v9", "items": [{"start": "00:00:00", "is_lecture": true, "end": "00:00:06", "is_worked_example": false, "text": "There are a few MMU implementation details we can tweak for more efficiency or functionality."}, {"start": "00:00:06", "is_lecture": true, "end": "00:00:13", "is_worked_example": false, "text": "In our simple page-map implementation, the full page map occupies some number of physical pages."}, {"start": "00:00:13", "is_lecture": true, "end": "00:00:23", "is_worked_example": false, "text": "Using the numbers shown here, if each page map occupies one word of main memory, we'd need 2^20 words (or 2^12 pages) to hold the page table."}, {"start": "00:00:23", "is_lecture": true, "end": "00:00:33", "is_worked_example": false, "text": "If we have multiple contexts, we would need multiple page tables, and the demands on our physical memory resources would start to get large."}, {"start": "00:00:33", "is_lecture": true, "end": "00:00:39", "is_worked_example": false, "text": "The MMU implementation shown here uses a hierarchical page map."}, {"start": "00:00:39", "is_lecture": true, "end": "00:00:50", "is_worked_example": false, "text": "The top 10 bits of virtual address are used to access a \"page directory\", which indicates the physical page that holds the page map for that segment of the virtual address space."}, {"start": "00:00:50", "is_lecture": true, "end": "00:00:59", "is_worked_example": false, "text": "The key idea is that the page map segments are in virtual memory, i.e., they don't all have to be resident at any given time."}, {"start": "00:00:59", "is_lecture": true, "end": "00:01:12", "is_worked_example": false, "text": "If the running application is only actively using a small portion of its virtual address space, we may only need a handful of pages to hold the page directory and the necessary page map segments."}, {"start": "00:01:12", "is_lecture": true, "end": "00:01:18", "is_worked_example": false, "text": "The resultant savings really add up when there are many applications, each with their own context."}, {"start": "00:01:18", "is_lecture": true, "end": "00:01:40", "is_worked_example": false, "text": "In this example, note that the middle entries in the page directory, i.e., the entries corresponding to the as-yet unallocated virtual memory between the stack and heap, are all marked as not resident. .133 So no page map resources need be devoted to holding a zillion page map entries all marked \"not resident\"."}, {"start": "00:01:40", "is_lecture": true, "end": "00:01:50", "is_worked_example": false, "text": "Accessing the page map now requires two access to main memory (first to the page directory, then to the appropriate segment of the page map),"}, {"start": "00:01:50", "is_lecture": true, "end": "00:01:54", "is_worked_example": false, "text": "but the TLB makes the impact of that additional access negligible."}, {"start": "00:01:54", "is_lecture": true, "end": "00:02:07", "is_worked_example": false, "text": "Normally when changing contexts, the OS would reload the page-table pointer to point to the appropriate page table (or page table directory if we adopt the scheme from the previous slide)."}, {"start": "00:02:07", "is_lecture": true, "end": "00:02:17", "is_worked_example": false, "text": "Since this context switch in effect changes all the entries in the page table, the OS would also have to invalidate all the entries in the TLB cache."}, {"start": "00:02:17", "is_lecture": true, "end": "00:02:30", "is_worked_example": false, "text": "This naturally has a huge impact on the TLB hit ratio and the average memory access time takes a huge hit because of the all page map accesses that are now necessary until the TLB is refilled."}, {"start": "00:02:30", "is_lecture": true, "end": "00:02:43", "is_worked_example": false, "text": "To reduce the impact of context switches, some MMUs include a context-number register whose contents are concatenated with the virtual page number to form the query to the TLB."}, {"start": "00:02:43", "is_lecture": true, "end": "00:02:53", "is_worked_example": false, "text": "Essentially this means that the tag field in the TLB cache entries will expand to include the context number provided at the time the TLB entry was filled."}, {"start": "00:02:53", "is_lecture": true, "end": "00:03:01", "is_worked_example": false, "text": "To switch contexts, the OS would now reload both the context-number register and the page-table pointer."}, {"start": "00:03:01", "is_lecture": true, "end": "00:03:10", "is_worked_example": false, "text": "With a new context number, entries in the TLB for other contexts would no longer match, so no need to flush the TLB on a context switch."}, {"start": "00:03:10", "is_lecture": true, "end": "00:03:24", "is_worked_example": false, "text": "If the TLB has sufficient capacity to cache the VPN-to-PPN mappings for several contexts, context switches would no longer have a substantial impact on average memory access time."}, {"start": "00:03:24", "is_lecture": true, "end": "00:03:32", "is_worked_example": false, "text": "Finally, let's return to the question about how to incorporate both a cache and an MMU into our memory system."}, {"start": "00:03:32", "is_lecture": true, "end": "00:03:39", "is_worked_example": false, "text": "The first choice is to place the cache between the CPU and the MMU, i.e., the cache would work on virtual addresses."}, {"start": "00:03:39", "is_lecture": true, "end": "00:03:47", "is_worked_example": false, "text": "This seems good: the cost of the VPN-to-PPN translation is only incurred on a cache miss."}, {"start": "00:03:47", "is_lecture": true, "end": "00:03:54", "is_worked_example": false, "text": "The difficulty comes when there's a context switch, which changes the effective contents of virtual memory."}, {"start": "00:03:54", "is_lecture": true, "end": "00:04:00", "is_worked_example": false, "text": "After all that was the point of the context switch, since we want to switch execution to another program."}, {"start": "00:04:00", "is_lecture": true, "end": "00:04:13", "is_worked_example": false, "text": "But that means the OS would have to invalidate all the entries in the cache when performing a context switch, which makes the cache miss ratio quite large until the cache is refilled."}, {"start": "00:04:13", "is_lecture": true, "end": "00:04:18", "is_worked_example": false, "text": "So once again the performance impact of a context switch would be quite high."}, {"start": "00:04:18", "is_lecture": true, "end": "00:04:27", "is_worked_example": false, "text": "We can solve this problem by caching physical addresses, i.e., placing the cache between the MMU and main memory."}, {"start": "00:04:27", "is_lecture": true, "end": "00:04:31", "is_worked_example": false, "text": "Thus the contents of the cache are unaffected by context switches --"}, {"start": "00:04:31", "is_lecture": true, "end": "00:04:36", "is_worked_example": false, "text": "the requested physical addresses will be different, but the cache handles that in due course."}, {"start": "00:04:36", "is_lecture": true, "end": "00:04:48", "is_worked_example": false, "text": "The downside of this approach is that we have to incur the cost of the MMU translation before we can start the cache access, slightly increasing the average memory access time."}, {"start": "00:04:48", "is_lecture": true, "end": "00:04:55", "is_worked_example": false, "text": "But if we're clever we don't have to wait for the MMU to finish before starting the access to the cache."}, {"start": "00:04:55", "is_lecture": true, "end": "00:05:02", "is_worked_example": false, "text": "To get started, the cache needs the line number from the virtual address in order to fetch the appropriate cache line."}, {"start": "00:05:02", "is_lecture": true, "end": "00:05:13", "is_worked_example": false, "text": "If the address bits used for the line number are completely contained in the page offset of the virtual address, these bits are unaffected by the MMU translation,"}, {"start": "00:05:13", "is_lecture": true, "end": "00:05:19", "is_worked_example": false, "text": "and so the cache lookup can happen in parallel with the MMU operation."}, {"start": "00:05:19", "is_lecture": true, "end": "00:05:29", "is_worked_example": false, "text": "Once the cache lookup is complete, the tag field of the cache line can be compared with the appropriate bits of the physical address produced by the MMU."}, {"start": "00:05:29", "is_lecture": true, "end": "00:05:38", "is_worked_example": false, "text": "If there was a TLB hit in the MMU, the physical address should be available at about the same time as the tag field produced by the cache lookup."}, {"start": "00:05:38", "is_lecture": true, "end": "00:05:46", "is_worked_example": false, "text": "By performing the MMU translation and cache lookup in parallel, there's usually no impact on the average memory access time!"}, {"start": "00:05:46", "is_lecture": true, "end": "00:05:54", "is_worked_example": false, "text": "Voila, the best of both worlds: a physically addressed cache that incurs no time penalty for MMU translation."}, {"start": "00:05:54", "is_lecture": true, "end": "00:06:06", "is_worked_example": false, "text": "One final detail: one way to increase the capacity of the cache is to increase the number of cache lines and hence the number of bits of address used as the line number."}, {"start": "00:06:06", "is_lecture": true, "end": "00:06:14", "is_worked_example": false, "text": "Since we want the line number to fit into the page offset field of the virtual address, we're limited in how many cache lines we can have."}, {"start": "00:06:14", "is_lecture": true, "end": "00:06:19", "is_worked_example": false, "text": "The same argument applies to increasing the block size."}, {"start": "00:06:19", "is_lecture": true, "end": "00:06:31", "is_worked_example": false, "text": "So to increase the capacity of the cache our only option is to increase the cache associativity, which adds capacity without affecting the address bits used for the line number."}, {"start": "00:06:31", "is_lecture": true, "end": "00:06:35", "is_worked_example": false, "text": "That's it for our discussion of virtual memory."}, {"start": "00:06:35", "is_lecture": true, "end": "00:06:41", "is_worked_example": false, "text": "We use the MMU to provide the context for mapping virtual addresses to physical addresses."}, {"start": "00:06:41", "is_lecture": true, "end": "00:06:53", "is_worked_example": false, "text": "By switching contexts we can create the illusion of many virtual address spaces, so many programs can share a single CPU and physical memory without interfering with each other."}, {"start": "00:06:53", "is_lecture": true, "end": "00:06:59", "is_worked_example": false, "text": "We discussed using a page map to translate virtual page numbers to physical page numbers."}, {"start": "00:06:59", "is_lecture": true, "end": "00:07:11", "is_worked_example": false, "text": "To save costs, we located the page map in physical memory and used a TLB to eliminate the cost of accessing the page map for most virtual memory accesses."}, {"start": "00:07:11", "is_lecture": true, "end": "00:07:23", "is_worked_example": false, "text": "Access to a non-resident page causes a page fault exception, allowing the OS to manage the complexities of equitably sharing physical memory across many applications."}, {"start": "00:07:23", "is_lecture": true, "end": "00:07:33", "is_worked_example": false, "text": "We saw that providing contexts was the first step towards creating virtual machines, which is the topic of our next lecture."}]}, "C03S01B09-LEC.srt": {"url": "https://courses.edx.org/courses/course-v1:MITx+6.004.3x+2T2016/courseware/c3/c3s1/9?activate_block_id=block-v1%3AMITx%2B6.004.3x%2B2T2016%2Btype%40discussion%2Bblock%40c3s1v9", "items": [{"start": "00:00:00", "is_lecture": true, "end": "00:00:05", "is_worked_example": false, "text": "So here's the final version of our 5-stage pipelined data path."}, {"start": "00:00:05", "is_lecture": true, "end": "00:00:11", "is_worked_example": false, "text": "To deal with data hazards we've added stall logic to the IF and RF input registers."}, {"start": "00:00:11", "is_lecture": true, "end": "00:00:24", "is_worked_example": false, "text": "We've also added bypass muxes on the output of the register file read ports so we can route values from later in the data path if we need to access a register value that's been computed but not yet written to the register file."}, {"start": "00:00:24", "is_lecture": true, "end": "00:00:32", "is_worked_example": false, "text": "We also made a provision to insert NOPs into the pipeline after the RF stage if the IF and RF stages are stalled."}, {"start": "00:00:32", "is_lecture": true, "end": "00:00:39", "is_worked_example": false, "text": "To deal with control hazards, we speculate that the next instruction is at PC+4."}, {"start": "00:00:39", "is_lecture": true, "end": "00:00:47", "is_worked_example": false, "text": "But for JMPs and taken branches, that guess is wrong so we added a provision for annulling the instruction in the IF stage."}, {"start": "00:00:47", "is_lecture": true, "end": "00:00:52", "is_worked_example": false, "text": "To deal with exceptions and interrupts we added instruction muxes in all but the final pipeline stage."}, {"start": "00:00:52", "is_lecture": true, "end": "00:01:02", "is_worked_example": false, "text": "An instruction that causes an exception is replaced by our magic BNE instruction to capture its PC+4 value."}, {"start": "00:01:02", "is_lecture": true, "end": "00:01:05", "is_worked_example": false, "text": "And instructions in earlier stages are annulled."}, {"start": "00:01:05", "is_lecture": true, "end": "00:01:14", "is_worked_example": false, "text": "All this extra circuitry has been added to ensure that pipelined execution gives the same result as unpipelined execution."}, {"start": "00:01:14", "is_lecture": true, "end": "00:01:23", "is_worked_example": false, "text": "The use of bypassing and branch prediction ensures that data and control hazards have only a small negative impact on the effective CPI."}, {"start": "00:01:23", "is_lecture": true, "end": "00:01:29", "is_worked_example": false, "text": "This means that the much shorter clock period translates to a large increase in instruction throughput."}, {"start": "00:01:29", "is_lecture": true, "end": "00:01:35", "is_worked_example": false, "text": "It's worth remembering the strategies we used to deal with hazards: stalling, bypassing and speculation."}, {"start": "00:01:35", "is_lecture": true, "end": "00:01:45", "is_worked_example": false, "text": "Most execution issues can be dealt with using one of these strategies, so keep these in mind if you ever need to design a high-performance pipelined system."}, {"start": "00:01:45", "is_lecture": true, "end": "00:01:48", "is_worked_example": false, "text": "This completes our discussion of pipelining."}, {"start": "00:01:48", "is_lecture": true, "end": "00:01:55", "is_worked_example": false, "text": "We'll explore other avenues to higher processor performance in the last lecture, which discusses parallel processing."}]}, "C03S02B01-WE.srt": {"url": "https://courses.edx.org/courses/course-v1:MITx+6.004.3x+2T2016/courseware/c3/c3s2/1?activate_block_id=block-v1%3AMITx%2B6.004.3x%2B2T2016%2Btype%40discussion%2Bblock%40c3s2v1", "items": [{"start": "00:00:00", "is_lecture": false, "end": "00:00:13", "is_worked_example": true, "text": "For this problem, assume that you have a fully functioning 5-stage pipelined beta with full bypassing and annulment of branch delay slots as presented in lecture."}, {"start": "00:00:13", "is_lecture": false, "end": "00:00:17", "is_worked_example": true, "text": "This beta has been running the program shown here for a while."}, {"start": "00:00:17", "is_lecture": false, "end": "00:00:24", "is_worked_example": true, "text": "The actual functionality of this program is not so important for this problem, but lets just review it quickly."}, {"start": "00:00:24", "is_lecture": false, "end": "00:00:30", "is_worked_example": true, "text": "This program begins by initializing R1 to 0 before entering the loop."}, {"start": "00:00:30", "is_lecture": false, "end": "00:00:35", "is_worked_example": true, "text": "R1 represents the index of the array element currently being accessed."}, {"start": "00:00:35", "is_lecture": false, "end": "00:00:40", "is_worked_example": true, "text": "Within the loop, the value of that array element is loaded into R0."}, {"start": "00:00:40", "is_lecture": false, "end": "00:00:47", "is_worked_example": true, "text": "R1 is then incremented by 4 in order to point to the next element in the array."}, {"start": "00:00:47", "is_lecture": false, "end": "00:00:57", "is_worked_example": true, "text": "We then compare the array element that was just loaded into R0 with the updated index in R1 and if they are not equal, then we repeat the loop."}, {"start": "00:00:57", "is_lecture": false, "end": "00:01:08", "is_worked_example": true, "text": "If they are equal, then we store the current value of R1 into a memory location called index to remember which index value satisfied the compare instruction."}, {"start": "00:01:08", "is_lecture": false, "end": "00:01:13", "is_worked_example": true, "text": "We want to understand how this program would run on our beta."}, {"start": "00:01:13", "is_lecture": false, "end": "00:01:19", "is_worked_example": true, "text": "In order to do this, we will create a pipeline diagram showing the execution of this program."}, {"start": "00:01:19", "is_lecture": false, "end": "00:01:28", "is_worked_example": true, "text": "A pipeline diagram demonstrates which instruction is currently being executed in each of the 5 pipeline stages."}, {"start": "00:01:28", "is_lecture": false, "end": "00:01:33", "is_worked_example": true, "text": "Our rows indicate the pipeline stage that the instruction is in."}, {"start": "00:01:33", "is_lecture": false, "end": "00:01:36", "is_worked_example": true, "text": "There are five pipeline stages."}, {"start": "00:01:36", "is_lecture": false, "end": "00:01:42", "is_worked_example": true, "text": "The first is IF, or instruction fetch, which fetches the next instruction from memory."}, {"start": "00:01:42", "is_lecture": false, "end": "00:01:50", "is_worked_example": true, "text": "The second is RF, or register file stage which reads the source operands of the instruction."}, {"start": "00:01:50", "is_lecture": false, "end": "00:01:58", "is_worked_example": true, "text": "Next comes the ALU stage where all required arithmetic and logic unit operations are executed."}, {"start": "00:01:58", "is_lecture": false, "end": "00:02:10", "is_worked_example": true, "text": "The fourth stage is the MEM stage where we can begin accessing memory for a load or store operation because the address of the memory location was computed in the ALU stage."}, {"start": "00:02:10", "is_lecture": false, "end": "00:02:19", "is_worked_example": true, "text": "Finally, the last stage is WB, or the write back stage where the results are written back into the register file."}, {"start": "00:02:19", "is_lecture": false, "end": "00:02:25", "is_worked_example": true, "text": "The columns in a pipeline diagram represent the execution cycles."}, {"start": "00:02:25", "is_lecture": false, "end": "00:02:35", "is_worked_example": true, "text": "Our loop begins with a LD operation, so we see our LD instruction in the IF stage in cycle 1001."}, {"start": "00:02:35", "is_lecture": false, "end": "00:02:40", "is_worked_example": true, "text": "The LD operation then proceeds down the 5 stages of the pipelined beta."}, {"start": "00:02:40", "is_lecture": false, "end": "00:02:45", "is_worked_example": true, "text": "Next comes the ADDC instruction."}, {"start": "00:02:45", "is_lecture": false, "end": "00:02:58", "is_worked_example": true, "text": "Since there is no dependency between the LD and the ADDC instruction, the ADDC instruction begins in cycle 1002 and proceeds through all the 5 stages of the beta pipeline as well."}, {"start": "00:02:58", "is_lecture": false, "end": "00:03:03", "is_worked_example": true, "text": "Next comes the CMPEQ instruction."}, {"start": "00:03:03", "is_lecture": false, "end": "00:03:15", "is_worked_example": true, "text": "When we reach the CMPEQ instruction, we are met with our first data hazard caused by the fact that the LD is updating R0, and the CMPEQ wants to read this new value of R0."}, {"start": "00:03:15", "is_lecture": false, "end": "00:03:22", "is_worked_example": true, "text": "Recall, that a LD does not produce its value until the WB stage of the pipeline."}, {"start": "00:03:22", "is_lecture": false, "end": "00:03:32", "is_worked_example": true, "text": "This means that even with full bypassing logic, the CMPEQ instruction cannot read register R0 until the LD is in the WB stage."}, {"start": "00:03:32", "is_lecture": false, "end": "00:03:38", "is_worked_example": true, "text": "So we must initiate a stall of the pipeline in cycle 1004."}, {"start": "00:03:38", "is_lecture": false, "end": "00:03:55", "is_worked_example": true, "text": "The stall can be seen in our pipeline diagram in cycle 1005 where the CMPEQ has remained in the RF stage and we have inserted a NOP in place of the CMPEQ that was coming down the pipe one cycle earlier."}, {"start": "00:03:55", "is_lecture": false, "end": "00:03:59", "is_worked_example": true, "text": "The instruction that follows the CMPEQ is the BNE."}, {"start": "00:03:59", "is_lecture": false, "end": "00:04:13", "is_worked_example": true, "text": "Notice that it entered the IF stage in cycle 1004, but it too was stalled by the CMPEQ, so the BNE remains in the IF stage while the CMPEQ is stuck in the RF stage."}, {"start": "00:04:13", "is_lecture": false, "end": "00:04:35", "is_worked_example": true, "text": "In cycle 1005, the CMPEQ is able to complete the read of its operands by using the bypass path from the WB stage to read the updated value of R0, and by using the bypass path from the MEM stage to read the updated value of R1 produced by the ADDC instruction."}, {"start": "00:04:35", "is_lecture": false, "end": "00:04:47", "is_worked_example": true, "text": "In cycle 1006, the CMPEQ instruction moves on to the ALU stage and the BNE can move on to the RF stage."}, {"start": "00:04:47", "is_lecture": false, "end": "00:05:08", "is_worked_example": true, "text": "Since the CMPEQ is going to update the value of R2 which is the register that the BNE is trying to read, we need to make use of the bypass path from the ALU stage to the RF stage in order to provide the BNE with the result of the CMPEQ instruction in cycle 1006."}, {"start": "00:05:08", "is_lecture": false, "end": "00:05:12", "is_worked_example": true, "text": "The RF stage is also the stage when Z is generated."}, {"start": "00:05:12", "is_lecture": false, "end": "00:05:18", "is_worked_example": true, "text": "The Z signal tells the beta whether or not a register is equal to zero."}, {"start": "00:05:18", "is_lecture": false, "end": "00:05:27", "is_worked_example": true, "text": "This means that by the end of the RF stage in cycle 1006, the BNE will know whether it is repeating the loop or not."}, {"start": "00:05:27", "is_lecture": false, "end": "00:05:32", "is_worked_example": true, "text": "We now illustrate what happens to the pipeline diagram if the loop is repeated."}, {"start": "00:05:32", "is_lecture": false, "end": "00:05:46", "is_worked_example": true, "text": "In cycle 1006, the ST instruction enters the IF stage of the pipeline because until we resolve whether a branch is taken or not, we assume that we should continue fetching the next instruction."}, {"start": "00:05:46", "is_lecture": false, "end": "00:05:56", "is_worked_example": true, "text": "If the BNE determines that it should branch back to LOOP, then this ST instruction which was just fetched must be annulled by inserting a NOP in its place."}, {"start": "00:05:56", "is_lecture": false, "end": "00:06:07", "is_worked_example": true, "text": "The annulment is initiated in cycle 1006 and shows up as a NOP in the RF stage in cycle 1007."}, {"start": "00:06:07", "is_lecture": false, "end": "00:06:18", "is_worked_example": true, "text": "In cycle 1007, we also see that we now fetch the first instruction of the loop which is the LD instruction so that we can repeat the loop."}, {"start": "00:06:18", "is_lecture": false, "end": "00:06:34", "is_worked_example": true, "text": "Here is a complete pipeline diagram showing repeated execution of the loop in our sample code together with the bypass paths being used as well as the initiation of stalls and annulment of branch delay slots."}, {"start": "00:06:34", "is_lecture": false, "end": "00:06:40", "is_worked_example": true, "text": "We are now ready to answer a few questions about the execution of this loop on our beta."}, {"start": "00:06:40", "is_lecture": false, "end": "00:06:55", "is_worked_example": true, "text": "The first question we want to consider is which of the registers R0, R1, and/or R2 were read at least once directly from the register file rather than through a bypass path?"}, {"start": "00:06:55", "is_lecture": false, "end": "00:07:04", "is_worked_example": true, "text": "Looking back at our completed pipeline diagram, we see that the LD and ADDC instructions did not get their operands through bypass paths."}, {"start": "00:07:04", "is_lecture": false, "end": "00:07:13", "is_worked_example": true, "text": "Since both of those instructions read R1, that means that register R1 was read at least once directly from the register file."}, {"start": "00:07:13", "is_lecture": false, "end": "00:07:19", "is_worked_example": true, "text": "R0 which is only read by the CMPEQ always comes from a bypass path."}, {"start": "00:07:19", "is_lecture": false, "end": "00:07:26", "is_worked_example": true, "text": "Similarly, R2, which is only read by the BNE, always comes from a bypass path as well."}, {"start": "00:07:26", "is_lecture": false, "end": "00:07:33", "is_worked_example": true, "text": "Next, we want to identify the cycle in which stall was set to 1 in the pipelined beta hardware."}, {"start": "00:07:33", "is_lecture": false, "end": "00:07:38", "is_worked_example": true, "text": "This occurs in the cycle where the stall is initiated which was in cycle 1004."}, {"start": "00:07:38", "is_lecture": false, "end": "00:07:51", "is_worked_example": true, "text": "At the end of that cycle the instructions that are currently in the IF and RF stage are stalled by not allowing a load of a new value into the instruction registers of that pipeline stage."}, {"start": "00:07:51", "is_lecture": false, "end": "00:07:58", "is_worked_example": true, "text": "Next, we want to determine in which cycle was ANNUL_IF != 0?"}, {"start": "00:07:58", "is_lecture": false, "end": "00:08:07", "is_worked_example": true, "text": "Recall that the ANNUL_STAGE control signals specify when an annulment is initiated in that particular stage."}, {"start": "00:08:07", "is_lecture": false, "end": "00:08:15", "is_worked_example": true, "text": "In order to initiate an annulment, then the instruction that is currently in the IF stage is replaced with a NOP."}, {"start": "00:08:15", "is_lecture": false, "end": "00:08:21", "is_worked_example": true, "text": "This occurs in the IF stage when we need to annul a branch delay slot."}, {"start": "00:08:21", "is_lecture": false, "end": "00:08:25", "is_worked_example": true, "text": "In our example this occurs in cycle 1006."}, {"start": "00:08:25", "is_lecture": false, "end": "00:08:30", "is_worked_example": true, "text": "In which cycle was ANNUL_RF != 0?"}, {"start": "00:08:30", "is_lecture": false, "end": "00:08:36", "is_worked_example": true, "text": "This question is asking when an annulment was initiated in the RF stage."}, {"start": "00:08:36", "is_lecture": false, "end": "00:08:42", "is_worked_example": true, "text": "This occurred when the CMPEQ instruction needed to be stalled in the RF stage."}, {"start": "00:08:42", "is_lecture": false, "end": "00:08:54", "is_worked_example": true, "text": "In order to fill the pipeline bubbles, a NOP is inserted into the pipeline in place of the CMPEQ instruction that was in the RF stage in cycle 1004."}, {"start": "00:08:54", "is_lecture": false, "end": "00:09:01", "is_worked_example": true, "text": "The stall and thus the setting of ANNUL_RF != 0 occurs in cycle 1004."}, {"start": "00:09:01", "is_lecture": false, "end": "00:09:07", "is_worked_example": true, "text": "In which cycle was ANNUL_ALU != 0?"}, {"start": "00:09:07", "is_lecture": false, "end": "00:09:14", "is_worked_example": true, "text": "In other words, in which cycle did we initiate the replacement of an instruction in the ALU stage with a NOP?"}, {"start": "00:09:14", "is_lecture": false, "end": "00:09:18", "is_worked_example": true, "text": "This does not occur in our example."}, {"start": "00:09:18", "is_lecture": false, "end": "00:09:23", "is_worked_example": true, "text": "Next, we want to consider our bypass paths."}, {"start": "00:09:23", "is_lecture": false, "end": "00:09:29", "is_worked_example": true, "text": "In which cycle was either bypass coming from the ALU stage?"}, {"start": "00:09:29", "is_lecture": false, "end": "00:09:39", "is_worked_example": true, "text": "In cycle 1006, the BNE reads the result of the CMPEQ instruction from the ALU stage."}, {"start": "00:09:39", "is_lecture": false, "end": "00:09:44", "is_worked_example": true, "text": "In which cycle was either bypass coming from the MEM stage?"}, {"start": "00:09:44", "is_lecture": false, "end": "00:09:53", "is_worked_example": true, "text": "In cycle 1005, the CMPEQ reads the result of the ADDC instruction from the MEM stage."}, {"start": "00:09:53", "is_lecture": false, "end": "00:10:00", "is_worked_example": true, "text": "Finally, in which cycle was either bypass coming from the WB stage?"}, {"start": "00:10:00", "is_lecture": false, "end": "00:10:09", "is_worked_example": true, "text": "In cycle 1005, the CMPEQ reads the result of the LD instruction from the WB stage."}]}, "C03S02B02-WE.srt": {"url": "https://courses.edx.org/courses/course-v1:MITx+6.004.3x+2T2016/courseware/c3/c3s2/2?activate_block_id=block-v1%3AMITx%2B6.004.3x%2B2T2016%2Btype%40discussion%2Bblock%40c3s2v2", "items": [{"start": "00:00:00", "is_lecture": false, "end": "00:00:07", "is_worked_example": true, "text": "For this problem, assume that you have discovered a room full of discarded 5-stage pipelined betas."}, {"start": "00:00:07", "is_lecture": false, "end": "00:00:10", "is_worked_example": true, "text": "These betas fall into four categories."}, {"start": "00:00:10", "is_lecture": false, "end": "00:00:16", "is_worked_example": true, "text": "The first is completely functional 5-stage Betas with full bypass and annulment logic."}, {"start": "00:00:16", "is_lecture": false, "end": "00:00:20", "is_worked_example": true, "text": "The second are betas with a bad register file."}, {"start": "00:00:20", "is_lecture": false, "end": "00:00:24", "is_worked_example": true, "text": "In these betas, all data read directly from the register file is zero."}, {"start": "00:00:24", "is_lecture": false, "end": "00:00:30", "is_worked_example": true, "text": "Note that if the data is read from a bypass path, then the correct value will be read."}, {"start": "00:00:30", "is_lecture": false, "end": "00:00:34", "is_worked_example": true, "text": "The third set are betas without bypass paths."}, {"start": "00:00:34", "is_lecture": false, "end": "00:00:39", "is_worked_example": true, "text": "And finally, the fourth are betas without annulment of branch delay slots."}, {"start": "00:00:39", "is_lecture": false, "end": "00:00:44", "is_worked_example": true, "text": "The problem is that the betas are not labeled, so we do not know which falls into which category."}, {"start": "00:00:44", "is_lecture": false, "end": "00:00:49", "is_worked_example": true, "text": "You come up with the test program shown here."}, {"start": "00:00:49", "is_lecture": false, "end": "00:00:58", "is_worked_example": true, "text": "Your plan is to single step through the program using each Beta chip, carefully noting the address that the final JMP loads into the PC."}, {"start": "00:00:58", "is_lecture": false, "end": "00:01:04", "is_worked_example": true, "text": "Your goal is to determine which of the four classes each chip falls into via this JMP address."}, {"start": "00:01:04", "is_lecture": false, "end": "00:01:13", "is_worked_example": true, "text": "Notice that on a fully functional beta, this code would execute the instructions sequentially skipping the MULC instruction."}, {"start": "00:01:13", "is_lecture": false, "end": "00:01:23", "is_worked_example": true, "text": "Here we see a pipeline diagram showing execution of this program on a fully functional beta from category C1."}, {"start": "00:01:23", "is_lecture": false, "end": "00:01:37", "is_worked_example": true, "text": "It shows that the although the MULC instruction is fetched in cycle 2, it gets annulled when the BEQ is in the RF stage and it determines that the branch to label X, or the SUBC instruction, will be taken."}, {"start": "00:01:37", "is_lecture": false, "end": "00:01:42", "is_worked_example": true, "text": "The MULC is annulled by inserting a NOP in its place."}, {"start": "00:01:42", "is_lecture": false, "end": "00:01:48", "is_worked_example": true, "text": "The ADDC and BEQ instructions read R31 from the register file."}, {"start": "00:01:48", "is_lecture": false, "end": "00:01:56", "is_worked_example": true, "text": "The SUBC, however, gets the value of R2 via the bypass path from the  BEQ instruction which is in the MEM stage."}, {"start": "00:01:56", "is_lecture": false, "end": "00:02:00", "is_worked_example": true, "text": "The ADD then reads R0 and R2."}, {"start": "00:02:00", "is_lecture": false, "end": "00:02:07", "is_worked_example": true, "text": "R0 has already made it back to the register file because the ADDC instruction completed by the end of cycle 4."}, {"start": "00:02:07", "is_lecture": false, "end": "00:02:15", "is_worked_example": true, "text": "R2, however, is read via the bypass path from the SUBC instruction which is in the ALU stage."}, {"start": "00:02:15", "is_lecture": false, "end": "00:02:25", "is_worked_example": true, "text": "Finally, the JMP, reads the value of R3 via the bypass path from the ADD instruction which is in the ALU stage in cycle 6."}, {"start": "00:02:25", "is_lecture": false, "end": "00:02:33", "is_worked_example": true, "text": "When run on a fully functional beta with bypass paths and annulment of branch delay slots, the code behaves as follows:"}, {"start": "00:02:33", "is_lecture": false, "end": "00:02:37", "is_worked_example": true, "text": "The ADDC sets R0 = 4."}, {"start": "00:02:37", "is_lecture": false, "end": "00:02:41", "is_worked_example": true, "text": "The BEQ stores PC + 4 into R2."}, {"start": "00:02:41", "is_lecture": false, "end": "00:02:53", "is_worked_example": true, "text": "Since the ADDC is at address 0, the BEQ is at address 4, so PC + 4 = 8 is stored into R2, and the program branches to label X."}, {"start": "00:02:53", "is_lecture": false, "end": "00:03:02", "is_worked_example": true, "text": "Next, the SUBC subtracts 4 from the latest value of R2 and stores the result which is 4 back into R2."}, {"start": "00:03:02", "is_lecture": false, "end": "00:03:10", "is_worked_example": true, "text": "The ADD adds R0 and R2, or 4 and 4, and stores the result which is 8 into R3."}, {"start": "00:03:10", "is_lecture": false, "end": "00:03:15", "is_worked_example": true, "text": "The JMP jumps to the address in R3 which is 8."}, {"start": "00:03:15", "is_lecture": false, "end": "00:03:25", "is_worked_example": true, "text": "When run on C2 which has a bad register file that always outputs a zero, the behavior of the program changes a bit."}, {"start": "00:03:25", "is_lecture": false, "end": "00:03:33", "is_worked_example": true, "text": "The ADDC and BEQ instructions which use R31 which is 0 anyways behave in the same way as before."}, {"start": "00:03:33", "is_lecture": false, "end": "00:03:41", "is_worked_example": true, "text": "The SUBC, which gets the value of R2 from the bypass path, reads the correct value for R2 which is 8."}, {"start": "00:03:41", "is_lecture": false, "end": "00:03:51", "is_worked_example": true, "text": "Recall that only reads directly from the register file return a zero, whereas if the data is coming from a bypass path, then you get the correct value."}, {"start": "00:03:51", "is_lecture": false, "end": "00:03:53", "is_worked_example": true, "text": "So the SUBC produces a 4."}, {"start": "00:03:53", "is_lecture": false, "end": "00:03:59", "is_worked_example": true, "text": "The ADD reads R0 from the register file and R2 from the bypass path."}, {"start": "00:03:59", "is_lecture": false, "end": "00:04:07", "is_worked_example": true, "text": "The result is that the value of R0 is read as if it was 0 while that of R2 is correct and is 4."}, {"start": "00:04:07", "is_lecture": false, "end": "00:04:18", "is_worked_example": true, "text": "So R3 gets the value 4 assigned to it, and that is the address that the JMP instruction jumps to because it too reads its register from a bypass path."}, {"start": "00:04:18", "is_lecture": false, "end": "00:04:28", "is_worked_example": true, "text": "When run on C3 which does not have any bypass paths, some of the instructions will read stale values of their source operands."}, {"start": "00:04:28", "is_lecture": false, "end": "00:04:31", "is_worked_example": true, "text": "Let's go through the example in detail."}, {"start": "00:04:31", "is_lecture": false, "end": "00:04:41", "is_worked_example": true, "text": "The ADDC and BEQ instructions read R31 which is 0 from the register file so what they ultimately produce does not change."}, {"start": "00:04:41", "is_lecture": false, "end": "00:04:53", "is_worked_example": true, "text": "However, you must keep in mind that the updated value of the destination register will not get updated until after that instruction completes the WB stage of the pipeline."}, {"start": "00:04:53", "is_lecture": false, "end": "00:05:05", "is_worked_example": true, "text": "When the SUBC reads R2, it gets a stale value of R2 because the BEQ instruction has not yet completed, so it assumes that R2 = 0."}, {"start": "00:05:05", "is_lecture": false, "end": "00:05:09", "is_worked_example": true, "text": "It then subtracts 4 from that and tries to write -4 into R2."}, {"start": "00:05:09", "is_lecture": false, "end": "00:05:12", "is_worked_example": true, "text": "Next the ADD runs."}, {"start": "00:05:12", "is_lecture": false, "end": "00:05:25", "is_worked_example": true, "text": "Recall that the ADD would normally read R0 from the register file because by the time the ADD is in the RF stage, the ADDC which writes to R0 has completed all the pipeline stages."}, {"start": "00:05:25", "is_lecture": false, "end": "00:05:29", "is_worked_example": true, "text": "The ADD also normally read R2 from the bypass path."}, {"start": "00:05:29", "is_lecture": false, "end": "00:05:36", "is_worked_example": true, "text": "However, since C3 does not have bypass paths, it reads a stale value of R2 from the register file."}, {"start": "00:05:36", "is_lecture": false, "end": "00:05:53", "is_worked_example": true, "text": "To determine which stale value it reads, we need to examine the pipeline diagram to see if either the BEQ or the SUBC operations, both of which eventually update R2, have completed by the time the ADD reads its source operands."}, {"start": "00:05:53", "is_lecture": false, "end": "00:06:09", "is_worked_example": true, "text": "Looking at our pipeline diagram, we see that when the ADD is in the RF stage, neither the BEQ nor the SUBC have completed, thus the value read for R2 is the initial value of R2 which is 0."}, {"start": "00:06:09", "is_lecture": false, "end": "00:06:21", "is_worked_example": true, "text": "We can now determine the behavior of the ADD instruction which is that it assumes R0 = 4 and R2 = 0 and will eventually write a 4 into R3."}, {"start": "00:06:21", "is_lecture": false, "end": "00:06:34", "is_worked_example": true, "text": "Finally, the JMP instruction wants to read the result of the ADD, however, since there are no bypass paths, it reads the original value of R3 which was 0 and jumps to address 0."}, {"start": "00:06:34", "is_lecture": false, "end": "00:06:55", "is_worked_example": true, "text": "Of course, had we looked at our code a little more closely, we could have determined this without all the intermediate steps because the ADD is the only instruction that tries to update R3, and you know that the JMP would normally get R3 from the bypass path which is not available, therefore it must read the original value of R3 which is 0."}, {"start": "00:06:55", "is_lecture": false, "end": "00:07:06", "is_worked_example": true, "text": "In category C4, the betas do not annul instructions that were fetched after a branch instruction but aren't supposed to get executed."}, {"start": "00:07:06", "is_lecture": false, "end": "00:07:14", "is_worked_example": true, "text": "This means that the MULC which is fetched after the BEQ is actually executed in the pipeline and affects the value of R2."}, {"start": "00:07:14", "is_lecture": false, "end": "00:07:18", "is_worked_example": true, "text": "Let's take a close look at what happens in each instruction."}, {"start": "00:07:18", "is_lecture": false, "end": "00:07:25", "is_worked_example": true, "text": "Once again we begin with the ADDC setting R0 to 4 and the BEQ setting R2 to 8."}, {"start": "00:07:25", "is_lecture": false, "end": "00:07:32", "is_worked_example": true, "text": "Since our bypass paths are now working, we can assume that we can immediately get the updated value."}, {"start": "00:07:32", "is_lecture": false, "end": "00:07:40", "is_worked_example": true, "text": "Next, we execute the MULC which takes the latest value of R2 from the bypass path and multiplies it by 2."}, {"start": "00:07:40", "is_lecture": false, "end": "00:07:43", "is_worked_example": true, "text": "So it sets R2 = 16."}, {"start": "00:07:43", "is_lecture": false, "end": "00:07:51", "is_worked_example": true, "text": "The SUBC now uses this value for R2 from which it subtracts 4 to produce R2 = 12."}, {"start": "00:07:51", "is_lecture": false, "end": "00:08:01", "is_worked_example": true, "text": "The ADD then reads R0 = 4 and adds to it R2 = 12 to produce R3 = 16."}, {"start": "00:08:01", "is_lecture": false, "end": "00:08:05", "is_worked_example": true, "text": "Finally, the JMP jumps to address 16."}, {"start": "00:08:05", "is_lecture": false, "end": "00:08:16", "is_worked_example": true, "text": "Since each of the four categories produces a unique jump address, this program can be used to sort out all the betas into the four categories."}]}, "C03S01B01-LEC.srt": {"url": "https://courses.edx.org/courses/course-v1:MITx+6.004.3x+2T2016/courseware/c3/c3s1/1?activate_block_id=block-v1%3AMITx%2B6.004.3x%2B2T2016%2Btype%40discussion%2Bblock%40c3s1v1", "items": [{"start": "00:00:00", "is_lecture": true, "end": "00:00:12", "is_worked_example": false, "text": "In this lecture, we're going to use the circuit pipelining techniques we learned in Part 1 of the course to improve the performance of the 32-bit Beta CPU design we developed in Part 2 of the course."}, {"start": "00:00:12", "is_lecture": true, "end": "00:00:16", "is_worked_example": false, "text": "This CPU design executes one Beta instruction per clock cycle."}, {"start": "00:00:16", "is_lecture": true, "end": "00:00:18", "is_worked_example": false, "text": "Hopefully you remember the design!"}, {"start": "00:00:18", "is_lecture": true, "end": "00:00:24", "is_worked_example": false, "text": "If not, you might find it worthwhile to review Lecture 13, Building the Beta, from Part 2."}, {"start": "00:00:24", "is_lecture": true, "end": "00:00:34", "is_worked_example": false, "text": "At the beginning of the clock cycle, this circuit loads a new value into the program counter, which is then sent to main memory as the address of the instruction to be executed this cycle."}, {"start": "00:00:34", "is_lecture": true, "end": "00:00:46", "is_worked_example": false, "text": "When the 32-bit word containing the binary encoding of the instruction is returned by the memory, the opcode field is decoded by the control logic to determine the control signals for the rest of the data path."}, {"start": "00:00:46", "is_lecture": true, "end": "00:00:53", "is_worked_example": false, "text": "The operands are read from the register file and routed to the ALU to perform the desired operation."}, {"start": "00:00:53", "is_lecture": true, "end": "00:01:04", "is_worked_example": false, "text": "For memory operations, the output of the ALU serves as the memory address and, in the case of load instructions, the main memory supplies the data to be written into the register file at the end of the cycle."}, {"start": "00:01:04", "is_lecture": true, "end": "00:01:08", "is_worked_example": false, "text": "PC+4 and ALU values can also be written to the register file."}, {"start": "00:01:08", "is_lecture": true, "end": "00:01:16", "is_worked_example": false, "text": "The clock period of the Beta is determined by the cumulative delay through all the components involved in instruction execution."}, {"start": "00:01:16", "is_lecture": true, "end": "00:01:19", "is_worked_example": false, "text": "Today's question is: how can we make this faster?"}, {"start": "00:01:19", "is_lecture": true, "end": "00:01:24", "is_worked_example": false, "text": "We can characterize the time spent executing a program as the product of three terms."}, {"start": "00:01:24", "is_lecture": true, "end": "00:01:28", "is_worked_example": false, "text": "The first term is the total number of instructions executed."}, {"start": "00:01:28", "is_lecture": true, "end": "00:01:35", "is_worked_example": false, "text": "Since the program usually contains loops and procedure calls, many of the encoded instructions will be executed many times."}, {"start": "00:01:35", "is_lecture": true, "end": "00:01:43", "is_worked_example": false, "text": "We want the total count of instructions executed, not the static size of the program as measured by the number of encoded instructions in memory."}, {"start": "00:01:43", "is_lecture": true, "end": "00:01:49", "is_worked_example": false, "text": "The second term is the average number of clock cycles it takes to execute a single instruction."}, {"start": "00:01:49", "is_lecture": true, "end": "00:01:53", "is_worked_example": false, "text": "And the third term is the duration of a single clock cycle."}, {"start": "00:01:53", "is_lecture": true, "end": "00:02:04", "is_worked_example": false, "text": "As CPU designers it's the last two terms which are under our control: the cycles per instruction (CPI) and the clock period (t_CLK)."}, {"start": "00:02:04", "is_lecture": true, "end": "00:02:09", "is_worked_example": false, "text": "To affect the first term, we would need to change the ISA or write a better compiler!"}, {"start": "00:02:09", "is_lecture": true, "end": "00:02:17", "is_worked_example": false, "text": "Our design for the Beta was able to execute every instruction in a single clock cycle, so our CPI is 1."}, {"start": "00:02:17", "is_lecture": true, "end": "00:02:23", "is_worked_example": false, "text": "As we discussed in the previous slide, t_CLK is determined by the longest path through the Beta circuitry."}, {"start": "00:02:23", "is_lecture": true, "end": "00:02:31", "is_worked_example": false, "text": "For example, consider the execution of an OP-class instruction, which involves two register operands and an ALU operation."}, {"start": "00:02:31", "is_lecture": true, "end": "00:02:36", "is_worked_example": false, "text": "The arrow shows all the components that are involved in the execution of the instruction."}, {"start": "00:02:36", "is_lecture": true, "end": "00:02:43", "is_worked_example": false, "text": "Aside from a few muxes, the main memory, register file, and ALU must all have time to do their thing."}, {"start": "00:02:43", "is_lecture": true, "end": "00:02:49", "is_worked_example": false, "text": "The worst-case execution time is for the LD instruction."}, {"start": "00:02:49", "is_lecture": true, "end": "00:02:53", "is_worked_example": false, "text": "In one clock cycle we need to fetch the instruction from main memory (t_IFETCH),"}, {"start": "00:02:53", "is_lecture": true, "end": "00:02:56", "is_worked_example": false, "text": "read the operands from the register file (t_RF),"}, {"start": "00:02:56", "is_lecture": true, "end": "00:02:59", "is_worked_example": false, "text": "perform the address addition in the ALU (t_ALU),"}, {"start": "00:02:59", "is_lecture": true, "end": "00:03:01", "is_worked_example": false, "text": "read the requested location from main memory (t_MEM),"}, {"start": "00:03:01", "is_lecture": true, "end": "00:03:06", "is_worked_example": false, "text": "and finally write the memory data to the destination register (t_WB)."}, {"start": "00:03:06", "is_lecture": true, "end": "00:03:15", "is_worked_example": false, "text": "The component delays add up and the result is a fairly long clock period and hence it will take a long time to run the program."}, {"start": "00:03:15", "is_lecture": true, "end": "00:03:19", "is_worked_example": false, "text": "And our two example execution paths illustrate another issue:"}, {"start": "00:03:19", "is_lecture": true, "end": "00:03:31", "is_worked_example": false, "text": "we're forced to choose the clock period to accommodate the worst-case execution time, even though we may be able to execute some instructions faster since their execution path through the circuitry is shorter."}, {"start": "00:03:31", "is_lecture": true, "end": "00:03:38", "is_worked_example": false, "text": "We're making all the instructions slower just because there's one instruction that has a long critical path."}, {"start": "00:03:38", "is_lecture": true, "end": "00:03:50", "is_worked_example": false, "text": "So why not have simple instructions execute in one clock cycle and more complex instructions take multiple cycles instead of forcing all instructions to execute in a single, long clock cycle?"}, {"start": "00:03:50", "is_lecture": true, "end": "00:03:59", "is_worked_example": false, "text": "As we'll see in the next few slides, we have a good answer to this question, one that will allow us to execute *all* instructions with a short clock period."}, {"start": "00:03:59", "is_lecture": true, "end": "00:04:02", "is_worked_example": false, "text": "We're going to use pipelining to address these issues."}, {"start": "00:04:02", "is_lecture": true, "end": "00:04:10", "is_worked_example": false, "text": "We're going to divide the execution of an instruction into a sequence of steps, where each step is performed in successive stages of the pipeline."}, {"start": "00:04:10", "is_lecture": true, "end": "00:04:17", "is_worked_example": false, "text": "So it will take multiple clock cycles to execute an instruction as it travels through the stages of the execution pipeline."}, {"start": "00:04:17", "is_lecture": true, "end": "00:04:26", "is_worked_example": false, "text": "But since there are only one or two components in each stage of the pipeline, the clock period can be much shorter and the throughput of the CPU can be much higher."}, {"start": "00:04:26", "is_lecture": true, "end": "00:04:32", "is_worked_example": false, "text": "The increased throughput is the result of overlapping the execution of consecutive instructions."}, {"start": "00:04:32", "is_lecture": true, "end": "00:04:40", "is_worked_example": false, "text": "At any given time, there will be multiple instructions in the CPU, each at a different stage of its execution."}, {"start": "00:04:40", "is_lecture": true, "end": "00:04:50", "is_worked_example": false, "text": "The time to execute all the steps for a particular instruction (i.e., the instruction latency) may be somewhat higher than in our unpipelined implementation."}, {"start": "00:04:50", "is_lecture": true, "end": "00:04:58", "is_worked_example": false, "text": "But we will finish the last step of executing some instruction in each clock cycle, so the instruction throughput is 1 per clock cycle."}, {"start": "00:04:58", "is_lecture": true, "end": "00:05:05", "is_worked_example": false, "text": "And since the clock cycle of our pipelined CPU is quite a bit shorter, the instruction throughput is quite a bit higher."}, {"start": "00:05:05", "is_lecture": true, "end": "00:05:10", "is_worked_example": false, "text": "All this sounds great, but, not surprisingly, there are few issues we'll have to deal with."}, {"start": "00:05:10", "is_lecture": true, "end": "00:05:14", "is_worked_example": false, "text": "There are many ways to pipeline the execution of an instruction."}, {"start": "00:05:14", "is_lecture": true, "end": "00:05:25", "is_worked_example": false, "text": "We're going to look at the design of the classic 5-stage instruction execution pipeline, which was widely used in the integrated circuit CPU designs of the 1980's."}, {"start": "00:05:25", "is_lecture": true, "end": "00:05:33", "is_worked_example": false, "text": "The 5 pipeline stages correspond to the steps of executing an instruction in a von-Neumann stored-program architecture."}, {"start": "00:05:33", "is_lecture": true, "end": "00:05:41", "is_worked_example": false, "text": "The first stage (IF) is responsible for fetching the binary-encoded instruction from the main memory location indicated by the program counter."}, {"start": "00:05:41", "is_lecture": true, "end": "00:05:50", "is_worked_example": false, "text": "The 32-bit instruction is passed to the register file stage (RF) where the required register operands are read from the register file."}, {"start": "00:05:50", "is_lecture": true, "end": "00:05:58", "is_worked_example": false, "text": "The operand values are passed to the ALU stage (ALU), which performs the requested operation."}, {"start": "00:05:58", "is_lecture": true, "end": "00:06:12", "is_worked_example": false, "text": "The memory stage (MEM) performs the second access to main memory to read or write the data for LD, LDR, or ST instructions, using the value from the ALU stage as the memory address."}, {"start": "00:06:12", "is_lecture": true, "end": "00:06:18", "is_worked_example": false, "text": "For load instructions, the output of the MEM stage is the read data from main memory."}, {"start": "00:06:18", "is_lecture": true, "end": "00:06:23", "is_worked_example": false, "text": "For all other instructions, the output of the MEM stage is simply the value from the ALU stage."}, {"start": "00:06:23", "is_lecture": true, "end": "00:06:32", "is_worked_example": false, "text": "In the final write-back stage (WB), the result from the earlier stages is written to the destination register in the register file."}, {"start": "00:06:32", "is_lecture": true, "end": "00:06:41", "is_worked_example": false, "text": "Looking at the execution path from the previous slide, we see that each of the main components of the unpipelined design is now in its own pipeline stage."}, {"start": "00:06:41", "is_lecture": true, "end": "00:06:46", "is_worked_example": false, "text": "So the clock period will now be determined by the slowest of these components."}, {"start": "00:06:46", "is_lecture": true, "end": "00:06:55", "is_worked_example": false, "text": "Having divided instruction execution into five stages, would we expect the clock period to be one fifth of its original value?"}, {"start": "00:06:55", "is_lecture": true, "end": "00:07:03", "is_worked_example": false, "text": "Well, that would only happen if we were able to divide the execution so that each stage performed exactly one fifth of the total work."}, {"start": "00:07:03", "is_lecture": true, "end": "00:07:14", "is_worked_example": false, "text": "In real life, the major components have somewhat different latencies, so the improvement in instruction throughput will be a little less than the factor of 5 a perfect 5-stage pipeline could achieve."}, {"start": "00:07:14", "is_lecture": true, "end": "00:07:26", "is_worked_example": false, "text": "If we have a slow component, e.g., the ALU, we might choose to pipeline that component into further stages, or, interleave multiple ALUs to achieve the same effect."}, {"start": "00:07:26", "is_lecture": true, "end": "00:07:31", "is_worked_example": false, "text": "But for this lecture, we'll go with the 5-stage pipeline described above."}, {"start": "00:07:31", "is_lecture": true, "end": "00:07:34", "is_worked_example": false, "text": "So why isn't this a 20-minute lecture?"}, {"start": "00:07:34", "is_lecture": true, "end": "00:07:37", "is_worked_example": false, "text": "After all we know how pipeline combinational circuits:"}, {"start": "00:07:37", "is_lecture": true, "end": "00:07:47", "is_worked_example": false, "text": "We can build a valid k-stage pipeline by drawing k contours across the circuit diagram and adding a pipeline register wherever a contour crosses a signal."}, {"start": "00:07:47", "is_lecture": true, "end": "00:07:48", "is_worked_example": false, "text": "What's the big deal here?"}, {"start": "00:07:48", "is_lecture": true, "end": "00:07:52", "is_worked_example": false, "text": "Well, is this circuit combinational?  No!"}, {"start": "00:07:52", "is_lecture": true, "end": "00:07:54", "is_worked_example": false, "text": "There's state in the registers and memories."}, {"start": "00:07:54", "is_lecture": true, "end": "00:08:00", "is_worked_example": false, "text": "This means that the result of executing a given instruction may depend on the results from earlier instructions."}, {"start": "00:08:00", "is_lecture": true, "end": "00:08:08", "is_worked_example": false, "text": "There are loops in the circuit where data from later pipeline stages affects the execution of earlier pipeline stages."}, {"start": "00:08:08", "is_lecture": true, "end": "00:08:16", "is_worked_example": false, "text": "For example, the write to the register file at the end of the WB stage will change values read from the register file in the RF stage."}, {"start": "00:08:16", "is_lecture": true, "end": "00:08:27", "is_worked_example": false, "text": "In other words, there are execution dependencies between instructions and these dependencies will need to be taken into account when we're trying to pipeline instruction execution."}, {"start": "00:08:27", "is_lecture": true, "end": "00:08:32", "is_worked_example": false, "text": "We'll be addressing these issues as we examine the operation of our execution pipeline."}, {"start": "00:08:32", "is_lecture": true, "end": "00:08:38", "is_worked_example": false, "text": "Sometimes execution of a given instruction will depend on the results of executing a previous instruction."}, {"start": "00:08:38", "is_lecture": true, "end": "00:08:41", "is_worked_example": false, "text": "Two are two types of problematic dependencies."}, {"start": "00:08:41", "is_lecture": true, "end": "00:08:50", "is_worked_example": false, "text": "The first, termed a data hazard, occurs when the execution of the current instruction depends on data produced by an earlier instruction."}, {"start": "00:08:50", "is_lecture": true, "end": "00:08:57", "is_worked_example": false, "text": "For example, an instruction that reads R0 will depend on the execution of an earlier instruction that wrote R0."}, {"start": "00:08:57", "is_lecture": true, "end": "00:09:04", "is_worked_example": false, "text": "The second, termed a control hazard, occurs when a branch, jump, or exception changes the order of execution."}, {"start": "00:09:04", "is_lecture": true, "end": "00:09:11", "is_worked_example": false, "text": "For example, the choice of which instruction to execute after a BNE depends on whether the branch is taken or not."}, {"start": "00:09:11", "is_lecture": true, "end": "00:09:23", "is_worked_example": false, "text": "Instruction execution triggers a hazard when the instruction on which it depends is also in the pipeline, i.e., the earlier instruction hasn't finished execution!"}, {"start": "00:09:23", "is_lecture": true, "end": "00:09:28", "is_worked_example": false, "text": "We'll need to adjust execution in our pipeline to avoid these hazards."}, {"start": "00:09:28", "is_lecture": true, "end": "00:09:30", "is_worked_example": false, "text": "Here's our plan of attack:"}, {"start": "00:09:30", "is_lecture": true, "end": "00:09:42", "is_worked_example": false, "text": "We'll start by designing a 5-stage pipeline that works with sequences of instructions that don't trigger hazards, i.e., where instruction execution doesn't depend on earlier instructions still in the pipeline."}, {"start": "00:09:42", "is_lecture": true, "end": "00:09:46", "is_worked_example": false, "text": "Then we'll fix our pipeline to deal correctly with data hazards."}, {"start": "00:09:46", "is_lecture": true, "end": "00:09:50", "is_worked_example": false, "text": "And finally, we'll address control hazards."}]}, "C05S01B01-LEC.srt": {"url": "https://courses.edx.org/courses/course-v1:MITx+6.004.3x+2T2016/courseware/c5/c5s1/1?activate_block_id=block-v1%3AMITx%2B6.004.3x%2B2T2016%2Btype%40discussion%2Bblock%40c5s1v1", "items": [{"start": "00:00:00", "is_lecture": true, "end": "00:00:05", "is_worked_example": false, "text": "In this lecture we return to the memory system that we last discussed in Lecture 14 of Part 2."}, {"start": "00:00:05", "is_lecture": true, "end": "00:00:15", "is_worked_example": false, "text": "There we learned about the fundamental tradeoff in current memory technologies: as the memory's capacity increases, so does it access time."}, {"start": "00:00:15", "is_lecture": true, "end": "00:00:22", "is_worked_example": false, "text": "It takes some architectural cleverness to build a memory system that has a large capacity and a small average access time."}, {"start": "00:00:22", "is_lecture": true, "end": "00:00:29", "is_worked_example": false, "text": "The cleverness is embodied in the cache, a hardware subsystem that lives between the CPU and main memory."}, {"start": "00:00:29", "is_lecture": true, "end": "00:00:43", "is_worked_example": false, "text": "Modern CPUs have several levels of cache, where the modest-capacity first level has an access time close to that of the CPU, and higher levels of cache have slower access times but larger capacities."}, {"start": "00:00:43", "is_lecture": true, "end": "00:00:57", "is_worked_example": false, "text": "Caches give fast access to a small number of memory locations, using associative addressing so that the cache has the ability to hold the contents of the memory locations the CPU is accessing most frequently."}, {"start": "00:00:57", "is_lecture": true, "end": "00:01:01", "is_worked_example": false, "text": "The current contents of the cache are managed automatically by the hardware."}, {"start": "00:01:01", "is_lecture": true, "end": "00:01:13", "is_worked_example": false, "text": "Caches work well because of the principle of locality: if the CPU accesses location X at time T, it's likely to access nearby locations in the not-too-distant future."}, {"start": "00:01:13", "is_lecture": true, "end": "00:01:26", "is_worked_example": false, "text": "The cache is organized so that nearby locations can all reside in the cache simultaneously, using a simple indexing scheme to choose which cache location should be checked for a matching address."}, {"start": "00:01:26", "is_lecture": true, "end": "00:01:32", "is_worked_example": false, "text": "If the address requested by the CPU resides in the cache, access time is quite fast."}, {"start": "00:01:32", "is_lecture": true, "end": "00:01:46", "is_worked_example": false, "text": "In order to increase the probability that requested addresses reside in the cache, we introduced the notion of \"associativity\", which increased the number of cache locations checked on each access and"}, {"start": "00:01:46", "is_lecture": true, "end": "00:01:51", "is_worked_example": false, "text": "solved the problem of having, say, instructions and data compete for the same cache locations.."}, {"start": "00:01:51", "is_lecture": true, "end": "00:01:58", "is_worked_example": false, "text": "We also discussed appropriate choices for block size (the number of words in a cache line),"}, {"start": "00:01:58", "is_lecture": true, "end": "00:02:04", "is_worked_example": false, "text": "replacement policy (how to choose which cache line to reuse on a cache miss),"}, {"start": "00:02:04", "is_lecture": true, "end": "00:02:09", "is_worked_example": false, "text": "and write policy (deciding when to write changed data back to main memory)."}, {"start": "00:02:09", "is_lecture": true, "end": "00:02:17", "is_worked_example": false, "text": "We'll see these same choices again in this lecture as we work to expand the memory hierarchy beyond main memory."}, {"start": "00:02:17", "is_lecture": true, "end": "00:02:25", "is_worked_example": false, "text": "We never discussed where the data in main memory comes from and how the process of filling main memory is managed."}, {"start": "00:02:25", "is_lecture": true, "end": "00:02:27", "is_worked_example": false, "text": "That's the topic of today's lecture.."}, {"start": "00:02:27", "is_lecture": true, "end": "00:02:41", "is_worked_example": false, "text": "Flash drives and hard disks provide storage options that have more capacity than main memory, with the added benefit of being non-volatile, i.e., they continue to store data even when turned off."}, {"start": "00:02:41", "is_lecture": true, "end": "00:02:52", "is_worked_example": false, "text": "The generic name for these new devices is \"secondary storage\", where data will reside until it's moved to \"primary storage\", i.e., main memory, for use."}, {"start": "00:02:52", "is_lecture": true, "end": "00:03:01", "is_worked_example": false, "text": "So when we first turn on a computer system, all of its data will be found in secondary storage, which we'll think of as the final level of our memory hierarchy."}, {"start": "00:03:01", "is_lecture": true, "end": "00:03:16", "is_worked_example": false, "text": "As we think about the right memory architecture, we'll build on the ideas from our previous discussion of caches, and, indeed, think of main memory as another level of cache for the permanent, high-capacity secondary storage."}, {"start": "00:03:16", "is_lecture": true, "end": "00:03:26", "is_worked_example": false, "text": "We'll be building what we call a virtual memory system, which, like caches, will automatically move data from secondary storage into main memory as needed."}, {"start": "00:03:26", "is_lecture": true, "end": "00:03:39", "is_worked_example": false, "text": "The virtual memory system will also let us control what data can be accessed by the program, serving as a stepping stone to building a system that can securely run many programs on a single CPU."}, {"start": "00:03:39", "is_lecture": true, "end": "00:03:41", "is_worked_example": false, "text": "Let's get started!"}, {"start": "00:03:41", "is_lecture": true, "end": "00:03:48", "is_worked_example": false, "text": "Here we see the cache and main memory, the two components of our memory system as developed in Lecture 14."}, {"start": "00:03:48", "is_lecture": true, "end": "00:03:51", "is_worked_example": false, "text": "And here's our new secondary storage layer."}, {"start": "00:03:51", "is_lecture": true, "end": "00:03:56", "is_worked_example": false, "text": "The good news: the capacity of secondary storage is huge!"}, {"start": "00:03:56", "is_lecture": true, "end": "00:04:06", "is_worked_example": false, "text": "Even the most modest modern computer system will have 100's of gigabytes of secondary storage and having a terabyte or two is not uncommon on medium-size desktop computers."}, {"start": "00:04:06", "is_lecture": true, "end": "00:04:15", "is_worked_example": false, "text": "Secondary storage for the cloud can grow to many petabytes (a petabyte is 10^15 bytes or a million gigabytes)."}, {"start": "00:04:15", "is_lecture": true, "end": "00:04:22", "is_worked_example": false, "text": "The bad news: disk access times are 100,000 times longer that those of DRAM."}, {"start": "00:04:22", "is_lecture": true, "end": "00:04:30", "is_worked_example": false, "text": "So the change in access time from DRAM to disk is much, much larger than the change from caches to DRAM."}, {"start": "00:04:30", "is_lecture": true, "end": "00:04:40", "is_worked_example": false, "text": "When looking at DRAM timing, we discovered that the additional access time for retrieving a contiguous block of words was small compared to the access time for the first word,"}, {"start": "00:04:40", "is_lecture": true, "end": "00:04:46", "is_worked_example": false, "text": "so fetching a block was the right plan assuming we'd eventually access the additional words."}, {"start": "00:04:46", "is_lecture": true, "end": "00:04:53", "is_worked_example": false, "text": "For disks, the access time difference between the first word and successive words is even more dramatic."}, {"start": "00:04:53", "is_lecture": true, "end": "00:04:58", "is_worked_example": false, "text": "So, not surprisingly, we'll be reading fairly large blocks of data from disk."}, {"start": "00:04:58", "is_lecture": true, "end": "00:05:10", "is_worked_example": false, "text": "The consequence of the much, much larger secondary-storage access time is that it will be very time consuming to access disk if the data we need is not in main memory."}, {"start": "00:05:10", "is_lecture": true, "end": "00:05:16", "is_worked_example": false, "text": "So we need to design our virtual memory system to minimize misses when accessing main memory."}, {"start": "00:05:16", "is_lecture": true, "end": "00:05:30", "is_worked_example": false, "text": "A miss, and the subsequent disk access, will have a huge impact on the average memory access time, so the miss rate will need to be very, very small compared to, say, the rate of executing instructions."}, {"start": "00:05:30", "is_lecture": true, "end": "00:05:38", "is_worked_example": false, "text": "Given the enormous miss penalties of secondary storage, what does that tell us about how it should be used as part of our memory hierarchy?"}, {"start": "00:05:38", "is_lecture": true, "end": "00:05:47", "is_worked_example": false, "text": "We will need high associativity, i.e., we need a great deal of flexibility on how data from disk can be located in main memory."}, {"start": "00:05:47", "is_lecture": true, "end": "00:06:00", "is_worked_example": false, "text": "In other words, if our working set of memory accesses fit in main memory, our virtual memory system should make that possible, avoiding unnecessary collisions between accesses to one block of data and another."}, {"start": "00:06:00", "is_lecture": true, "end": "00:06:08", "is_worked_example": false, "text": "We'll want to use a large block size to take advantage of the low incremental cost of reading successive words from disk."}, {"start": "00:06:08", "is_lecture": true, "end": "00:06:18", "is_worked_example": false, "text": "And, given the principle of locality, we'd expect to be accessing other words of the block, thus amortizing the cost of the miss over many future hits."}, {"start": "00:06:18", "is_lecture": true, "end": "00:06:32", "is_worked_example": false, "text": "Finally, we'll want to use a write-back strategy where we'll only update the contents of disk when data that's changed in main memory needs to be replaced by data from other blocks of secondary storage."}, {"start": "00:06:32", "is_lecture": true, "end": "00:06:36", "is_worked_example": false, "text": "There is upside to misses having such long latencies."}, {"start": "00:06:36", "is_lecture": true, "end": "00:06:43", "is_worked_example": false, "text": "We can manage the organization of main memory and the accesses to secondary storage in software."}, {"start": "00:06:43", "is_lecture": true, "end": "00:06:52", "is_worked_example": false, "text": "Even it takes 1000's of instructions to deal with the consequences of a miss, executing those instructions is quick compared to the access time of a disk."}, {"start": "00:06:52", "is_lecture": true, "end": "00:06:57", "is_worked_example": false, "text": "So our strategy will be to handle hits in hardware and misses in software."}, {"start": "00:06:57", "is_lecture": true, "end": "00:07:08", "is_worked_example": false, "text": "This will lead to simple memory management hardware and the possibility of using very clever strategies implemented in software to figure out what to do on misses."}]}, "C06S01B03-LEC.srt": {"url": "https://courses.edx.org/courses/course-v1:MITx+6.004.3x+2T2016/courseware/c6/c6s1/3?activate_block_id=block-v1%3AMITx%2B6.004.3x%2B2T2016%2Btype%40discussion%2Bblock%40c6s1v3", "items": [{"start": "00:00:00", "is_lecture": true, "end": "00:00:05", "is_worked_example": false, "text": "A key technology for timesharing is the periodic interrupt from the external timer device."}, {"start": "00:00:05", "is_lecture": true, "end": "00:00:09", "is_worked_example": false, "text": "Let's remind ourselves how the interrupt hardware in the Beta works."}, {"start": "00:00:09", "is_lecture": true, "end": "00:00:16", "is_worked_example": false, "text": "External devices request an interrupt by asserting the Beta's interrupt request (IRQ) input."}, {"start": "00:00:16", "is_lecture": true, "end": "00:00:28", "is_worked_example": false, "text": "If the Beta is running in user mode, i.e., the supervisor bit stored in the PC is 0, asserting IRQ will trigger the following actions on the clock cycle the interrupt is recognized."}, {"start": "00:00:28", "is_lecture": true, "end": "00:00:40", "is_worked_example": false, "text": "The goal is to save the current PC+4 value in the XP register and force the program counter (PC) to a particular kernel-mode instruction, which starts the execution of the interrupt handler code."}, {"start": "00:00:40", "is_lecture": true, "end": "00:00:50", "is_worked_example": false, "text": "The normal process of generating control signals based on the current instruction is superseded by forcing particular values for some of the control signals."}, {"start": "00:00:50", "is_lecture": true, "end": "00:00:58", "is_worked_example": false, "text": "PCSEL is set to 4, which selects a specified kernel-mode address as the next value of the program counter."}, {"start": "00:00:58", "is_lecture": true, "end": "00:01:02", "is_worked_example": false, "text": "The address chosen depends on the type of external interrupt."}, {"start": "00:01:02", "is_lecture": true, "end": "00:01:08", "is_worked_example": false, "text": "In the case of the timer interrupt, the address is 0x80000008."}, {"start": "00:01:08", "is_lecture": true, "end": "00:01:18", "is_worked_example": false, "text": "Note that PC[31], the supervisor bit, is being set to 1 and the CPU will be in kernel-mode as it starts executing the code of the interrupt handler."}, {"start": "00:01:18", "is_lecture": true, "end": "00:01:30", "is_worked_example": false, "text": "The WASEL, WDSEL, and WERF control signals are set so that PC+4 is written into the XP register (i.e., R30) in the register file."}, {"start": "00:01:30", "is_lecture": true, "end": "00:01:39", "is_worked_example": false, "text": "And, finally, MWR is set to 0 to ensure that if we're interrupting a ST instruction that its execution is aborted correctly."}, {"start": "00:01:39", "is_lecture": true, "end": "00:01:45", "is_worked_example": false, "text": "So in the next clock cycle, execution starts with the first instruction of the kernel-mode interrupt handler,"}, {"start": "00:01:45", "is_lecture": true, "end": "00:01:52", "is_worked_example": false, "text": "which can find the PC+4 of the interrupted instruction in the XP register of the CPU."}, {"start": "00:01:52", "is_lecture": true, "end": "00:01:56", "is_worked_example": false, "text": "As we can see the interrupt hardware is pretty minimal:"}, {"start": "00:01:56", "is_lecture": true, "end": "00:02:07", "is_worked_example": false, "text": "it saves the PC+4 of the interrupted user-mode program in the XP register and sets the program counter to some predetermined value that depends on which external interrupt happened."}, {"start": "00:02:07", "is_lecture": true, "end": "00:02:13", "is_worked_example": false, "text": "The remainder of the work to handle the interrupt request is performed in software."}, {"start": "00:02:13", "is_lecture": true, "end": "00:02:24", "is_worked_example": false, "text": "The state of the interrupted process, e.g., the values in the CPU registers R0 through R30, is stored in main memory in an OS data structure called UserMState."}, {"start": "00:02:24", "is_lecture": true, "end": "00:02:31", "is_worked_example": false, "text": "Then the appropriate handler code, usually a procedure written in C, is invoked to do the heavy lifting."}, {"start": "00:02:31", "is_lecture": true, "end": "00:02:36", "is_worked_example": false, "text": "When that procedure returns, the process state is reloaded from UserMState."}, {"start": "00:02:36", "is_lecture": true, "end": "00:02:47", "is_worked_example": false, "text": "The OS subtracts 4 from the value in XP, making it point to the interrupted instruction and then resumes user-mode execution with a JMP(XP)."}, {"start": "00:02:47", "is_lecture": true, "end": "00:02:57", "is_worked_example": false, "text": "Note that in our simple Beta implementation the first instructions for the various interrupt handlers occupy consecutive locations in main memory."}, {"start": "00:02:57", "is_lecture": true, "end": "00:03:05", "is_worked_example": false, "text": "Since interrupt handlers are longer than one instruction, this first instruction is invariably a branch to the actual interrupt code."}, {"start": "00:03:05", "is_lecture": true, "end": "00:03:21", "is_worked_example": false, "text": "Here we see that the reset interrupt (asserted when the CPU first starts running) sets the PC to 0, the illegal instruction interrupt sets the PC to 4, the timer interrupt sets the PC to 8, and so on."}, {"start": "00:03:21", "is_lecture": true, "end": "00:03:33", "is_worked_example": false, "text": "In all cases, bit 31 of the new PC value is set to 1 so that handlers execute in supervisor or kernel mode, giving them access to the kernel context."}, {"start": "00:03:33", "is_lecture": true, "end": "00:03:45", "is_worked_example": false, "text": "A common alternative is provide a table of new PC values at a known location and have the interrupt hardware access that table to fetch the PC for the appropriate handler routine."}, {"start": "00:03:45", "is_lecture": true, "end": "00:03:50", "is_worked_example": false, "text": "This provides the same functionality as our simple Beta implementation."}, {"start": "00:03:50", "is_lecture": true, "end": "00:03:59", "is_worked_example": false, "text": "Since the process state is saved and restored during an interrupt, interrupts are transparent to the running user-mode program."}, {"start": "00:03:59", "is_lecture": true, "end": "00:04:07", "is_worked_example": false, "text": "In essence, we borrow a few CPU cycles to deal with the interrupt, then it's back to normal program execution."}, {"start": "00:04:07", "is_lecture": true, "end": "00:04:10", "is_worked_example": false, "text": "Here's how the timer interrupt handler would work."}, {"start": "00:04:10", "is_lecture": true, "end": "00:04:17", "is_worked_example": false, "text": "Our initial goal is to use the timer interrupt to update a data value in the OS that records the current time of day (TOD)."}, {"start": "00:04:17", "is_lecture": true, "end": "00:04:21", "is_worked_example": false, "text": "Let's assume the timer interrupt is triggered every 1/60th of a second."}, {"start": "00:04:21", "is_lecture": true, "end": "00:04:28", "is_worked_example": false, "text": "A user-mode program executes normally, not needing to make any special provision to deal with timer interrupts."}, {"start": "00:04:28", "is_lecture": true, "end": "00:04:38", "is_worked_example": false, "text": "Periodically the timer interrupts the user-mode program to run the clock interrupt handler code in the OS, then resumes execution of the user-mode program."}, {"start": "00:04:38", "is_lecture": true, "end": "00:04:43", "is_worked_example": false, "text": "The program continues execution just as if the interrupt had not occurred."}, {"start": "00:04:43", "is_lecture": true, "end": "00:04:50", "is_worked_example": false, "text": "If the program needs access to the TOD, it makes the appropriate service request to the OS."}, {"start": "00:04:50", "is_lecture": true, "end": "00:04:58", "is_worked_example": false, "text": "The clock handler code in the OS starts and ends with a small amount of assembly-language code to save and restore the state."}, {"start": "00:04:58", "is_lecture": true, "end": "00:05:04", "is_worked_example": false, "text": "In the middle, the assembly code makes a C procedure call to actually handle the interrupt."}, {"start": "00:05:04", "is_lecture": true, "end": "00:05:07", "is_worked_example": false, "text": "Here's what the handler code might look like."}, {"start": "00:05:07", "is_lecture": true, "end": "00:05:17", "is_worked_example": false, "text": "In C, we find the declarations for the TOD data value and the structure, called UserMState, that temporarily holds the saved process state."}, {"start": "00:05:17", "is_lecture": true, "end": "00:05:21", "is_worked_example": false, "text": "There's also the C procedure for incrementing the TOD value."}, {"start": "00:05:21", "is_lecture": true, "end": "00:05:31", "is_worked_example": false, "text": "A timer interrupt executes the BR() instruction at location 8, which branches to the actual interrupt handler code at CLOCK_H."}, {"start": "00:05:31", "is_lecture": true, "end": "00:05:37", "is_worked_example": false, "text": "The code first saves the values of all the CPU registers into the UserMState data structure."}, {"start": "00:05:37", "is_lecture": true, "end": "00:05:42", "is_worked_example": false, "text": "Note that we don't save the value of R31 since its value is always 0."}, {"start": "00:05:42", "is_lecture": true, "end": "00:05:49", "is_worked_example": false, "text": "After setting up the kernel-mode stack, the assembly-language stub calls the C procedure above to do the hard work."}, {"start": "00:05:49", "is_lecture": true, "end": "00:06:01", "is_worked_example": false, "text": "When the procedure returns, the CPU registers are reloaded from the saved process state and the XP register value decremented by 4 so that it will point to the interrupted instruction."}, {"start": "00:06:01", "is_lecture": true, "end": "00:06:05", "is_worked_example": false, "text": "Then a JMP(XP) resumes user-mode execution."}, {"start": "00:06:05", "is_lecture": true, "end": "00:06:08", "is_worked_example": false, "text": "Okay, that was simple enough."}, {"start": "00:06:08", "is_lecture": true, "end": "00:06:12", "is_worked_example": false, "text": "But what does this all have to do with timesharing?"}, {"start": "00:06:12", "is_lecture": true, "end": "00:06:16", "is_worked_example": false, "text": "Wasn't our goal to arrange to periodically switch which process was running?"}, {"start": "00:06:16", "is_lecture": true, "end": "00:06:18", "is_worked_example": false, "text": "Aha!"}, {"start": "00:06:18", "is_lecture": true, "end": "00:06:27", "is_worked_example": false, "text": "We have code that runs on every timer interrupt, so let's modify it so that every so often we arrange to call the OS' Scheduler() routine."}, {"start": "00:06:27", "is_lecture": true, "end": "00:06:35", "is_worked_example": false, "text": "In this example, we'd set the constant QUANTUM to 2 if we wanted to call Scheduler() every second timer interrupt."}, {"start": "00:06:35", "is_lecture": true, "end": "00:06:40", "is_worked_example": false, "text": "The Scheduler() subroutine is where the time sharing magic happens!"}, {"start": "00:06:40", "is_lecture": true, "end": "00:06:48", "is_worked_example": false, "text": "Here we see the UserMState data structure from the previous slide where the user-mode process state is stored during interrupts."}, {"start": "00:06:48", "is_lecture": true, "end": "00:06:55", "is_worked_example": false, "text": "And here's an array of process control block (PCB) data structures, one for each process in the system."}, {"start": "00:06:55", "is_lecture": true, "end": "00:07:05", "is_worked_example": false, "text": "The PCB holds the complete state of a process when some other process is currently executing -- it's the long-term storage for processor state!"}, {"start": "00:07:05", "is_lecture": true, "end": "00:07:17", "is_worked_example": false, "text": "As you can see, it includes a copy of MState with the process' register values, the MMU state, and various state associated with the process' input/output activities,"}, {"start": "00:07:17", "is_lecture": true, "end": "00:07:23", "is_worked_example": false, "text": "represented here by a number indicating which virtual user-interface console is attached to the process."}, {"start": "00:07:23", "is_lecture": true, "end": "00:07:27", "is_worked_example": false, "text": "There are N processes altogether."}, {"start": "00:07:27", "is_lecture": true, "end": "00:07:33", "is_worked_example": false, "text": "The variable CUR gives the index into ProcTable for the currently running process."}, {"start": "00:07:33", "is_lecture": true, "end": "00:07:39", "is_worked_example": false, "text": "And here's the surprisingly simple code for implementing timesharing."}, {"start": "00:07:39", "is_lecture": true, "end": "00:07:48", "is_worked_example": false, "text": "Whenever the Scheduler() routine is called, it starts by moving the temporary saved state into the PCB for the current process."}, {"start": "00:07:48", "is_lecture": true, "end": "00:07:58", "is_worked_example": false, "text": "It then increments CUR to move to the next process, making sure it wraps back around to 0 when we've just finished running the last of the N processes."}, {"start": "00:07:58", "is_lecture": true, "end": "00:08:07", "is_worked_example": false, "text": "It then loads reloads the temporary state from the PCB of the new process and sets up the MMU appropriately."}, {"start": "00:08:07", "is_lecture": true, "end": "00:08:17", "is_worked_example": false, "text": "At this point Scheduler() returns and the clock interrupt handler reloads the CPU registers from the updated temporary saved state and resumes execution."}, {"start": "00:08:17", "is_lecture": true, "end": "00:08:19", "is_worked_example": false, "text": "Voila!"}, {"start": "00:08:19", "is_lecture": true, "end": "00:08:21", "is_worked_example": false, "text": "We're now running a new process."}, {"start": "00:08:21", "is_lecture": true, "end": "00:08:26", "is_worked_example": false, "text": "Let's use this diagram to once again walk through how time sharing works."}, {"start": "00:08:26", "is_lecture": true, "end": "00:08:24", "is_worked_example": false, "text": "At the top of the diagram you'll see the code for the user-mode processes, and below the OS code along with its data structures."}, {"start": "00:08:24", "is_lecture": true, "end": "00:08:42", "is_worked_example": false, "text": "The timer interrupts the currently running user-mode program and starts execution of the OS' clock handler code."}, {"start": "00:08:42", "is_lecture": true, "end": "00:08:48", "is_worked_example": false, "text": "The first thing the handler does is save all the registers into the UserMState data structure."}, {"start": "00:08:48", "is_lecture": true, "end": "00:09:00", "is_worked_example": false, "text": "If the Scheduler() routine is called, it moves the temporarily saved state into the PCB, which provides the long-term storage for a process' state."}, {"start": "00:09:00", "is_lecture": true, "end": "00:09:06", "is_worked_example": false, "text": "Next, Scheduler() copies the saved state for the next process into the temporary holding area."}, {"start": "00:09:06", "is_lecture": true, "end": "00:09:15", "is_worked_example": false, "text": "Then the clock handler reloads the updated state into the CPU registers and resumes execution, this time running code in the new process."}, {"start": "00:09:15", "is_lecture": true, "end": "00:09:25", "is_worked_example": false, "text": "While we're looking at the OS, note that since its code runs with the supervisor mode bit set to 1, interrupts are disabled while in the OS."}, {"start": "00:09:25", "is_lecture": true, "end": "00:09:37", "is_worked_example": false, "text": "This prevents the awkward problem of getting a second interrupt while still in the middle of handling a first interrupt, a situation that might accidentally overwrite the state in UserMState."}, {"start": "00:09:37", "is_lecture": true, "end": "00:09:42", "is_worked_example": false, "text": "But that means one has to be very careful when writing OS code."}, {"start": "00:09:42", "is_lecture": true, "end": "00:09:46", "is_worked_example": false, "text": "Any sort of infinite loop can never be interrupted."}, {"start": "00:09:46", "is_lecture": true, "end": "00:09:53", "is_worked_example": false, "text": "You may have experienced this when your machine appears to freeze, accepting no inputs and just sitting there like a lump."}, {"start": "00:09:53", "is_lecture": true, "end": "00:10:00", "is_worked_example": false, "text": "At this point, your only choice is to power-cycle the hardware (the ultimate interrupt!) and start afresh."}, {"start": "00:10:00", "is_lecture": true, "end": "00:10:12", "is_worked_example": false, "text": "Interrupts are allowed during execution of user-mode programs, so if they run amok and need to be interrupted, that's always possible since the OS is still responding to, say, keyboard interrupts."}, {"start": "00:10:12", "is_lecture": true, "end": "00:10:22", "is_worked_example": false, "text": "Every OS has a magic combination of keystrokes that is guaranteed to suspend execution of the current process, sometimes arranging to make a copy of the process state for later debugging."}, {"start": "00:10:22", "is_lecture": true, "end": "00:10:24", "is_worked_example": false, "text": "Very handy!"}]}, "C03S01B02-LEC.srt": {"url": "https://courses.edx.org/courses/course-v1:MITx+6.004.3x+2T2016/courseware/c3/c3s1/2?activate_block_id=block-v1%3AMITx%2B6.004.3x%2B2T2016%2Btype%40discussion%2Bblock%40c3s1v2", "items": [{"start": "00:00:00", "is_lecture": true, "end": "00:00:07", "is_worked_example": false, "text": "Let's start by redrawing and simplifying the Beta data path so that it will be easier to reason about when we add pipelining."}, {"start": "00:00:07", "is_lecture": true, "end": "00:00:15", "is_worked_example": false, "text": "The first simplification is to focus on sequential execution and so leave out the branch addressing and PC mux logic."}, {"start": "00:00:15", "is_lecture": true, "end": "00:00:19", "is_worked_example": false, "text": "Our simplified Beta always executes the next instruction from PC+4."}, {"start": "00:00:19", "is_lecture": true, "end": "00:00:25", "is_worked_example": false, "text": "We'll add back the branch and jump logic when we discuss control hazards."}, {"start": "00:00:25", "is_lecture": true, "end": "00:00:36", "is_worked_example": false, "text": "The second simplification is to have the register file appear twice in the diagram so that we can tease apart the read and write operations that occur at different stages of instruction execution."}, {"start": "00:00:36", "is_lecture": true, "end": "00:00:44", "is_worked_example": false, "text": "The top Register File shows the combinational read ports, used to when reading the register operands in the RF stage."}, {"start": "00:00:44", "is_lecture": true, "end": "00:00:52", "is_worked_example": false, "text": "The bottom Register File shows the clocked write port, used to write the result into the destination register at the end of the WB stage."}, {"start": "00:00:52", "is_lecture": true, "end": "00:01:00", "is_worked_example": false, "text": "Physically, there's only one set of 32 registers, we've just drawn the read and write circuity as separate components in the diagram."}, {"start": "00:01:00", "is_lecture": true, "end": "00:01:09", "is_worked_example": false, "text": "If we add pipeline registers to the simplified diagram, we see that execution proceeds through the five stages from top to bottom."}, {"start": "00:01:09", "is_lecture": true, "end": "00:01:21", "is_worked_example": false, "text": "If we consider execution of instruction sequences with no data hazards, information is flowing down the pipeline and the pipeline will correctly overlap the execution of all the instructions in the pipeline."}, {"start": "00:01:21", "is_lecture": true, "end": "00:01:26", "is_worked_example": false, "text": "The diagram shows the components needed to implement each of the five stages."}, {"start": "00:01:26", "is_lecture": true, "end": "00:01:32", "is_worked_example": false, "text": "The IF stage contains the program counter and the main memory interface for fetching instructions."}, {"start": "00:01:32", "is_lecture": true, "end": "00:01:26", "is_worked_example": false, "text": "The RF stage has the register file and operand multiplexers."}, {"start": "00:01:26", "is_lecture": true, "end": "00:01:41", "is_worked_example": false, "text": "The ALU stage uses the operands and computes the result."}, {"start": "00:01:41", "is_lecture": true, "end": "00:01:46", "is_worked_example": false, "text": "The MEM stage handles the memory access for load and store operations."}, {"start": "00:01:46", "is_lecture": true, "end": "00:01:51", "is_worked_example": false, "text": "And the WB stage writes the result into the destination register."}, {"start": "00:01:51", "is_lecture": true, "end": "00:01:57", "is_worked_example": false, "text": "In each clock cycle, each stage does its part in the execution of a particular instruction."}, {"start": "00:01:57", "is_lecture": true, "end": "00:02:01", "is_worked_example": false, "text": "In a given clock cycle, there are five instructions in the pipeline."}, {"start": "00:02:01", "is_lecture": true, "end": "00:02:05", "is_worked_example": false, "text": "Note that data accesses to main memory span almost two clock cycles."}, {"start": "00:02:05", "is_lecture": true, "end": "00:02:14", "is_worked_example": false, "text": "Data accesses are initiated at the beginning of the MEM stage and returning data is only needed just before the end of the WB stage."}, {"start": "00:02:14", "is_lecture": true, "end": "00:02:23", "is_worked_example": false, "text": "The memory is itself pipelined and can simultaneously finish the access from an earlier instruction while starting an access for the next instruction."}, {"start": "00:02:23", "is_lecture": true, "end": "00:02:29", "is_worked_example": false, "text": "This simplified diagram isn't showing how the control logic is split across the pipeline stages."}, {"start": "00:02:29", "is_lecture": true, "end": "00:02:30", "is_worked_example": false, "text": "How does that work?"}, {"start": "00:02:30", "is_lecture": true, "end": "00:02:40", "is_worked_example": false, "text": "Note that we've included instruction registers as part of each pipeline stage, so that each stage can compute the control signals it needs from its instruction register."}, {"start": "00:02:40", "is_lecture": true, "end": "00:02:47", "is_worked_example": false, "text": "The encoded instruction is simply passed from one stage to the next as the instruction flows through the pipeline.."}, {"start": "00:02:47", "is_lecture": true, "end": "00:02:52", "is_worked_example": false, "text": "Each stage computes its control signals from the opcode field of its instruction register."}, {"start": "00:02:52", "is_lecture": true, "end": "00:02:57", "is_worked_example": false, "text": "The RF stage needs the RA, RB, and literal fields from its instruction register."}, {"start": "00:02:57", "is_lecture": true, "end": "00:03:02", "is_worked_example": false, "text": "And the WB stage needs the RC field from its instruction register."}, {"start": "00:03:02", "is_lecture": true, "end": "00:03:10", "is_worked_example": false, "text": "The required logic is very similar to the unpipelined implementation, it's just been split up and moved to the appropriate pipeline stage."}, {"start": "00:03:10", "is_lecture": true, "end": "00:03:16", "is_worked_example": false, "text": "We'll see that we will have to add some additional control logic to deal correctly with pipeline hazards."}, {"start": "00:03:16", "is_lecture": true, "end": "00:03:20", "is_worked_example": false, "text": "Our simplified diagram isn't so simple anymore!"}, {"start": "00:03:20", "is_lecture": true, "end": "00:03:27", "is_worked_example": false, "text": "To see how the pipeline works, let's follow along as it executes this sequence of six instructions."}, {"start": "00:03:27", "is_lecture": true, "end": "00:03:33", "is_worked_example": false, "text": "Note that the instructions are reading and writing from different registers, so there are no potential data hazards."}, {"start": "00:03:33", "is_lecture": true, "end": "00:03:03", "is_worked_example": false, "text": "And there are no branches and jumps, so there are no potential control hazards."}, {"start": "00:03:03", "is_lecture": true, "end": "00:03:47", "is_worked_example": false, "text": "Since there are no potential hazards, the instruction executions can be overlapped and their overlapped execution in the pipeline will work correctly."}, {"start": "00:03:47", "is_lecture": true, "end": "00:03:49", "is_worked_example": false, "text": "Okay, here we go!"}, {"start": "00:03:49", "is_lecture": true, "end": "00:04:03", "is_worked_example": false, "text": "During cycle 1, the IF stage sends the value from the program counter to main memory to fetch the first instruction (the green LD instruction), which will be stored in the RF-stage instruction register at the end of the cycle."}, {"start": "00:04:03", "is_lecture": true, "end": "00:04:09", "is_worked_example": false, "text": "Meanwhile, it's also computing PC+4, which will be the next value of the program counter."}, {"start": "00:04:09", "is_lecture": true, "end": "00:04:16", "is_worked_example": false, "text": "We've colored the next value blue to indicate that it's the address of the blue instruction in the sequence."}, {"start": "00:04:16", "is_lecture": true, "end": "00:04:23", "is_worked_example": false, "text": "We'll add the appropriately colored label on the right of each pipeline stage to indicate which instruction the stage is processing."}, {"start": "00:04:23", "is_lecture": true, "end": "00:04:34", "is_worked_example": false, "text": "At the start of cycle 2, we see that values in the PC and instruction registers for the RF stage now correspond to the green instruction."}, {"start": "00:04:34", "is_lecture": true, "end": "00:04:42", "is_worked_example": false, "text": "During the cycle the register file will be reading the register operands, in this case R1, which is needed for the green instruction."}, {"start": "00:04:42", "is_lecture": true, "end": "00:04:53", "is_worked_example": false, "text": "Since the green instruction is a LD, ASEL is 0 and BSEL is 1, selecting the appropriate values to be written into the A and B operand registers at the end of the cycle."}, {"start": "00:04:53", "is_lecture": true, "end": "00:05:03", "is_worked_example": false, "text": "Concurrently, the IF stage is fetching the blue instruction from main memory and computing an updated PC value for the next cycle."}, {"start": "00:05:03", "is_lecture": true, "end": "00:05:20", "is_worked_example": false, "text": "In cycle 3, the green instruction is now in the ALU stage, where the ALU is adding the values in its operand registers (in this case the value of R1 and the constant 4) and the result will be stored in Y_MEM register at the end of the cycle."}, {"start": "00:05:20", "is_lecture": true, "end": "00:05:25", "is_worked_example": false, "text": "In cycle 4, we're overlapping execution of four instructions."}, {"start": "00:05:25", "is_lecture": true, "end": "00:05:30", "is_worked_example": false, "text": "The MEM stage initiates a memory read for the green LD instruction."}, {"start": "00:05:30", "is_lecture": true, "end": "00:05:39", "is_worked_example": false, "text": "Note that the read data will first become available in the WB stage -- it's not available to CPU in the current clock cycle."}, {"start": "00:05:39", "is_lecture": true, "end": "00:05:47", "is_worked_example": false, "text": "In cycle 5, the results of the main memory read initiated in cycle 4 are available for writing to the register file in the WB stage."}, {"start": "00:05:47", "is_lecture": true, "end": "00:05:56", "is_worked_example": false, "text": "So execution of the green LD instruction will be complete when the memory data is written to R2 at the end of cycle 5."}, {"start": "00:05:56", "is_lecture": true, "end": "00:06:02", "is_worked_example": false, "text": "Meanwhile, the MEM stage is initiating a memory read for the blue LD instruction."}, {"start": "00:06:02", "is_lecture": true, "end": "00:06:07", "is_worked_example": false, "text": "The pipeline continues to complete successive instructions in successive clock cycles."}, {"start": "00:06:07", "is_lecture": true, "end": "00:06:10", "is_worked_example": false, "text": "The latency for a particular instruction is 5 clock cycles."}, {"start": "00:06:10", "is_lecture": true, "end": "00:06:15", "is_worked_example": false, "text": "The throughput of the pipelined CPU is 1 instruction/cycle."}, {"start": "00:06:15", "is_lecture": true, "end": "00:06:24", "is_worked_example": false, "text": "This is the same as the unpipelined implementation, except that the clock period is shorter because each pipeline stage has fewer components."}, {"start": "00:06:24", "is_lecture": true, "end": "00:06:34", "is_worked_example": false, "text": "Note that the effects of the green LD, i.e., filling R2 with a new value, don't happen until the rising edge of the clock at the end of cycle 5."}, {"start": "00:06:34", "is_lecture": true, "end": "00:06:41", "is_worked_example": false, "text": "In other words, the results of the green LD aren't available to other instructions until cycle 6."}, {"start": "00:06:41", "is_lecture": true, "end": "00:06:49", "is_worked_example": false, "text": "If there were instructions in the pipeline that read R2 before cycle 6, they would have gotten an old value!"}, {"start": "00:06:49", "is_lecture": true, "end": "00:06:51", "is_worked_example": false, "text": "This is an example of a data hazard."}, {"start": "00:06:51", "is_lecture": true, "end": "00:06:56", "is_worked_example": false, "text": "Not a problem for us, since our instruction sequence didn't trigger this data hazard."}, {"start": "00:06:56", "is_lecture": true, "end": "00:07:01", "is_worked_example": false, "text": "Tackling data hazards is our next task."}]}}
