0
00:00:00,000 --> 00:00:03,000
Let's take a moment to look at a different example.

1
00:00:03,000 --> 00:00:10,000
Automated teller machines allow bank customers to perform a variety of transactions: deposits, withdrawals, transfers, etc.

2
00:00:10,000 --> 00:00:17,000
Let's consider what happens when two customers try to withdraw $50 from the same account at the same time.

3
00:00:17,000 --> 00:00:22,000
A portion of the bank's code for a withdrawal transaction is shown in the upper right.

4
00:00:22,000 --> 00:00:27,000
This code is responsible for adjusting the account balance to reflect the amount of the withdrawal.

5
00:00:27,000 --> 00:00:32,000
Presumably the check to see if there is sufficient funds has already happened.

6
00:00:32,000 --> 00:00:34,000
What's supposed to happen?

7
00:00:34,000 --> 00:00:47,000
Let's assume that the bank is using a separate process to handle each transaction, so the two withdrawal transactions cause two different processes to be created, each of which will run the Debit code.

8
00:00:47,000 --> 00:01:00,000
If each of the calls to Debit run to completion without interruption, we get the desired outcome: the first transaction debits the account by $50, then the second transaction does the same.

9
00:01:00,000 --> 00:01:06,000
The net result is that you and your friend have $100 and the balance is $100 less.

10
00:01:06,000 --> 00:01:08,000
So far, so good.

11
00:01:08,000 --> 00:01:14,000
But what if the process for the first transaction is interrupted just after it's read the balance?

12
00:01:14,000 --> 00:01:19,000
The second process subtracts $50 from the balance, completing that transaction.

13
00:01:19,000 --> 00:01:27,000
Now the first process resumes, using the now out-of-date balance it loaded just before being interrupted.

14
00:01:27,000 --> 00:01:33,000
The net result is that you and your friend have $100, but the balance has only been debited by $50.

15
00:01:33,000 --> 00:01:44,000
The moral of the story is that we need to be careful when writing code that reads and writes shared data since other processes might modify the data in the middle of our execution.

16
00:01:44,000 --> 00:01:53,000
When, say, updating a shared memory location, we'll need to LD the current value, modify it, then ST the updated value.

17
00:01:53,000 --> 00:02:02,000
We would like to ensure that no other processes access the shared location between the start of the LD and the completion of the ST.

18
00:02:02,000 --> 00:02:07,000
The LD/modify/ST code sequence is what we call a "critical section".

19
00:02:07,000 --> 00:02:15,000
We need to arrange that other processes attempting to execute the same critical section are delayed until our execution is complete.

20
00:02:15,000 --> 00:02:24,000
This constraint is called "mutual exclusion", i.e., only one process at a time can be executing code in the same critical section.

21
00:02:24,000 --> 00:02:32,000
Once we've identified critical sections, we'll use semaphores to guarantee they execute atomically,

22
00:02:32,000 --> 00:02:41,000
i.e., that once execution of the critical section begins, no other process will be able to enter the critical section until the execution is complete.

23
00:02:41,000 --> 00:02:51,000
The combination of the semaphore to enforce the mutual exclusion constraint and the critical section of code implement what's called a "transaction".

24
00:02:51,000 --> 00:03:01,000
A transaction can perform multiple reads and writes of shared data with the guarantee that none of the data will be read or written by other processes while the transaction is in progress.

25
00:03:01,000 --> 00:03:06,000
Here's the original code to Debit, which we'll modify by adding a LOCK semaphore.

26
00:03:06,000 --> 00:03:12,000
In this case, the resource controlled by the semaphore is the right to run the code in the critical section.

27
00:03:12,000 --> 00:03:20,000
By initializing LOCK to 1, we're saying that at most one process can execute the critical section at a time.

28
00:03:20,000 --> 00:03:25,000
A process running the Debit code WAITs on the LOCK semaphore.

29
00:03:25,000 --> 00:03:34,000
If the value of LOCK is 1, the WAIT will decrement value of LOCK to 0 and let the process enter the critical section.

30
00:03:34,000 --> 00:03:36,000
This is called acquiring the lock.

31
00:03:36,000 --> 00:03:47,000
If the value of LOCK is 0, some other process has acquired the lock and is executing the critical section and our execution is suspended until the LOCK value is non-zero.

32
00:03:47,000 --> 00:03:58,000
When the process completes execution of the critical section, it releases the LOCK with a call to SIGNAL, which will allow other processes to enter the critical section.

33
00:03:58,000 --> 00:04:05,000
If there are multiple WAITing processes, only one will be able to acquire the lock, and the others will still have to wait their turn.

34
00:04:05,000 --> 00:04:16,000
Used in this manner, semaphores are implementing a mutual exclusion constraint, i.e., there's a guarantee that two executions of the critical section cannot overlap.

35
00:04:16,000 --> 00:04:25,000
Note that if multiple processes need to execute the critical section, they may run in any order and the only guarantee is that their executions will not overlap.

36
00:04:25,000 --> 00:04:30,000
There are some interesting engineering issues to consider.

37
00:04:30,000 --> 00:04:36,000
There's the question of the granularity of the lock, i.e., what shared data is controlled by the lock?

38
00:04:36,000 --> 00:04:43,000
In our bank example, should there be one lock controlling access to the balance for all accounts?

39
00:04:43,000 --> 00:04:48,000
That would mean that no one could access any balance while a transaction was in progress.

40
00:04:48,000 --> 00:04:56,000
That would mean that transactions accessing different accounts would have to run one after the other even though they're accessing different data.

41
00:04:56,000 --> 00:05:05,000
So one lock for all the balances would introduce unnecessary precedence constraints, greatly slowing the rate at which transactions could be processed.

42
00:05:05,000 --> 00:05:12,000
Since the guarantee we need is that we shouldn't permit multiple simultaneous transactions on the same account,

43
00:05:12,000 --> 00:05:20,000
it would make more sense to have a separate lock for each account, and change the Debit code to acquire the account's lock before proceeding.

44
00:05:20,000 --> 00:05:32,000
That will only delay transactions that truly overlap, an important efficiency consideration for a large system processing many thousands of mostly non-overlapping transactions each second.

45
00:05:32,000 --> 00:05:37,000
Of course, having per-account locks would mean a lot of locks!

46
00:05:37,000 --> 00:05:47,000
If that's a concern, we can adopt a compromise strategy of having locks that protect groups of accounts, e.g., accounts with same last three digits in the account number.

47
00:05:47,000 --> 00:05:55,000
That would mean we'd only need 1000 locks, which would allow up to 1000 transactions to happen simultaneously.

48
00:05:55,000 --> 00:06:04,000
The notion of transactions on shared data is so useful that we often use a separate system called a database that provides the desired functionality.

49
00:06:04,000 --> 00:06:12,000
Database systems are engineered to provide low-latency access to shared data, providing the appropriate transactional semantics.

50
00:06:12,000 --> 00:06:17,000
The design and implementation of databases and transactions is pretty interesting.

51
00:06:17,000 --> 00:06:21,000
To follow up, I recommend reading about databases on the web.

52
00:06:21,000 --> 00:06:30,000
Returning to our producer/consumer example, we see that if multiple producers are trying to insert characters into the buffer at the same time,

53
00:06:30,000 --> 00:06:39,000
it's possible that their execution may overlap in a way that causes characters to be overwritten and/or the index to be improperly incremented.

54
00:06:39,000 --> 00:06:42,000
We just saw this bug in the bank example:

55
00:06:42,000 --> 00:06:52,000
the producer code contains a critical section of code that accesses the FIFO buffer and we need to ensure that the critical section is executed atomically.

56
00:06:52,000 --> 00:07:03,000
Here we've added a third semaphore, called LOCK, to implement the necessary mutual exclusion constraint for the critical section of code that inserts characters into the FIFO buffer.

57
00:07:03,000 --> 00:07:10,000
With this modification, the system will now work correctly when there are multiple producer processes.

58
00:07:10,000 --> 00:07:18,000
There's a similar issue with multiple consumers, so we've used the same LOCK to protect the critical section for reading from the buffer in the RCV code.

59
00:07:18,000 --> 00:07:29,000
Using the same LOCK for producers and consumers will work, but does introduce unnecessary precedence constraints since producers and consumers use different indices,

60
00:07:29,000 --> 00:07:33,000
i.e., IN for producers and OUT for consumers.

61
00:07:33,000 --> 00:07:39,000
To solve this problem we could use two locks: one for producers and one for consumers.

62
00:07:39,000 --> 00:07:45,000
Semaphores are a pretty handy swiss army knife when it comes to dealing with synchronization issues.

63
00:07:45,000 --> 00:07:53,000
When WAIT and SIGNAL appear in different processes, the semaphore ensures the correct execution timing between processes.

64
00:07:53,000 --> 00:08:02,000
In our example, we used two semaphores to ensure that consumers can't read from an empty buffer and that producers can't write into a full buffer.

65
00:08:02,000 --> 00:08:13,000
We also used semaphores to ensure that execution of critical sections -- in our example, updates of the indices IN and OUT -- were guaranteed to be atomic.

66
00:08:13,000 --> 00:08:25,000
In other words, that the sequence of reads and writes needed to increment a shared index would not be interrupted by another process between the initial read of the index and the final write.

